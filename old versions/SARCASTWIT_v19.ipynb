{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SARCASTWIT_v19.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "62162cd658224f96a90f324b3059ebb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5a280d3d56ef4800906ba592cb85a0c7",
              "IPY_MODEL_0d6c0a0dbf904b3d8471d98af1ac2b1b"
            ],
            "layout": "IPY_MODEL_acf269f7b1a54730bdd2487087f8b0bb"
          }
        },
        "5a280d3d56ef4800906ba592cb85a0c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "info",
            "description": "Yes",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_b5680c928e07492784b2b79222da88d4",
            "style": "IPY_MODEL_38a4e4f3bf9843d6b986ef153113f378",
            "tooltip": ""
          }
        },
        "0d6c0a0dbf904b3d8471d98af1ac2b1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "info",
            "description": "No",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_29acc096604145a69586f411d55088fa",
            "style": "IPY_MODEL_0921fd0e384749cb890431a350c2c1ea",
            "tooltip": ""
          }
        },
        "acf269f7b1a54730bdd2487087f8b0bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5680c928e07492784b2b79222da88d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "50px",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "150px"
          }
        },
        "38a4e4f3bf9843d6b986ef153113f378": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "29acc096604145a69586f411d55088fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "50px",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "150px"
          }
        },
        "0921fd0e384749cb890431a350c2c1ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. **Define dependencies and constrains**"
      ],
      "metadata": {
        "id": "IfcrKr5Na8A_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to download tweet from Twitter, first one must create an account and apply for **developer priviledges**. The application will grant the developer basic access the the [Twitter API](https://developer.twitter.com/en/docs/twitter-api) which are not enough because it only allows the download of tweet of the last 7 days. Therefore, I've applied to the [Premium plan](https://developer.twitter.com/en/support/twitter-api/premium) which allows the download of 25k of tweets per month along with the use _full archive_ and the _30 days_ search API but with limited amout of request per month."
      ],
      "metadata": {
        "id": "TdELnf08cHP2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ImtN6rXUazit"
      },
      "outputs": [],
      "source": [
        "COLAB_DIR = \"/content/\"\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "\n",
        "# File with Twitter project credentials\n",
        "CREDENTIALS = COLAB_DIR+'credentials.yaml'\n",
        "CREDENTIALS_KEY = 'search_tweets_30_day_dev'\n",
        "\n",
        "# csv file where tweet downloaded will be saved\n",
        "DATASET = COLAB_DIR+'dataset.csv'\n",
        "DATASET_ANNOTATED = COLAB_DIR+'dataset_annotated.csv'\n",
        "SENTIPOLIC = COLAB_DIR+'sentipolic.csv'\n",
        "\n",
        "# result of data processing\n",
        "DATASET_PROCESSED = COLAB_DIR+\"result_processed\"\n",
        "DRIVE_FOLDER = \"/content/drive/MyDrive/BIG_DATA_MODELS/\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0sYKlPLLjvx",
        "outputId": "46d5c436-c7c3-4de7-9452-d1c9df4ee3bb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.7.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### install libraries"
      ],
      "metadata": {
        "id": "bdKPmsLJTYA6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install stop-words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0NxpbGi44TS",
        "outputId": "f29d4c04-6592-423e-d206-93bd752bb57d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting stop-words\n",
            "  Downloading stop-words-2018.7.23.tar.gz (31 kB)\n",
            "Building wheels for collected packages: stop-words\n",
            "  Building wheel for stop-words (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stop-words: filename=stop_words-2018.7.23-py3-none-any.whl size=32911 sha256=65998c45f4a72ce60525045bcda75d773b18fa58a7c6a26764953804fe4bbb6d\n",
            "  Stored in directory: /root/.cache/pip/wheels/fb/86/b2/277b10b1ce9f73ce15059bf6975d4547cc4ec3feeb651978e9\n",
            "Successfully built stop-words\n",
            "Installing collected packages: stop-words\n",
            "Successfully installed stop-words-2018.7.23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install libenchant1c2a\n",
        "!pip install pyenchant\n",
        "!apt-get install hunspell-it"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRdt8lR_QBTm",
        "outputId": "21e9e49c-eb16-4121-82d9-9fbb5c7ce73f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  aspell aspell-en dictionaries-common emacsen-common enchant hunspell-en-us\n",
            "  libaspell15 libhunspell-1.6-0 libtext-iconv-perl\n",
            "Suggested packages:\n",
            "  aspell-doc spellutils wordlist hunspell openoffice.org-hunspell\n",
            "  | openoffice.org-core libenchant-voikko\n",
            "The following NEW packages will be installed:\n",
            "  aspell aspell-en dictionaries-common emacsen-common enchant hunspell-en-us\n",
            "  libaspell15 libenchant1c2a libhunspell-1.6-0 libtext-iconv-perl\n",
            "0 upgraded, 10 newly installed, 0 to remove and 42 not upgraded.\n",
            "Need to get 1,312 kB of archives.\n",
            "After this operation, 5,353 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libtext-iconv-perl amd64 1.7-5build6 [13.0 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libaspell15 amd64 0.60.7~20110707-4ubuntu0.2 [310 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 emacsen-common all 2.0.8 [17.6 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 dictionaries-common all 1.27.2 [186 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 aspell amd64 0.60.7~20110707-4ubuntu0.2 [87.7 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 aspell-en all 2017.08.24-0-0.1 [298 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 hunspell-en-us all 1:2017.08.24 [168 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhunspell-1.6-0 amd64 1.6.2-1 [154 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 libenchant1c2a amd64 1.6.0-11.1 [64.4 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 enchant amd64 1.6.0-11.1 [12.2 kB]\n",
            "Fetched 1,312 kB in 0s (10.9 MB/s)\n",
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package libtext-iconv-perl.\n",
            "(Reading database ... 155629 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libtext-iconv-perl_1.7-5build6_amd64.deb ...\n",
            "Unpacking libtext-iconv-perl (1.7-5build6) ...\n",
            "Selecting previously unselected package libaspell15:amd64.\n",
            "Preparing to unpack .../1-libaspell15_0.60.7~20110707-4ubuntu0.2_amd64.deb ...\n",
            "Unpacking libaspell15:amd64 (0.60.7~20110707-4ubuntu0.2) ...\n",
            "Selecting previously unselected package emacsen-common.\n",
            "Preparing to unpack .../2-emacsen-common_2.0.8_all.deb ...\n",
            "Unpacking emacsen-common (2.0.8) ...\n",
            "Selecting previously unselected package dictionaries-common.\n",
            "Preparing to unpack .../3-dictionaries-common_1.27.2_all.deb ...\n",
            "Adding 'diversion of /usr/share/dict/words to /usr/share/dict/words.pre-dictionaries-common by dictionaries-common'\n",
            "Unpacking dictionaries-common (1.27.2) ...\n",
            "Selecting previously unselected package aspell.\n",
            "Preparing to unpack .../4-aspell_0.60.7~20110707-4ubuntu0.2_amd64.deb ...\n",
            "Unpacking aspell (0.60.7~20110707-4ubuntu0.2) ...\n",
            "Selecting previously unselected package aspell-en.\n",
            "Preparing to unpack .../5-aspell-en_2017.08.24-0-0.1_all.deb ...\n",
            "Unpacking aspell-en (2017.08.24-0-0.1) ...\n",
            "Selecting previously unselected package hunspell-en-us.\n",
            "Preparing to unpack .../6-hunspell-en-us_1%3a2017.08.24_all.deb ...\n",
            "Unpacking hunspell-en-us (1:2017.08.24) ...\n",
            "Selecting previously unselected package libhunspell-1.6-0:amd64.\n",
            "Preparing to unpack .../7-libhunspell-1.6-0_1.6.2-1_amd64.deb ...\n",
            "Unpacking libhunspell-1.6-0:amd64 (1.6.2-1) ...\n",
            "Selecting previously unselected package libenchant1c2a:amd64.\n",
            "Preparing to unpack .../8-libenchant1c2a_1.6.0-11.1_amd64.deb ...\n",
            "Unpacking libenchant1c2a:amd64 (1.6.0-11.1) ...\n",
            "Selecting previously unselected package enchant.\n",
            "Preparing to unpack .../9-enchant_1.6.0-11.1_amd64.deb ...\n",
            "Unpacking enchant (1.6.0-11.1) ...\n",
            "Setting up libhunspell-1.6-0:amd64 (1.6.2-1) ...\n",
            "Setting up libaspell15:amd64 (0.60.7~20110707-4ubuntu0.2) ...\n",
            "Setting up emacsen-common (2.0.8) ...\n",
            "Setting up libtext-iconv-perl (1.7-5build6) ...\n",
            "Setting up dictionaries-common (1.27.2) ...\n",
            "Setting up aspell (0.60.7~20110707-4ubuntu0.2) ...\n",
            "Setting up hunspell-en-us (1:2017.08.24) ...\n",
            "Setting up libenchant1c2a:amd64 (1.6.0-11.1) ...\n",
            "Setting up aspell-en (2017.08.24-0-0.1) ...\n",
            "Setting up enchant (1.6.0-11.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for dictionaries-common (1.27.2) ...\n",
            "aspell-autobuildhash: processing: en [en-common].\n",
            "aspell-autobuildhash: processing: en [en-variant_0].\n",
            "aspell-autobuildhash: processing: en [en-variant_1].\n",
            "aspell-autobuildhash: processing: en [en-variant_2].\n",
            "aspell-autobuildhash: processing: en [en-w_accents-only].\n",
            "aspell-autobuildhash: processing: en [en-wo_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_AU-variant_0].\n",
            "aspell-autobuildhash: processing: en [en_AU-variant_1].\n",
            "aspell-autobuildhash: processing: en [en_AU-w_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_AU-wo_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_CA-variant_0].\n",
            "aspell-autobuildhash: processing: en [en_CA-variant_1].\n",
            "aspell-autobuildhash: processing: en [en_CA-w_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_CA-wo_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_GB-ise-w_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_GB-ise-wo_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_GB-ize-w_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_GB-ize-wo_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_GB-variant_0].\n",
            "aspell-autobuildhash: processing: en [en_GB-variant_1].\n",
            "aspell-autobuildhash: processing: en [en_US-w_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_US-wo_accents-only].\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyenchant\n",
            "  Downloading pyenchant-3.2.2-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 3.5 MB/s \n",
            "\u001b[?25hInstalling collected packages: pyenchant\n",
            "Successfully installed pyenchant-3.2.2\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "Suggested packages:\n",
            "  hunspell libreoffice-writer\n",
            "The following NEW packages will be installed:\n",
            "  hunspell-it\n",
            "0 upgraded, 1 newly installed, 0 to remove and 42 not upgraded.\n",
            "Need to get 340 kB of archives.\n",
            "After this operation, 1,752 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 hunspell-it all 1:6.0.3-3 [340 kB]\n",
            "Fetched 340 kB in 1s (562 kB/s)\n",
            "Selecting previously unselected package hunspell-it.\n",
            "(Reading database ... 156043 files and directories currently installed.)\n",
            "Preparing to unpack .../hunspell-it_1%3a6.0.3-3_all.deb ...\n",
            "Unpacking hunspell-it (1:6.0.3-3) ...\n",
            "Setting up hunspell-it (1:6.0.3-3) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://downloads.apache.org/spark/spark-2.4.8/spark-2.4.8-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.8-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark"
      ],
      "metadata": {
        "id": "rF7hhURdQB9v"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!update-alternatives --set java /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\n",
        "!java -version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08GbgJr6MgmM",
        "outputId": "79da3856-bacf-47c4-cf8e-7992d44ffd25"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java to provide /usr/bin/java (java) in manual mode\n",
            "openjdk version \"1.8.0_312\"\n",
            "OpenJDK Runtime Environment (build 1.8.0_312-8u312-b07-0ubuntu1~18.04-b07)\n",
            "OpenJDK 64-Bit Server VM (build 25.312-b07, mixed mode)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ],
      "metadata": {
        "id": "dVTyQPmzDff1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark==3.1.2\n",
        "!pip install spark-nlp==3.4.4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvmO7zGx6v_1",
        "outputId": "c5de79ae-5bf6-4ebf-a89e-066c97c5f436"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark==3.1.2\n",
            "  Downloading pyspark-3.1.2.tar.gz (212.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 212.4 MB 54 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "  Downloading py4j-0.10.9-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 38.3 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.1.2-py2.py3-none-any.whl size=212880769 sha256=c895c1d7ea712d384ad5006d97ee4f1404653292707ae5a0f162c1dd8b062bbc\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/0a/c1/9561f6fecb759579a7d863dcd846daaa95f598744e71b02c77\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.1.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting spark-nlp==3.4.4\n",
            "  Downloading spark_nlp-3.4.4-py2.py3-none-any.whl (145 kB)\n",
            "\u001b[K     |████████████████████████████████| 145 kB 19.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: spark-nlp\n",
            "Successfully installed spark-nlp-3.4.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sparktorch"
      ],
      "metadata": {
        "id": "riiFxATzw3gl",
        "outputId": "b7978f9d-f8fe-490e-da1c-3baf757dce74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sparktorch\n",
            "  Downloading sparktorch-0.1.2.tar.gz (21 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from sparktorch) (1.11.0+cu113)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.7/dist-packages (from sparktorch) (1.1.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from sparktorch) (2.23.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from sparktorch) (0.3.5.1)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from flask->sparktorch) (1.0.1)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from flask->sparktorch) (7.1.2)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask->sparktorch) (1.1.0)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask->sparktorch) (2.11.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->flask->sparktorch) (2.0.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->sparktorch) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->sparktorch) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->sparktorch) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->sparktorch) (2022.5.18.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->sparktorch) (4.2.0)\n",
            "Building wheels for collected packages: sparktorch\n",
            "  Building wheel for sparktorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sparktorch: filename=sparktorch-0.1.2-py3-none-any.whl size=24596 sha256=fa73362dd77cb4eb82130575872a524ad05f0e48fadb8880ba3b73155349354b\n",
            "  Stored in directory: /root/.cache/pip/wheels/67/d4/a2/a288b918877e28698fc8ff8cb1d8290713bd84abcb80715d47\n",
            "Successfully built sparktorch\n",
            "Installing collected packages: sparktorch\n",
            "Successfully installed sparktorch-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ekphrasis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcZteKOWjOzv",
        "outputId": "7910f4a0-7802-45ed-a52f-3343266e66ac"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ekphrasis\n",
            "  Downloading ekphrasis-0.5.4-py3-none-any.whl (83 kB)\n",
            "\u001b[K     |████████████████████████████████| 83 kB 1.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from ekphrasis) (1.21.6)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from ekphrasis) (3.2.5)\n",
            "Collecting ujson\n",
            "  Downloading ujson-5.3.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (45 kB)\n",
            "\u001b[K     |████████████████████████████████| 45 kB 2.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from ekphrasis) (4.64.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from ekphrasis) (1.1.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from ekphrasis) (3.2.2)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Collecting ftfy\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 1.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from ftfy->ekphrasis) (0.2.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->ekphrasis) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->ekphrasis) (1.4.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->ekphrasis) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->ekphrasis) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->ekphrasis) (4.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->ekphrasis) (1.15.0)\n",
            "Installing collected packages: ujson, ftfy, colorama, ekphrasis\n",
            "Successfully installed colorama-0.4.4 ekphrasis-0.5.4 ftfy-6.1.1 ujson-5.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PySpark configurations"
      ],
      "metadata": {
        "id": "VdfBlXxLTgxU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pyspark packages\n",
        "from pyspark import *\n",
        "from pyspark.sql import *\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark import SparkContext, SparkConf\n",
        "from pyspark.sql import DataFrame\n",
        "from pyspark.ml.feature import VectorAssembler, SQLTransformer, Normalizer\n",
        "from pyspark.sql.functions import udf, col, lower, trim, regexp_replace, transform\n",
        "\n",
        "import sparknlp"
      ],
      "metadata": {
        "id": "V-dnnL8JS90g"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "OJzJeXfRMCPb"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Spark NLP\")\\\n",
        "    .master(\"local[4]\")\\\n",
        "    .config('spark.executor.memory', '16G')\\\n",
        "    .config(\"spark.driver.memory\",\"50G\")\\\n",
        "    .config(\"spark.driver.cores\", \"10\")\\\n",
        "    .config(\"spark.sql.analyzer.maxIterations\", \"6000\")\\\n",
        "    .config(\"spark.driver.maxResultSize\", \"10G\") \\\n",
        "    .config(\"spark.kryoserializer.buffer.max\", \"2000M\")\\\n",
        "    .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.12:3.4.4\")\\\n",
        "    .getOrCreate()\n",
        "\n",
        "print(\"Spark NLP version\", sparknlp.version())\n",
        "print(\"Apache Spark version:\", spark.version)"
      ],
      "metadata": {
        "id": "mkCNpht6bvLp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84ba2190-5ce6-4324-aa23-457df98e192c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark NLP version 3.4.4\n",
            "Apache Spark version: 3.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sc = spark.sparkContext\n",
        "type(sc)"
      ],
      "metadata": {
        "id": "HYCtzalg-rGm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9e7e2e0-8494-489d-9bd8-ee046c9ad2bf"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.context.SparkContext"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! cd ~/.ivy2/cache/com.johnsnowlabs.nlp/spark-nlp_2.12/jars && ls -lt"
      ],
      "metadata": {
        "id": "0yAIKiS36-3J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e631f29-ba32-40bc-fe14-301e1427484b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 38952\n",
            "-rw-r--r-- 1 root root 39885074 May  5 15:16 spark-nlp_2.12-3.4.4.jar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download useful files"
      ],
      "metadata": {
        "id": "DokjWUCvcIkQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/deborahdore/italian-sarcastic-tweet-classification/raw/main/dataset/dataset.csv\n",
        "!wget https://github.com/deborahdore/italian-sarcastic-tweet-classification/raw/main/dataset/other/sentipolic.csv\n",
        "!wget https://raw.githubusercontent.com/deborahdore/italian-sarcastic-tweet-classification/main/credentials/credentials.yaml\n",
        "!wget https://raw.githubusercontent.com/deborahdore/italian-sarcastic-tweet-classification/main/dataset/dataset_annotated.csv"
      ],
      "metadata": {
        "id": "EENgh8yncNzS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b687fe00-9888-4aac-fc84-b1bbdde8e78d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-30 19:15:24--  https://github.com/deborahdore/italian-sarcastic-tweet-classification/raw/main/dataset/dataset.csv\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/deborahdore/italian-sarcastic-tweet-classification/main/dataset/dataset.csv [following]\n",
            "--2022-05-30 19:15:24--  https://raw.githubusercontent.com/deborahdore/italian-sarcastic-tweet-classification/main/dataset/dataset.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1797205 (1.7M) [text/plain]\n",
            "Saving to: ‘dataset.csv’\n",
            "\n",
            "dataset.csv         100%[===================>]   1.71M  --.-KB/s    in 0.01s   \n",
            "\n",
            "2022-05-30 19:15:25 (162 MB/s) - ‘dataset.csv’ saved [1797205/1797205]\n",
            "\n",
            "--2022-05-30 19:15:25--  https://github.com/deborahdore/italian-sarcastic-tweet-classification/raw/main/dataset/other/sentipolic.csv\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/deborahdore/italian-sarcastic-tweet-classification/main/dataset/other/sentipolic.csv [following]\n",
            "--2022-05-30 19:15:25--  https://raw.githubusercontent.com/deborahdore/italian-sarcastic-tweet-classification/main/dataset/other/sentipolic.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1356686 (1.3M) [text/plain]\n",
            "Saving to: ‘sentipolic.csv’\n",
            "\n",
            "sentipolic.csv      100%[===================>]   1.29M  --.-KB/s    in 0.007s  \n",
            "\n",
            "2022-05-30 19:15:25 (176 MB/s) - ‘sentipolic.csv’ saved [1356686/1356686]\n",
            "\n",
            "--2022-05-30 19:15:25--  https://raw.githubusercontent.com/deborahdore/italian-sarcastic-tweet-classification/main/credentials/credentials.yaml\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 237 [text/plain]\n",
            "Saving to: ‘credentials.yaml’\n",
            "\n",
            "credentials.yaml    100%[===================>]     237  --.-KB/s    in 0s      \n",
            "\n",
            "2022-05-30 19:15:25 (8.53 MB/s) - ‘credentials.yaml’ saved [237/237]\n",
            "\n",
            "--2022-05-30 19:15:25--  https://raw.githubusercontent.com/deborahdore/italian-sarcastic-tweet-classification/main/dataset/dataset_annotated.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 931783 (910K) [text/plain]\n",
            "Saving to: ‘dataset_annotated.csv’\n",
            "\n",
            "dataset_annotated.c 100%[===================>] 909.94K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2022-05-30 19:15:25 (48.3 MB/s) - ‘dataset_annotated.csv’ saved [931783/931783]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# italian dictionary for lemmatization\n",
        "!wget https://raw.githubusercontent.com/michmech/lemmatization-lists/master/lemmatization-it.txt"
      ],
      "metadata": {
        "id": "5v7zGUIlnl4Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "834a9717-f718-4468-fcb1-7a3ed3991b9c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-30 19:15:25--  https://raw.githubusercontent.com/michmech/lemmatization-lists/master/lemmatization-it.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7917510 (7.5M) [text/plain]\n",
            "Saving to: ‘lemmatization-it.txt’\n",
            "\n",
            "lemmatization-it.tx 100%[===================>]   7.55M  --.-KB/s    in 0.03s   \n",
            "\n",
            "2022-05-30 19:15:26 (252 MB/s) - ‘lemmatization-it.txt’ saved [7917510/7917510]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "R3ujpuPDQvbH",
        "outputId": "b17a3fa5-26af-4e13-ac23-d505b07b4057"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-d5df0069828e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms)\u001b[0m\n\u001b[1;32m    107\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m       \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m       ephemeral=True)\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral)\u001b[0m\n\u001b[1;32m    122\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     _message.blocking_request(\n\u001b[0;32m--> 124\u001b[0;31m         'request_auth', request={'authType': 'dfs_ephemeral'}, timeout_sec=None)\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m   \u001b[0mmountpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    173\u001b[0m   request_id = send_request(\n\u001b[1;32m    174\u001b[0m       request_type, request, parent=parent, expect_reply=True)\n\u001b[0;32m--> 175\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    104\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. **Retrieve Tweet**\n",
        "\n",
        "\n",
        "> Following, some code cell will be annotated with *%% script false* in order to avoid their execution. Those cell concern the download of the tweets from Twitter. Even if this may not sound dangerous, I've finished the request at my disposal. Therefore, calling the Twitter API will produce an error. Also, please don't run them otherwise the output of the cell will be lost.\n",
        "\n"
      ],
      "metadata": {
        "id": "5wh23uCQcxfP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# useful imports\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "import requests\n",
        "import json\n",
        "import yaml\n",
        "import csv\n",
        "import pdb\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "cynI3DutEnEP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- First we must retrieve and validate the credentials that we will need to access the Twitter API. I've store the bearer token in a yaml file: *credentials.yaml*\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gt6JZtFie0Py"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def handle_credentials(credentials, key):\n",
        "  with open(credentials, \"r\") as stream:\n",
        "    try:\n",
        "        credentials = yaml.safe_load(stream)\n",
        "        return credentials[key]\n",
        "    except yaml.YAMLError as exc:\n",
        "        print(exc)"
      ],
      "metadata": {
        "id": "qOoIg7uZc2bM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "credentials = handle_credentials(CREDENTIALS, CREDENTIALS_KEY)\n",
        "endpoint = credentials['endpoint'] # we will use this endpoint to search for the tweet\n",
        "print(endpoint)"
      ],
      "metadata": {
        "id": "i_UEONFUfOt2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cfb98fe-5adf-48dd-e402-4c8b826d5ef0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://api.twitter.com/1.1/tweets/search/30day/dev1.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Second we must create the header for the request"
      ],
      "metadata": {
        "id": "J-RByZFOf9iQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def handle_headers(credentials:dict):\n",
        "  headers = {\n",
        "    'Content-Type': 'application/json',\n",
        "    'Authorization': f'Bearer {credentials[\"bearer_token\"]}'\n",
        "  }\n",
        "  return headers"
      ],
      "metadata": {
        "id": "5OYEqkb2fW7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "headers = handle_headers(credentials)\n",
        "headers"
      ],
      "metadata": {
        "id": "vfRm7V29gCJq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "822febdd-9dc3-49ce-9ab1-541940019074"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Authorization': 'Bearer None', 'Content-Type': 'application/json'}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Another parameter of the request is the query. The query determines which tweet will be returned in the response. In our case, we have 2 types of queries: the one that searches for sarcastic tweets and the one that returns non-sarcastic tweets"
      ],
      "metadata": {
        "id": "9yp2tFf9gOsg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the query about sarcastic tweet I've chosen some keyword that, in my opion, are used to express sarcasm and/or irony (sarcasm is a sub-type of irony):\n",
        "\n",
        "\n",
        "1. sarcasmo (with or without #)\n",
        "2. ironia (with or without #)\n",
        "3. \"*ridiamo per non piangere*\"\n",
        "4. #coincidenze (.. io non credo) is mostly used to express sarcasm\n",
        "5. \"*qualquadra non cosa*\"\n",
        "\n",
        "Many studies also suggest that sarcasm can be found in tweet related to politics. Therefore, these seems very good starting point:\n",
        "1. monti, draghi, berlusconi (known italian prime minister)\n",
        "2. governo\n",
        "3. premier\n",
        "\n",
        "\n",
        "For non-sarcastic tweet, I've excluded all the possibile word that may refer to sarcasm.\n",
        "\n",
        "The list of operator used can be found in the [Twitter API documentation](https://developer.twitter.com/en/docs/twitter-api/enterprise/rules-and-filtering/operators-by-product)."
      ],
      "metadata": {
        "id": "jL_QG_G5Ew4o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sarcasm_query = '(#sarcasmo OR sarcasmo OR #ironia OR ironia OR \"ridiamo per non piangere\" \\\n",
        "                  OR #coincidenze OR \"qualquadra non cosa\" OR draghi OR monti OR berlusconi \\\n",
        "                  OR governo OR premier) lang:it -has:media'\n",
        "\n",
        "non_sarcasm_query = '-\"ridiamo per non piangere\" -sarcasmo -ironia -\"qualquadra non cosa\" lang:it -has:media'"
      ],
      "metadata": {
        "id": "B4Qan_sigKsq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Now we can define the function that will handle the request and the dataframe where tweet will be stored.\n",
        "\n",
        "\n",
        "> Other parameters that we need in order to process the request are:\n",
        "- *max_result_per_page* : the maximum number of tweets per call \n",
        "- *next_token* : a token that if passed to the request will return the next page of results\n",
        "- I've defined a parameter *max_num_of_request* that will stop the call once that we've reached the desidered amount of calls. This must be done because the request at our disposal are not illimited. So we must be careful to the number of the request that we do\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1AItsWZphAXa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def handle_request(endpoint, headers, query, max_result_per_page, next_token = None):\n",
        "  \n",
        "  if next_token is not None:\n",
        "    payload = json.dumps({\n",
        "      \"maxResults\": max_result_per_page,\n",
        "      \"query\": query,\n",
        "      \"next\": next_token\n",
        "    })\n",
        "  else:\n",
        "    payload = json.dumps({\n",
        "      \"maxResults\": max_result_per_page,\n",
        "      \"query\": query,\n",
        "    })\n",
        "  \n",
        "  response = requests.post(endpoint, headers=headers, data=payload)\n",
        "\n",
        "  return response.text"
      ],
      "metadata": {
        "id": "OVmgNDDch8Se"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_tweet(response, label):\n",
        "  tweets = []\n",
        "  json_response = json.loads(response)\n",
        "  \n",
        "  if 'results' in response:\n",
        "    results = json_response[\"results\"]\n",
        "\n",
        "    for tweet in results:\n",
        "      # is tweet a retweet?\n",
        "      if 'retweeted_status' in tweet:\n",
        "        if tweet['retweeted_status']['truncated']:\n",
        "          text = tweet['retweeted_status']['extended_tweet']['full_text']\n",
        "        else:\n",
        "          text = tweet['retweeted_status']['text']\n",
        "      else:\n",
        "        if tweet['truncated']:\n",
        "          text = tweet['extended_tweet']['full_text']\n",
        "        else:\n",
        "          text = tweet['text']\n",
        "        \n",
        "      text = text.replace('\"', \"'\")\n",
        "      data = Tweet(tweet[\"id\"], f\"{text}\", label)\n",
        "      \n",
        "      tweets.append(data)\n",
        "\n",
        "  else:\n",
        "    print(\"Request went wrong\")\n",
        "    print(response)\n",
        "\n",
        "  return tweets"
      ],
      "metadata": {
        "id": "1gNdo7Bnijtz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_tweet(endpoint, \n",
        "                   headers, \n",
        "                   query, \n",
        "                   label,\n",
        "                   max_result_per_page,\n",
        "                   tweet_list,\n",
        "                   next_token = None, \n",
        "                   max_num_of_request = 20):\n",
        "\n",
        "  if max_num_of_request <= 0:\n",
        "    return tweet_list\n",
        "\n",
        "  response = handle_request(endpoint, headers, query, max_result_per_page, next_token)\n",
        "\n",
        "  tweet_list.extend(extract_tweet(response, label))\n",
        "\n",
        "  try:\n",
        "      next_token = json.loads(response)['next']\n",
        "  except:\n",
        "      next_token = None\n",
        "\n",
        "  if next_token is not None:\n",
        "      return download_tweet(endpoint, headers, query, label, max_result_per_page,\n",
        "                   tweet_list, next_token, max_num_of_request - 1)\n",
        "  else:\n",
        "      return tweet_list"
      ],
      "metadata": {
        "id": "oHbiTTbNg7x4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define tweet\n",
        "Tweet = Row(\"id\", \"text\", \"sarcastic\")"
      ],
      "metadata": {
        "id": "yUW4eUSoyq08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweets = []"
      ],
      "metadata": {
        "id": "nnd9wSFdmzTs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%script false\n",
        "\n",
        "# download sarcastic tweet\n",
        "tweets = download_tweet(endpoint, \n",
        "                   headers, \n",
        "                   sarcasm_query, \n",
        "                   \"Yes\",\n",
        "                   100,\n",
        "                   [],\n",
        "                   next_token = None, \n",
        "                   max_num_of_request = 40)"
      ],
      "metadata": {
        "id": "wqphEQDcwHHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%script false\n",
        "\n",
        "# download non-sarcastic tweet\n",
        "tweets.extend(\n",
        "    download_tweet(endpoint, \n",
        "                   headers, \n",
        "                   non_sarcasm_query, \n",
        "                   \"No\",\n",
        "                   100,\n",
        "                   [],\n",
        "                   next_token = None, \n",
        "                   max_num_of_request = 40))"
      ],
      "metadata": {
        "id": "rLUvtri88LyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%script false\n",
        "# create DataFrame\n",
        "df = spark.createDataFrame(tweets)"
      ],
      "metadata": {
        "id": "RZeSJmGt5FOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%script false\n",
        "df.show(10, truncate=False)"
      ],
      "metadata": {
        "id": "nmS3eNL075po"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%script false\n",
        "\n",
        "# create file\n",
        "if not os.path.exists(DATASET):\n",
        "  os.mknod(DATASET)\n",
        "\n",
        "# save tweets\n",
        "df.toPandas().to_csv(DATASET, header=True, index=False) "
      ],
      "metadata": {
        "id": "PgAKUhbDmrmU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%script false\n",
        "del df"
      ],
      "metadata": {
        "id": "ScVj8BVQgljy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. **Annotate Tweet**"
      ],
      "metadata": {
        "id": "29_DCW9URUjb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# python widgets\n",
        "from ipywidgets import Button\n",
        "import asyncio\n",
        "from IPython.display import display, clear_output\n",
        "import ipywidgets as widgets\n",
        "from ipywidgets import HBox, Layout\n",
        "import time as t"
      ],
      "metadata": {
        "id": "SXY6DWppEFJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When we download tweet using an hashtag, we are not 100% sure of what we downloaded is correct. We must analyze - at least - the majority of the tweet to understand if what we have labelled is correct. There here's a little tool to help us with that."
      ],
      "metadata": {
        "id": "xrDr46suRbeP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Tweet = Row(\"id\", \"text\", \"sarcastic\")\n",
        "\n",
        "schema = StructType([StructField(\"id\", StringType(), True)\\\n",
        "                   ,StructField(\"text\", StringType(), True)\\\n",
        "                   ,StructField(\"sarcastic\", StringType(), True)])\n",
        "\n",
        "df = spark.createDataFrame(pd.read_csv(DATASET), schema=schema)\n",
        "df.show(10)"
      ],
      "metadata": {
        "id": "8hS8XFLNRa2q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3a991bf-cd8e-4ec3-de72-78c53e855523"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+--------------------+---------+\n",
            "|                 id|                text|sarcastic|\n",
            "+-------------------+--------------------+---------+\n",
            "|1524034279151489025|@AlienoGentile C’...|       No|\n",
            "|1524034279122034690|@NaremFox @RickyT...|       No|\n",
            "|1524034278983704581|Sempre al fine di...|       No|\n",
            "|1524034278870372354|E Comunque quest'...|       No|\n",
            "|1524034278828425218|Comunque a me Alb...|       No|\n",
            "|1524034278719475712|che bella persona...|       No|\n",
            "|1524034278589411328|oddio io quando h...|       No|\n",
            "|1524034278559993857|@carlopitocchi La...|       No|\n",
            "|1524034278140616708|Oh nooo solo 400 ...|       No|\n",
            "|1524034278031609856|@WillSorareSmith ...|       No|\n",
            "+-------------------+--------------------+---------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def count_label(df, numeric=False):\n",
        "  label_yes = 1 if numeric else \"Yes\"\n",
        "  label_no = 0 if numeric else \"No\"\n",
        "  return df.groupBy(\"sarcastic\").agg(\n",
        "      count(when(col(\"sarcastic\") == label_yes, 1)),\n",
        "      count(when(col(\"sarcastic\") == label_no, 1)))"
      ],
      "metadata": {
        "id": "g-2CxhPEb59B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# count tweet\n",
        "print(f'Total number of tweet retrieved {df.count()}')"
      ],
      "metadata": {
        "id": "UWC7f6AHbzKA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d97dd678-b48c-4b0f-b43c-13f86ddeace8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of tweet retrieved 11800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we want first to drop duplicates\n",
        "\n",
        "print(\"Count before drop:\")\n",
        "count_label(df).show()\n",
        "\n",
        "count_before_drop = df.count()\n",
        "df = df.dropDuplicates([\"text\"])\n",
        "print(f\"Distinct count: {str(df.count())} \\n\")\n",
        "\n",
        "print(\"Count after drop:\")\n",
        "count_label(df).show()"
      ],
      "metadata": {
        "id": "gciiYKT7R148",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18c29912-de12-4297-cf99-9e284befb88e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Count before drop:\n",
            "+---------+---------------------------------------------+--------------------------------------------+\n",
            "|sarcastic|count(CASE WHEN (sarcastic = Yes) THEN 1 END)|count(CASE WHEN (sarcastic = No) THEN 1 END)|\n",
            "+---------+---------------------------------------------+--------------------------------------------+\n",
            "|       No|                                            0|                                        7800|\n",
            "|      Yes|                                         4000|                                           0|\n",
            "+---------+---------------------------------------------+--------------------------------------------+\n",
            "\n",
            "Distinct count: 9290 \n",
            "\n",
            "Count after drop:\n",
            "+---------+---------------------------------------------+--------------------------------------------+\n",
            "|sarcastic|count(CASE WHEN (sarcastic = Yes) THEN 1 END)|count(CASE WHEN (sarcastic = No) THEN 1 END)|\n",
            "+---------+---------------------------------------------+--------------------------------------------+\n",
            "|       No|                                            0|                                        7304|\n",
            "|      Yes|                                         1986|                                           0|\n",
            "+---------+---------------------------------------------+--------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'dropped {count_before_drop-df.count()} columns')\n",
        "print(f'total count: {df.count()}')"
      ],
      "metadata": {
        "id": "q3WedH78qpMX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8de26cad-25f4-4c3c-f253-e81fe408f790"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dropped 2510 columns\n",
            "total count: 9290\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# visually \n",
        "data = count_label(df).collect()\n",
        "\n",
        "labels = ['sarcastic', 'non sarcastic']\n",
        "colors = sns.color_palette('pastel')[0:5]\n",
        "\n",
        "plt.pie([int(data[1][1]), int(data[0][2])], labels = labels, colors = colors, autopct='%.0f%%')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "idZSd7XIVbXS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "69e47e0f-6f59-4c49-a5b7-cfde3c3d431c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tweets_annotated = []"
      ],
      "metadata": {
        "id": "t4hgqk7qs9mZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def wait_for_change(widget1, widget2): \n",
        "    future = asyncio.Future()\n",
        "    def getvalue(change):\n",
        "        future.set_result(change.description)\n",
        "        widget1.on_click(getvalue, remove=True)\n",
        "        widget2.on_click(getvalue, remove=True) \n",
        "    widget1.on_click(getvalue)\n",
        "    widget2.on_click(getvalue)\n",
        "    return future\n",
        "\n",
        "async def f(df):\n",
        "  df_pandas = df.toPandas()\n",
        "  for index, row in df_pandas.iterrows():\n",
        "    print(f'Is this tweet sarcastic? \\n {row.text} \\n', flush=True)\n",
        "\n",
        "    x = await wait_for_change(sarcastic,non_sarcastic)\n",
        "    \n",
        "    if x == \"Yes\":\n",
        "      print(\"Tagged \", row.id, \"with sarcastic \\n\")\n",
        "      data = Tweet(row.id, row.text, \"Yes\")\n",
        "      tweets_annotated.append(data)\n",
        "    else:\n",
        "      print(\"Tagged \", row.id, \"with non-sarcastic \\n\")\n",
        "      data = Tweet(row.id, row.text, \"No\")      \n",
        "      tweets_annotated.append(data)\n",
        "\n",
        "    clear_output()\n",
        "    display(HBox([sarcastic,non_sarcastic]))"
      ],
      "metadata": {
        "id": "T3QQC7zoSvmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before going forward, we want to ask ourselves *How can know if a tweet is sarcastic or not?*\n",
        "\n",
        "*In Harry Potter and the Half Blood Prince, there is a scene where Harry is leaving the Weasley house and Mrs. Weasley says: “Promise me you will look after yourself…stay out of trouble….” Harry responds: “I always do Mrs. Weasley. I like a quiet life, you know me.” Anyone familiar with Harry Potter knows that his life is far from quiet, and so he must not really mean what he is saying. In fact, Harry is being sarcastic.*\n",
        "\n",
        "[source](https://kids.frontiersin.org/articles/10.3389/frym.2018.00056)\n",
        "\n",
        "Sarcasm is the use of words that say the opposite of what you really mean, often as a joke and with a tone of voice that shows this. It is often used to mock or critize someone, express disapproval or as a defence mechanism.\n",
        "\n",
        "For example:\n",
        "> *Noi invece ce la caviamo con un grado in meno ai termosifoni d'inverno e spegnendo i condizionatori d'estate. Non è fantastico? (#Draghi è un cialtrone sesquipedale, nel caso aveste ancora qualche dubbio)*\n",
        "\n",
        "Here we can imagine the sarcastic tone of the writer. He's obviously criticising the Italian prime minister, Mario Draghi, when, during an interview, he said that we must make sacrifices like lowering the grade of the radiator in order to cope with the possibility of not having the gas from Russia anymore. Obviously, this won't be enough. *Isn't this great?*\n",
        "\n",
        "Sometimes it's difficult also for a human person to understand sarcasm therefore I don't expect the following dataset to be 100% free from bias."
      ],
      "metadata": {
        "id": "8Kyh9cjvkoZN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tool used for annotation: it displays each tweet and the user has to click \"Yes\" \n",
        "# if the tweet was sarcastic, \"No\" otherwise\n",
        "\n",
        "sarcastic=Button(description=\"Yes\", button_style='info', layout=Layout(width='150px', height='50px'))\n",
        "non_sarcastic=Button(description=\"No\", button_style='info', layout=Layout(width='150px', height='50px'))\n",
        "\n",
        "asyncio.create_task(f(df))\n",
        "t.sleep(2)\n",
        "display(HBox([sarcastic,non_sarcastic]))"
      ],
      "metadata": {
        "id": "NJM-MObHrwWp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71,
          "referenced_widgets": [
            "62162cd658224f96a90f324b3059ebb4",
            "5a280d3d56ef4800906ba592cb85a0c7",
            "0d6c0a0dbf904b3d8471d98af1ac2b1b",
            "acf269f7b1a54730bdd2487087f8b0bb",
            "b5680c928e07492784b2b79222da88d4",
            "38a4e4f3bf9843d6b986ef153113f378",
            "29acc096604145a69586f411d55088fa",
            "0921fd0e384749cb890431a350c2c1ea"
          ]
        },
        "outputId": "7f030b1e-f997-4853-a06f-2d9edd98bbdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HBox(children=(Button(button_style='info', description='Yes', layout=Layout(height='50px', width='150px'), sty…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "62162cd658224f96a90f324b3059ebb4"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%script false\n",
        "print(tweets_annotated)"
      ],
      "metadata": {
        "id": "XvlYa09uXPRs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%script false\n",
        "df_annotated = spark.createDataFrame(tweets_annotated)\n",
        "df_annotated.tail(5)"
      ],
      "metadata": {
        "id": "5oOAAGZFsYKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%script false\n",
        "if not os.path.exists(DATASET_ANNOTATED):\n",
        "  os.mknod(DATASET_ANNOTATED)\n",
        "\n",
        "# save tweets\n",
        "df_annotated.toPandas().to_csv(DATASET_ANNOTATED, header=True, index=False)\n",
        "del df_annotated"
      ],
      "metadata": {
        "id": "ClMe-OHFXrDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del df"
      ],
      "metadata": {
        "id": "e3AyKHHqgxE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. **Extend Dataset**"
      ],
      "metadata": {
        "id": "daSEOScGUKJo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "schema = StructType([StructField(\"id\", StringType(), True)\\\n",
        "                   ,StructField(\"text\", StringType(), True)\\\n",
        "                   ,StructField(\"sarcastic\", StringType(), True)])\n",
        "\n",
        "df_annotated = spark.createDataFrame(pd.read_csv(DATASET_ANNOTATED), schema=schema)"
      ],
      "metadata": {
        "id": "W4g8iOQTxneE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Annotated tweets: {df_annotated.count()}\")"
      ],
      "metadata": {
        "id": "K421QQz1sfyt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "994fb656-fbad-4f3d-867b-076df8f886bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Annotated tweets: 5480\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see from the code below, we lost multiple *tweet*.\n",
        "First of all, multiple tweets classified as sarcastic were not sarcastic. Also, I've dropped every tweet that contained only one word, that wasn't actually in italian or \n",
        "that had no sense."
      ],
      "metadata": {
        "id": "M_awlh0kq3nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count_label(df_annotated).show()"
      ],
      "metadata": {
        "id": "k6k_llNRpKCE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14d2a863-176f-4151-9ac7-228862087bfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------------------------------------------+--------------------------------------------+\n",
            "|sarcastic|count(CASE WHEN (sarcastic = Yes) THEN 1 END)|count(CASE WHEN (sarcastic = No) THEN 1 END)|\n",
            "+---------+---------------------------------------------+--------------------------------------------+\n",
            "|       No|                                            0|                                        4629|\n",
            "|      Yes|                                          830|                                           0|\n",
            "|      NaN|                                            0|                                           0|\n",
            "+---------+---------------------------------------------+--------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "However, we can integrate we some external Dataset such as: [SENTIPOLIC](http://www.di.unito.it/~tutreeb/sentipolc-evalita16/index.html) from the challenge EVALITA2016 which contains several italian tweet already classified."
      ],
      "metadata": {
        "id": "UeH_4XijrNc3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_sentipolic = spark.createDataFrame(pd.read_csv(SENTIPOLIC))"
      ],
      "metadata": {
        "id": "B2eVp6uIw9kO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_sentipolic.show(10)"
      ],
      "metadata": {
        "id": "qld5kvU0yDBS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da7ac589-c51f-46d2-ffc3-57648caa5bda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+----+----+----+---+----+----+---+--------------------+\n",
            "|         idtwitter|subj|opos|oneg|iro|lpos|lneg|top|                text|\n",
            "+------------------+----+----+----+---+----+----+---+--------------------+\n",
            "|122449983151669248|   1|   0|   1|  0|   0|   1|  1|Intanto la partit...|\n",
            "|125485104863780865|   1|   0|   1|  0|   0|   1|  1|False illusioni, ...|\n",
            "|125513454315507712|   1|   0|   1|  0|   0|   1|  1|False illusioni, ...|\n",
            "|125524238290522113|   1|   0|   1|  0|   0|   1|  1|Mario Monti: Berl...|\n",
            "|125527933224886272|   1|   0|   1|  0|   0|   1|  1|Mario Monti: Berl...|\n",
            "|125530285164072961|   1|   1|   1|  0|   1|   1|  1|False illusioni, ...|\n",
            "|125533343482789889|   1|   0|   1|  0|   0|   1|  1|L'attacco di Mari...|\n",
            "|125633929217708032|   1|   1|   0|  0|   1|   0|  1|Mario Monti sul C...|\n",
            "|125642756147265536|   1|   0|   1|  0|   0|   1|  1|Le 5 sgradevoli r...|\n",
            "|125692702145785856|   1|   0|   1|  0|   0|   1|  1|False illusioni, ...|\n",
            "+------------------+----+----+----+---+----+----+---+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we will extract only the tweets which are ironic since we have plenty non-ironic\n",
        "df_sentipolic = df_sentipolic.filter(col(\"iro\")==1)"
      ],
      "metadata": {
        "id": "0LMvvrxNyFlS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Ironic tweet retrieved: {df_sentipolic.count()}\")"
      ],
      "metadata": {
        "id": "lN-MoSRiyQ37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "556bcee7-6994-4098-a120-ec893bfee491"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ironic tweet retrieved: 1103\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_sentipolic = df_sentipolic.withColumnRenamed(\"idTwitter\", \"id\")\\\n",
        "                              .withColumnRenamed(\"iro\", \"sarcastic\")\\\n",
        "                              .select(\"id\", \"text\", \"sarcastic\")"
      ],
      "metadata": {
        "id": "CmzhGiatyZxd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_sentipolic.show(10)"
      ],
      "metadata": {
        "id": "PrDm7Oz_zbDx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8781a267-6192-49d0-dcca-d841d5f37858"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+--------------------+---------+\n",
            "|                id|                text|sarcastic|\n",
            "+------------------+--------------------+---------+\n",
            "|125695266887184384|Mario Monti: c'è ...|        1|\n",
            "|125838624670490624|Ma a quanta gente...|        1|\n",
            "|127137847491821568|#la7 ma perche' M...|        1|\n",
            "|129143970163990528|Mario Monti è con...|        1|\n",
            "|131426878245437440|Ma quanto ce vuol...|        1|\n",
            "|133822129773879297|Mario Monti a cap...|        1|\n",
            "|133831591234502656| Mario Monti for ...|        1|\n",
            "|133849038243110912|[News] Mario Mont...|        1|\n",
            "|133954931982991360|cmq Mario Monti è...|        1|\n",
            "|134335814531416064| Napolitano: \"Bis...|        1|\n",
            "+------------------+--------------------+---------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now we want to join the two dataset. However we must use the same label for both.\n",
        "# Therefore if the tweet is sarcastic, the label will be 1, 0 otherwise.\n",
        "\n",
        "\n",
        "df_annotated = df_annotated.withColumn(\"sarcastic\", \n",
        "                                         when(df_annotated.sarcastic == \"Yes\", 1)\n",
        "                                         .when(df_annotated.sarcastic == \"No\", 0)                                    \n",
        "                                         .otherwise(df_annotated.sarcastic))"
      ],
      "metadata": {
        "id": "9J2Ekp4317OU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_annotated.show()"
      ],
      "metadata": {
        "id": "MEk2bAHu2XwA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5602700c-d4c1-4ab7-f9b2-c4994eb19bb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+--------------------+---------+\n",
            "|                 id|                text|sarcastic|\n",
            "+-------------------+--------------------+---------+\n",
            "|1524033834416754689|#'Tu sei un gioca...|        0|\n",
            "|1524034020417294337|#10maggio In occa...|        0|\n",
            "|1524034242963034112|#9maggio Zelensky...|        0|\n",
            "|1524034526908981250|#A SCUOLA DI GIUS...|        1|\n",
            "|1524034207923814401|#A1 - Ginevra -&g...|        0|\n",
            "|1524034530579030018|#A1 - Zurigo -&gt...|        0|\n",
            "|1524034404850581504|#APRILIA: TENTATO...|        0|\n",
            "|1524034635012968448|#Agricoltura, Ocm...|        0|\n",
            "|1524034097424777216|#Algeria: colloqu...|        0|\n",
            "|1524034794635603972|#Alpini pensate c...|        1|\n",
            "|1524034897383505921|#Amici21\n",
            "Il mondo...|        0|\n",
            "|1524034689366953984|#Amici21\n",
            "Riassunt...|        0|\n",
            "|1524034761940946952|#Amici21 che tene...|        0|\n",
            "|1523988570867961856|#Armi #Ucraina Fr...|        1|\n",
            "|1524001659290017794|#Armi, #gas e nuo...|        1|\n",
            "|1524033774102720512|#Aron è una creat...|        0|\n",
            "|1524033888124874752|#Bergamo L'Ammini...|        0|\n",
            "|1524033892935733248|#Bergamo Tutto su...|        0|\n",
            "|1524034781201190915|#Bergamo potrebbe...|        0|\n",
            "|1523993624861626368|#Biden e #Draghi ...|        1|\n",
            "+-------------------+--------------------+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# concatenate DataFrames\n",
        "df_complete = df_annotated.union(df_sentipolic)"
      ],
      "metadata": {
        "id": "m5YwEtQkj-ry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_complete.cache()\n",
        "print(f'Now we have a total of {df_complete.count()} tweets')"
      ],
      "metadata": {
        "id": "DGDmh6_d3Csy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a73b163c-421f-4b99-e46f-bd2eaea56762"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Now we have a total of 6583 tweets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_complete.show(5)"
      ],
      "metadata": {
        "id": "vRXyeqRH2nUU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d295808-5b88-4ebb-f820-3a0a0a08da3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+--------------------+---------+\n",
            "|                 id|                text|sarcastic|\n",
            "+-------------------+--------------------+---------+\n",
            "|1524033834416754689|#'Tu sei un gioca...|        0|\n",
            "|1524034020417294337|#10maggio In occa...|        0|\n",
            "|1524034242963034112|#9maggio Zelensky...|        0|\n",
            "|1524034526908981250|#A SCUOLA DI GIUS...|        1|\n",
            "|1524034207923814401|#A1 - Ginevra -&g...|        0|\n",
            "+-------------------+--------------------+---------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count_label(df_complete, numeric=True).show()"
      ],
      "metadata": {
        "id": "e89JUhcA3IkL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e819b9bd-b587-4032-d8ed-fa5b8c5b8e2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-------------------------------------------+-------------------------------------------+\n",
            "|sarcastic|count(CASE WHEN (sarcastic = 1) THEN 1 END)|count(CASE WHEN (sarcastic = 0) THEN 1 END)|\n",
            "+---------+-------------------------------------------+-------------------------------------------+\n",
            "|        0|                                          0|                                       4629|\n",
            "|      NaN|                                          0|                                          0|\n",
            "|        1|                                       1933|                                          0|\n",
            "+---------+-------------------------------------------+-------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del df_annotated\n",
        "del df_sentipolic"
      ],
      "metadata": {
        "id": "Tay9-2mmha8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E35Bg2RFqSG8",
        "outputId": "120bf0e3-1512-45b2-c2f7-70ad724ec77a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2253"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset is still unbalanced, but better than before."
      ],
      "metadata": {
        "id": "Ap6Pm9b13WEL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. **Data Processing**"
      ],
      "metadata": {
        "id": "pDQJOzR4-Ncl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import enchant\n",
        "from enchant.checker import SpellChecker"
      ],
      "metadata": {
        "id": "v95f3Q1LiqWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ekphrasis.classes.preprocessor import TextPreProcessor\n",
        "from ekphrasis.classes.tokenizer import SocialTokenizer\n",
        "from ekphrasis.dicts.emoticons import emoticons"
      ],
      "metadata": {
        "id": "AFs_VT0XjKF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we want to clean tweet: remove hashtag, links, emoji, whitespaces, mentions. When annotating the tweets, I've also noticed that many of them contained spelling errors. It is recommended to adjust those tweets before the model training."
      ],
      "metadata": {
        "id": "lGGkaFhE360S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "broker = enchant.Broker()\n",
        "broker.describe()\n",
        "broker.list_languages()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMZk9zDMiwQq",
        "outputId": "275690dd-eb2b-404e-bec3-4bb2c0e6fb58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['it_IT', 'it_CH', 'en_US', 'en', 'en_AU', 'en_CA', 'en_GB']"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@udf(\"string\")\n",
        "def spell_checker(text):\n",
        "  checker = SpellChecker(\"it_IT\", text)\n",
        "  for err in checker:\n",
        "    if len(err.suggest())>0:\n",
        "      sug = err.suggest()[0]\n",
        "      err.replace(sug)\n",
        "  return checker.get_text()"
      ],
      "metadata": {
        "id": "xf6fnqpqixZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@udf(\"string\")\n",
        "def remove_unwanted_symbols(text):\n",
        "  punctuation = \"!$%&'()*+, -./:;<=>?[\\]^_`{|}~«»\"\n",
        "  for p in punctuation:\n",
        "    text = text.replace(p, \" \")\n",
        "  return text"
      ],
      "metadata": {
        "id": "XtmPo4dZ6HVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(dataframe):\n",
        "  print(\"Clean Text steps:\")\n",
        "\n",
        "  print(\"1. To lowercase\")\n",
        "  df_lowercase = dataframe.withColumn('text', lower(col('text')))\n",
        "\n",
        "  print(\"2. Remove links\")\n",
        "  df_links = df_lowercase.withColumn('text', regexp_replace('text', r'http\\S+', ''))\n",
        "  \n",
        "  print(\"3. Remove unwanted symbols\")\n",
        "  df_symbol = df_links.withColumn('text', regexp_replace('text', '\\n', ' '))\n",
        "  df_punct = df_symbol.withColumn('text', remove_unwanted_symbols(col('text')))\n",
        "\n",
        "  print(\"4. Remove digits\")\n",
        "  df_digit = df_punct.withColumn('text', regexp_replace('text', r'[0-9]{5,}', ''))\n",
        "\n",
        "  print(\"5. Remove whitespaces\")\n",
        "  df_whitespaces = df_digit.withColumn('text', trim(col('text')))\\\n",
        "                            .withColumn('text', regexp_replace(col(\"text\"), \" +\", \" \"))\n",
        "  \n",
        "\n",
        "  return df_whitespaces"
      ],
      "metadata": {
        "id": "7qqKq2qYiOMS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# exclude columns with NaN\n",
        "df_nan = df_complete.filter(~col('sarcastic').contains('NaN'))\\\n",
        "                    .filter(~col('text').contains('NaN'))"
      ],
      "metadata": {
        "id": "74wXNywLjv3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_clean_text = clean_text(df_nan)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqhO4Z-_kKP7",
        "outputId": "3cb3a927-ac35-4136-83c3-7840012995dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clean Text steps:\n",
            "1. To lowercase\n",
            "2. Remove links\n",
            "3. Remove unwanted symbols\n",
            "4. Remove digits\n",
            "5. Remove whitespaces\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_clean_text.show(15, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TsWyHIXBtN_R",
        "outputId": "06784da4-82bd-4708-a9d1-59f588b36c65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------+\n",
            "|id                 |text                                                                                                                                                                                                                                                       |sarcastic|\n",
            "+-------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------+\n",
            "|1524033834416754689|# tu sei un giocatore incredibile abbracciami l emozionante discorso di un bambino al compagno #dibattito #attualità e società #la7 #politica                                                                                                              |0        |\n",
            "|1524034020417294337|#10maggio in occasione della ix giornata dell’amicizia tra copti e cattolici messaggio inviato oggi da #papafrancesco a tawadros ii leggi 👇                                                                                                               |0        |\n",
            "|1524034242963034112|#9maggio zelensky nato crimea pace ha detto no ha risposto no grazie a @valigiablu per il servizio reso alla chiarezza dei fatti                                                                                                                           |0        |\n",
            "|1524034526908981250|#a scuola di giuseppe conte devi venire                                                                                                                                                                                                                    |1        |\n",
            "|1524034207923814401|#a1 ginevra gt losanna tra raccordo di ecublens e losanna crissier problemi di traffico veicolo in avaria                                                                                                                                                  |0        |\n",
            "|1524034530579030018|#a1 zurigo gt berna tra raccordo di luterbach e kriegstetten colonna lavori di costruzione                                                                                                                                                                 |0        |\n",
            "|1524034404850581504|#aprilia tentato furto al tabacchi                                                                                                                                                                                                                         |0        |\n",
            "|1524034635012968448|#agricoltura ocm #vino @toniscilla «bando da 13 milioni per la qualità dei vigneti» #sicilia                                                                                                                                                               |0        |\n",
            "|1524034097424777216|#algeria colloqui tra #lavrov il presidente e il ministro degli esteri algerino                                                                                                                                                                            |0        |\n",
            "|1524034794635603972|#alpini pensate che si puo essere molesti anche senza essere ubriachi in molti lo sappiamo chi dice il contrario mi pare propio di no                                                                                                                      |1        |\n",
            "|1524034897383505921|#amici21 il mondo ha bisogno di più persone come albe                                                                                                                                                                                                      |0        |\n",
            "|1524034689366953984|#amici21 riassunto serena incontra la nonna la nonna di serena è un po bimba della cele michele incontra i genitori albe incontra finalmente teddy                                                                                                         |0        |\n",
            "|1524034761940946952|#amici21 che tenerezza i genitori di michele si vede che hanno sofferto tanto la lontananza da lui fin da bambino i sacrifici di una famiglia umile il rapporto sempre a distanza ma nei loro occhi c è così tanto orgoglio nel vederlo felice e realizzato|0        |\n",
            "|1523988570867961856|#armi #ucraina fratoianni a @skytg24 grave che #draghi non sia tornato in parlamento #stopwar                                                                                                                                                              |1        |\n",
            "|1524001659290017794|#armi #gas e nuove #sanzioni alla #russia questi i temi sul tavolo nell’incontro con #biden di oggi di #draghi #10maggio                                                                                                                                   |1        |\n",
            "+-------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------+\n",
            "only showing top 15 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the spelling\n",
        "df_spell = df_clean_text.withColumn('text', spell_checker(col('text')))"
      ],
      "metadata": {
        "id": "z4teocLszWNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_spell.cache()\n",
        "df_spell.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rmfhYjLzdXg",
        "outputId": "0880044c-d7ac-4c78-aab9-afbf55915591"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+--------------------+---------+\n",
            "|                 id|                text|sarcastic|\n",
            "+-------------------+--------------------+---------+\n",
            "|1524033834416754689|# tu sei un gioca...|        0|\n",
            "|1524034020417294337|#10maggio in occa...|        0|\n",
            "|1524034242963034112|#9maggio melenso ...|        0|\n",
            "|1524034526908981250|#a scuola di Gius...|        1|\n",
            "|1524034207923814401|#a1 Ginevra g Los...|        0|\n",
            "+-------------------+--------------------+---------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_processor = TextPreProcessor(\n",
        "    normalize=['url', 'email', 'percent', 'money', 'phone', 'user',\n",
        "        'time', 'date', 'number'],\n",
        "    annotate={\"hashtag\", \"allcaps\", \"elongated\", \"repeated\",\n",
        "        'emphasis', 'censored'},\n",
        "    fix_html=True,\n",
        "    segmenter=\"twitter\", \n",
        "    corrector=\"twitter\", \n",
        "    unpack_hashtags=True,\n",
        "    unpack_contractions=True,\n",
        "    spell_correct_elong=False,\n",
        "    tokenizer=SocialTokenizer(lowercase=True).tokenize,\n",
        "    dicts=[emoticons]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYDKyqJYjTEU",
        "outputId": "fef69179-5ac6-49da-9eda-b0ff602370fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ekphrasis/classes/tokenizer.py:225: FutureWarning: Possible nested set at position 2190\n",
            "  self.tok = re.compile(r\"({})\".format(\"|\".join(pipeline)))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word statistics files not found!\n",
            "Downloading... done!\n",
            "Unpacking... done!\n",
            "Reading twitter - 1grams ...\n",
            "generating cache file for faster loading...\n",
            "reading ngrams /root/.ekphrasis/stats/twitter/counts_1grams.txt\n",
            "Reading twitter - 2grams ...\n",
            "generating cache file for faster loading...\n",
            "reading ngrams /root/.ekphrasis/stats/twitter/counts_2grams.txt\n",
            "Reading twitter - 1grams ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ekphrasis/classes/exmanager.py:14: FutureWarning: Possible nested set at position 42\n",
            "  regexes = {k.lower(): re.compile(self.expressions[k]) for k, v in\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@udf(\"string\")\n",
        "def tweet_processor(s):\n",
        "  return \" \".join(text_processor.pre_process_doc(s))"
      ],
      "metadata": {
        "id": "Ya68_fsyjV6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using ekphrasis to annotate text\n",
        "df_process = df_spell.withColumn('text', tweet_processor(col('text')))"
      ],
      "metadata": {
        "id": "TYA176YKzo30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_process.cache()\n",
        "df_process.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-YJ4PCCz2SZ",
        "outputId": "4d8a7bcb-3ade-4b67-b3d7-eac216c438be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+--------------------+---------+\n",
            "|                 id|                text|sarcastic|\n",
            "+-------------------+--------------------+---------+\n",
            "|1524033834416754689|# tu sei un gioca...|        0|\n",
            "|1524034020417294337|<hashtag> 1 0 mag...|        0|\n",
            "|1524034242963034112|<hashtag> 9 maggi...|        0|\n",
            "|1524034526908981250|<hashtag> a </has...|        1|\n",
            "|1524034207923814401|<hashtag> a1 </ha...|        0|\n",
            "+-------------------+--------------------+---------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. **Feature Engineering**"
      ],
      "metadata": {
        "id": "p-cnH0NX7Xup"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# libraries for feature engineering\n",
        "from sparknlp.base import *\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.common import *\n",
        "from sparknlp.annotator import Tokenizer\n",
        "from pyspark.ml.functions import vector_to_array\n",
        "from stop_words import get_stop_words"
      ],
      "metadata": {
        "id": "WNmH5S8BD-m_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First of all, we start the pipeline with the document assembler that is essetial for the next steps. Then we tokenize the text: we transform the phase into tokens. The lemmatizer will convert words (now tokens) into their base form. Then stop-words will be removed. The finisher will transform everything into a readable form."
      ],
      "metadata": {
        "id": "g2K2uUGUkefo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = get_stop_words('it')"
      ],
      "metadata": {
        "id": "JgyZwFsm49f9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document_assembler = DocumentAssembler()\\\n",
        "                        .setInputCol('text')\\\n",
        "                        .setOutputCol('document')\\\n",
        "                        .setCleanupMode(\"shrink\")\n",
        "\n",
        "tokenizer = sparknlp.annotator.Tokenizer()\\\n",
        "                    .setInputCols([\"document\"])\\\n",
        "                    .setOutputCol(\"token\")\n",
        "\n",
        "lemmatizer = Lemmatizer()\\\n",
        "     .setInputCols(['token'])\\\n",
        "     .setOutputCol('lemma')\\\n",
        "     .setDictionary(\"lemmatization-it.txt\", \"->\", \"\\t\")\n",
        "\n",
        "stopwords_cleaner = StopWordsCleaner() \\\n",
        "                .setInputCols([\"lemma\"]) \\\n",
        "                .setOutputCol(\"clean_lemma\") \\\n",
        "                .setCaseSensitive(False)\\\n",
        "                .setStopWords(stop_words)\n",
        "\n",
        "finisher = Finisher()\\\n",
        "                  .setInputCols(\"clean_lemma\")\\\n",
        "                  .setOutputCols(\"pipeline_result\")\\\n",
        "                  .setCleanAnnotations(False)\\\n",
        "                  .setOutputAsArray(True)"
      ],
      "metadata": {
        "id": "WGJ6c4YZjhi4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# assemble pipeline\n",
        "nlpPipeline = Pipeline(stages=[document_assembler,\n",
        "                               tokenizer,\n",
        "                               lemmatizer,\n",
        "                               stopwords_cleaner,\n",
        "                               finisher\n",
        "                               ])"
      ],
      "metadata": {
        "id": "nc557jkAZc0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_fitted = nlpPipeline.fit(df_process).transform(df_process)\\\n",
        "                      .select(['text', 'sarcastic', 'document', 'clean_lemma', 'pipeline_result'])"
      ],
      "metadata": {
        "id": "yFO3xWIiE42O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8871302-e3b2-42da-8772-441e9abe7d36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 132 ms, sys: 23.7 ms, total: 156 ms\n",
            "Wall time: 2.33 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "df_fitted.cache()\n",
        "df_fitted.show()"
      ],
      "metadata": {
        "id": "xbO31EzPE-mx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a96aa6bb-6531-4b67-e088-93628035d2e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+---------+--------------------+--------------------+--------------------+\n",
            "|                text|sarcastic|            document|         clean_lemma|     pipeline_result|\n",
            "+--------------------+---------+--------------------+--------------------+--------------------+\n",
            "|# tu sei un gioca...|        0|[{document, 0, 22...|[{token, 0, 0, #,...|[#, giocatore, in...|\n",
            "|<hashtag> 1 0 mag...|        0|[{document, 0, 18...|[{token, 0, 8, <h...|[<hashtag>, 1, 0,...|\n",
            "|<hashtag> 9 maggi...|        0|[{document, 0, 14...|[{token, 0, 8, <h...|[<hashtag>, 9, ma...|\n",
            "|<hashtag> a </has...|        1|[{document, 0, 58...|[{token, 0, 8, <h...|[<hashtag>, </has...|\n",
            "|<hashtag> a1 </ha...|        0|[{document, 0, 12...|[{token, 0, 8, <h...|[<hashtag>, a1, <...|\n",
            "|<hashtag> a1 </ha...|        0|[{document, 0, 10...|[{token, 0, 8, <h...|[<hashtag>, a1, <...|\n",
            "|<hashtag> aprilia...|        0|[{document, 0, 53...|[{token, 0, 8, <h...|[<hashtag>, april...|\n",
            "|<hashtag> agri co...|        0|[{document, 0, 15...|[{token, 0, 8, <h...|[<hashtag>, agri,...|\n",
            "|<hashtag> algeria...|        0|[{document, 0, 12...|[{token, 0, 8, <h...|[<hashtag>, alger...|\n",
            "|<hashtag> alpin i...|        1|[{document, 0, 15...|[{token, 0, 8, <h...|[<hashtag>, alpin...|\n",
            "|<hashtag> amici21...|        0|[{document, 0, 72...|[{token, 0, 8, <h...|[<hashtag>, amici...|\n",
            "|<hashtag> amici21...|        0|[{document, 0, 16...|[{token, 0, 8, <h...|[<hashtag>, amici...|\n",
            "|<hashtag> amici21...|        0|[{document, 0, 27...|[{token, 0, 8, <h...|[<hashtag>, amici...|\n",
            "|<hashtag> arm i <...|        1|[{document, 0, 17...|[{token, 0, 8, <h...|[<hashtag>, arm, ...|\n",
            "|<hashtag> arm i <...|        1|[{document, 0, 26...|[{token, 0, 8, <h...|[<hashtag>, arm, ...|\n",
            "|<hashtag> aro </h...|        0|[{document, 0, 23...|[{token, 0, 8, <h...|[<hashtag>, aro, ...|\n",
            "|<hashtag> bergamo...|        0|[{document, 0, 11...|[{token, 0, 8, <h...|[<hashtag>, berga...|\n",
            "|<hashtag> bergamo...|        0|[{document, 0, 11...|[{token, 0, 8, <h...|[<hashtag>, berga...|\n",
            "|<hashtag> bergamo...|        0|[{document, 0, 27...|[{token, 0, 8, <h...|[<hashtag>, berga...|\n",
            "|<hashtag> bin de ...|        1|[{document, 0, 10...|[{token, 0, 8, <h...|[<hashtag>, bin, ...|\n",
            "+--------------------+---------+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's write the data into a file so that we don't have to repeat these steps \n",
        "df_fitted.write.parquet(DRIVE_FOLDER + \"result_processed\")"
      ],
      "metadata": {
        "id": "g2XBbOnhETPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_fitted.unpersist()\n",
        "df_process.unpersist()\n",
        "df_spell.unpersist()\n",
        "\n",
        "\n",
        "del df_embeddings\n",
        "del df_process\n",
        "del df_fitted\n",
        "\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEuq1iJDH6cR",
        "outputId": "350211d5-cd7f-4d7a-dab3-3c3a266fd39d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "848"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Choosing the best model"
      ],
      "metadata": {
        "id": "z9_kRE1T7MUj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from sparktorch import serialize_torch_obj, SparkTorch\n",
        "\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.ml.feature import Word2Vec\n",
        "from pyspark.ml.pipeline import Pipeline\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import re\n",
        "from pyspark.ml.linalg import Vectors, VectorUDT\n",
        "\n",
        "\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "from pyspark.mllib.evaluation import BinaryClassificationMetrics"
      ],
      "metadata": {
        "id": "n3enicPJ7ZLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.parquet(DRIVE_FOLDER + \"result_processed\")"
      ],
      "metadata": {
        "id": "j-L_UA4-HLp_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = df.select(col('sarcastic').cast(FloatType())).toPandas().values.reshape(-1)\n",
        "y"
      ],
      "metadata": {
        "id": "CfJS-Dr7aGoS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_weights = compute_class_weight('balanced',\n",
        "                                     classes=[1.0,0.0],\n",
        "                                     y=y)\n",
        "class_weights=torch.tensor(class_weights,dtype=torch.float)\n",
        "\n",
        "class_weights"
      ],
      "metadata": {
        "id": "Rud7tTtuZJE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural Network\n"
      ],
      "metadata": {
        "id": "TpDV9JswWCwT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Word embedding"
      ],
      "metadata": {
        "id": "KUJPIdPx7bc3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to feed the tokens to a neural network, we have to transform them into numbers. To accomplish this task, the Word2Vec approach has been used."
      ],
      "metadata": {
        "id": "o6egjshMlJ20"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = Word2VecApproach() \\\n",
        "    .setInputCols([\"clean_lemma\"]) \\\n",
        "    .setOutputCol(\"embeddings\")\\\n",
        "    .setVectorSize(100)\n",
        "\n",
        "embeddingsSentence = SentenceEmbeddings() \\\n",
        "    .setInputCols([\"document\", \"embeddings\"]) \\\n",
        "    .setOutputCol(\"sentence_embeddings\") \\\n",
        "    .setPoolingStrategy(\"AVERAGE\")\n",
        "\n",
        "embeddingsFinisher = EmbeddingsFinisher() \\\n",
        "   .setInputCols(\"sentence_embeddings\") \\\n",
        "   .setOutputCols(\"finished_sentence_embeddings\") \\\n",
        "   .setOutputAsVector(True) \\\n",
        "   .setCleanAnnotations(False)"
      ],
      "metadata": {
        "id": "oZe8_74sCM0J"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = Pipeline(stages=[embeddings, embeddingsSentence, embeddingsFinisher])"
      ],
      "metadata": {
        "id": "OU3-thn_7OBb"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_embeddings = pipeline.fit(df).transform(df)"
      ],
      "metadata": {
        "id": "5YAyhcC_7qmn"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_embeddings.cache()\n",
        "df_embeddings.select('finished_sentence_embeddings').show(15, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgvZO5UMMrzF",
        "outputId": "e283bca4-81ff-4be9-98f8-61b3904b4da5"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|finished_sentence_embeddings                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|[[-0.025423988699913025,0.009470736607909203,0.005137912463396788,-0.0035136316437274218,-0.037948984652757645,0.015587643720209599,-0.0473012700676918,0.021750489249825478,-0.003691966412588954,-0.04947682097554207,-0.03305191174149513,0.03620591759681702,-0.003036932088434696,0.007895741611719131,-0.007915015332400799,-0.01117664948105812,-0.0035557234659790993,0.01832418330013752,0.02849573642015457,0.007954251952469349,0.014168589375913143,-0.017030660063028336,-0.001069311867468059,-0.009325259365141392,-0.022962065413594246,-0.0021629254333674908,0.011585361324250698,-0.027098892256617546,-0.0331214964389801,0.017744140699505806,-0.005327790509909391,-0.028097515925765038,-0.010815238580107689,-0.0031020452734082937,-0.03306630998849869,0.0035849944688379765,-0.012497251853346825,-0.0267027597874403,-0.01576865278184414,-0.009303195402026176,0.025882987305521965,0.013128508813679218,0.004462534561753273,0.0037962167989462614,0.006859034299850464,-0.0021878541447222233,-0.01478959433734417,-0.02647942304611206,0.0024075249675661325,-0.013298127800226212,0.01643352583050728,-0.011173093691468239,0.021443994715809822,0.013992861844599247,-0.01323818787932396,-0.02792682871222496,-0.0076065161265432835,0.0051385797560215,-0.0026497573126107454,0.013838939368724823,0.011402172967791557,-0.006904171779751778,-0.021250110119581223,-0.009306135587394238,0.026774585247039795,0.0035717999562621117,7.398598245345056E-4,-5.021425895392895E-4,-0.012300518341362476,-0.029331134632229805,-0.01766788400709629,-0.014194571413099766,0.016059979796409607,0.010428404435515404,-0.01016427855938673,-0.013104597106575966,0.0030539955478161573,-0.005079417023807764,0.028709376230835915,-0.0030577415600419044,0.018289070576429367,-0.017166955396533012,-0.01802903600037098,0.014862715266644955,-0.01691289246082306,-0.00718421395868063,-0.006079224869608879,-0.024454720318317413,0.005661380477249622,0.008091789670288563,-0.00791633129119873,0.021418944001197815,0.012477811425924301,0.0251704640686512,0.005367986857891083,-0.00931058544665575,-0.017675133422017097,0.008770938962697983,-0.01761908456683159,0.00704982690513134]]               |\n",
            "|[[0.01708064414560795,0.014206066727638245,0.029749209061264992,-0.004296376369893551,-0.03052658587694168,0.018801912665367126,-0.010287357494235039,0.009226358495652676,0.008807494305074215,-0.021006740629673004,-0.023455319926142693,0.0064537920989096165,-0.02629614621400833,-0.02739410474896431,-0.016138704493641853,-0.04400443658232689,0.012572766281664371,0.0017684906488284469,0.04174619913101196,-8.398322388529778E-4,0.028157422319054604,0.024590885266661644,0.008505136705935001,-0.026152152568101883,-0.009037631563842297,0.025803618133068085,-0.00597174558788538,0.0025569309946149588,0.01657864823937416,0.04388829693198204,-0.0055872537195682526,-0.015566414222121239,-0.005855648312717676,-0.0013419744791463017,0.0051129842177033424,0.0034920615144073963,-0.002231607912108302,-0.025159768760204315,-0.008321049623191357,-2.535551320761442E-4,-0.0047687082551419735,8.728490793146193E-4,-0.01688118278980255,0.0249074287712574,0.00470349658280611,0.010943465866148472,-0.017638519406318665,-0.024773353710770607,-0.012827062048017979,1.0548054706305265E-4,0.024071432650089264,-0.031871624290943146,0.0417817048728466,-0.008533811196684837,0.016295399516820908,-0.018656020984053612,0.020864326506853104,0.029468577355146408,-0.007354378700256348,-0.05158591270446777,-0.005202133674174547,0.010635482147336006,0.00782795250415802,-0.03485901653766632,-0.0025927757378667593,0.03192541003227234,0.02148476429283619,-0.02318263053894043,0.012930203229188919,-0.025504345074295998,0.012069505639374256,-0.022170377895236015,-0.002028687624260783,-0.021489765495061874,-0.01647311821579933,-0.03274351730942726,0.013148127123713493,0.013281027786433697,-0.02104034833610058,0.005738272797316313,0.03206782415509224,-0.003222760045900941,-0.007443965878337622,0.0018287659622728825,-0.005680822767317295,-0.03886869177222252,0.00782687496393919,0.03322911635041237,0.003859894350171089,-0.025357533246278763,-0.034817878156900406,-0.018258148804306984,0.03933516889810562,0.009620471857488155,-0.017935601994395256,0.0065814051777124405,0.014785386621952057,-0.0026492755860090256,-0.010108490474522114,-0.0032640418503433466]]                |\n",
            "|[[-0.04204521328210831,0.011024787090718746,0.00845038890838623,-0.007401636335998774,-0.05592026188969612,0.011522707529366016,-0.055300015956163406,0.03191670775413513,-0.0042608994990587234,-0.050460729748010635,-0.05267751216888428,0.028784099966287613,0.001528050284832716,-0.02324824407696724,-0.01602635346353054,-0.03638245165348053,0.003057508496567607,0.013669351115822792,0.05224304646253586,0.01657070219516754,0.027405887842178345,-0.019958332180976868,0.010237550362944603,-0.01420065388083458,-0.042985428124666214,-0.006810203194618225,0.0244801864027977,-0.03569038584828377,-0.03802857920527458,0.05093635618686676,-0.001348751364275813,-0.02403648942708969,-0.02710605226457119,-0.0016314300009980798,-0.045886676758527756,0.005605172831565142,-0.01597164012491703,-0.032651592046022415,-0.03378286957740784,-0.015836594626307487,0.027206923812627792,0.018942857161164284,0.005394039675593376,0.001105193980038166,0.009883887134492397,-0.002871690085157752,-0.01312636211514473,-0.03071986883878708,-0.011435532942414284,-0.02383330464363098,0.02004014328122139,-0.026166439056396484,0.04305296763777733,0.005915173329412937,-0.01890760287642479,-0.057054921984672546,-8.099679835140705E-4,0.005097059532999992,0.0015074012335389853,0.003260314930230379,-0.01124897412955761,0.00904424861073494,-0.009318345226347446,-0.020017031580209732,0.027964383363723755,0.006362750194966793,0.02954857423901558,0.006969080306589603,0.014156747609376907,-0.03898143023252487,-0.021182775497436523,-0.016770316287875175,0.02276831679046154,0.010749703273177147,-0.004649320151656866,-0.018673699349164963,-0.008687281981110573,-0.006104240193963051,0.0358390174806118,-0.001240103505551815,0.022756371647119522,-0.03534648194909096,-0.028141595423221588,0.008051129058003426,-0.016483163461089134,-0.010893329046666622,-0.013258185237646103,-0.03540926054120064,0.010875366628170013,-0.006897637154906988,-0.017583543434739113,0.030078787356615067,0.021577665582299232,0.01749844290316105,0.00820137932896614,-0.013506115414202213,-0.025304265320301056,0.004973471164703369,-0.028564980253577232,0.02309395931661129]]                                 |\n",
            "|[[-0.031958386301994324,0.009085196070373058,0.013885668478906155,-0.013897399418056011,-0.041623882949352264,0.012329819612205029,-0.05576954409480095,0.022440442815423012,-0.005551316309720278,-0.04578797519207001,-0.04522811993956566,0.030400089919567108,-0.0021834124345332384,0.006648262497037649,-0.0115028852596879,-0.01346262264996767,-0.0034992431756109,0.015352848917245865,0.04782600700855255,0.006523722317069769,0.013972935266792774,-0.01377031672745943,0.005291072651743889,0.009860356338322163,-0.019033491611480713,-0.01750878058373928,0.010519415140151978,-0.035124655812978745,-0.03288209065794945,0.03151160851120949,-0.007262056693434715,-0.01980333961546421,-0.01087641716003418,-0.0034926000516861677,-0.040216680616140366,-0.011059767566621304,-0.016047656536102295,-0.032236192375421524,-0.015430388040840626,-0.004050987306982279,0.022357450798153877,0.022447459399700165,0.0062408894300460815,0.004214756656438112,-0.00251152366399765,-0.014712546952068806,-0.023772776126861572,-0.028573153540492058,0.00908359419554472,-0.021008091047406197,0.0040750689804553986,-0.018969057127833366,0.030987737700343132,0.02385818026959896,-0.012500609271228313,-0.038137342780828476,-0.012414886616170406,0.007494504097849131,0.015163195319473743,0.017404597252607346,0.021392904222011566,-0.0023825280368328094,-0.027574000880122185,0.004434279631823301,0.017032595351338387,-0.0047002010978758335,-0.001348903402686119,-0.00590086355805397,0.0024107748176902533,-0.022457996383309364,-0.020811082795262337,-0.025243202224373817,0.015108407475054264,0.019999012351036072,-0.007564007770270109,-0.014351894147694111,0.004931750241667032,-0.005839969962835312,0.02900238148868084,-0.001704456633888185,0.007275795564055443,-0.03438493236899376,-0.02716999314725399,0.0054536121897399426,-0.00990337785333395,6.48949237074703E-4,0.007934718392789364,-0.021314874291419983,0.00631573935970664,0.014980143867433071,-0.00590197229757905,0.04461272433400154,0.0011770062847062945,0.029503995552659035,0.01841401867568493,-0.01444800291210413,-0.013255171477794647,0.0012803681893274188,-0.013924072496592999,0.018341274932026863]]                  |\n",
            "|[[-0.01378736924380064,0.00713732372969389,0.006271126214414835,-0.00623265141621232,-0.026227489113807678,0.0014381047803908587,-0.019379030913114548,0.00994428712874651,0.00264269532635808,-0.029062515124678612,-0.02160540036857128,0.014490860514342785,-0.0047247521579265594,-0.008230236358940601,-0.007941358722746372,-0.015976140275597572,9.25292435567826E-4,0.00860561989247799,0.024137932807207108,0.004041346721351147,0.01883048005402088,-0.00532658863812685,0.0016025496879592538,-0.012602497823536396,-0.008110277354717255,0.0010987239656969905,0.003883959027007222,-0.012789425440132618,-0.008543447591364384,0.023706089705228806,-0.004113770090043545,-0.015206614509224892,-0.00557610671967268,-0.0031686846632510424,-0.022663898766040802,0.0033150925301015377,-0.006033687386661768,-0.013820551335811615,-0.014112429693341255,-0.010219382122159004,0.011305167339742184,0.012209273874759674,-0.002396645490080118,0.005738550331443548,0.006356913596391678,0.0035658651031553745,-0.006721113808453083,-0.013756620697677135,-0.0017406049882993102,-0.007460550405085087,0.00831218995153904,-0.012639738619327545,0.016371257603168488,0.00518811447545886,-0.0035049165599048138,-0.020900916308164597,0.002931516384705901,0.008529731072485447,0.0011776582105085254,-0.008485553786158562,0.001974130980670452,-0.0020683309994637966,-0.010545678436756134,-0.009901177138090134,0.009033777751028538,0.006012294441461563,0.006609581410884857,-0.00493280217051506,0.007728769443929195,-0.022311966866254807,-0.009464271366596222,-0.0061924876645207405,0.005636558867990971,0.006729389540851116,-0.002751297550275922,-0.01523521263152361,-3.4204794792458415E-4,-0.0018089875811710954,0.011739932000637054,0.0025715120136737823,0.013237659819424152,-0.015338311903178692,-0.012188635766506195,0.00864667259156704,-9.585227817296982E-4,-0.013004343025386333,0.004363876301795244,-0.007923504337668419,0.006623761262744665,4.7328550135716796E-4,-0.00811595469713211,0.012086011469364166,0.017315026372671127,0.010074399411678314,0.006288859993219376,-0.007587780244648457,-0.007982978597283363,0.002266144612804055,-0.009132476523518562,0.006439292337745428]]  |\n",
            "|[[-0.01508787740021944,0.01360334362834692,0.025092944502830505,-0.007677879650145769,-0.048749636858701706,0.008091297931969166,-0.031609904021024704,0.02009667083621025,0.0036882113199681044,-0.03810523822903633,-0.04451971501111984,0.020844757556915283,-0.011343196965754032,-0.023483021184802055,-0.018627868965268135,-0.036351919174194336,-0.0010412875562906265,0.010336077772080898,0.05666765198111534,0.005023132544010878,0.03128156438469887,-0.011322593316435814,0.006135200150310993,-0.017376959323883057,-0.018885154277086258,-0.008474591188132763,1.4483237464446574E-4,-0.01783675327897072,-0.01113111525774002,0.04962438344955444,-0.00817075278609991,-0.012598824687302113,-0.015154161490499973,-0.006190694402903318,-0.030506204813718796,-5.519467522390187E-4,-0.0128277987241745,-0.024962399154901505,-0.016593487933278084,-0.018493780866265297,0.011090697720646858,0.027799418196082115,-0.013397914357483387,0.018439901992678642,0.002227633725851774,-8.132319198921323E-4,-0.02171216532588005,-0.029941771179437637,-8.815095643512905E-4,-0.008900928311049938,0.010634436272084713,-0.03335195779800415,0.037750668823719025,0.006714281626045704,0.011777008883655071,-0.04502921923995018,0.005952987354248762,0.017381073907017708,9.875340620055795E-4,-0.015379860997200012,0.008612836711108685,0.010104773566126823,-0.018022408708930016,-0.01631598360836506,0.006715047173202038,0.013916424475610256,0.008625312708318233,-0.018391834571957588,0.015300409868359566,-0.03276710957288742,-0.011355777271091938,-0.025606179609894753,0.0131398169323802,0.0031324210576713085,-2.184760378440842E-4,-0.0291884895414114,0.009675062261521816,0.012246327474713326,0.015268811024725437,9.643174707889557E-4,0.02159305475652218,-0.02709829993546009,-0.02210136130452156,-0.002204358112066984,-0.0026840977370738983,-0.02522018551826477,0.004592030309140682,-0.00626325560733676,0.013567334972321987,-0.00183124840259552,-0.015802612528204918,0.025183824822306633,0.028117427602410316,0.023357700556516647,0.0018473155796527863,-0.007287559099495411,-0.0031456619035452604,-0.002860378473997116,-0.015074575319886208,0.012470267713069916]]                   |\n",
            "|[[0.006862292997539043,0.0065201520919799805,0.025473782792687416,-0.0036397231742739677,-0.01617840863764286,0.018242934718728065,-0.029546331614255905,0.011017026379704475,1.1006592831108719E-4,-0.022591466084122658,-0.022231316193938255,0.016766320914030075,-0.012646505609154701,0.0015276405028998852,-0.014782489277422428,-0.025122951716184616,0.00314696435816586,7.455330342054367E-4,0.04137587174773216,0.0010645197471603751,0.01850738562643528,0.008945527486503124,0.005338289774954319,0.006488719489425421,-0.006773820146918297,-0.0017914501950144768,-0.009036651812493801,-0.016512053087353706,-0.011028003878891468,0.025609908625483513,-0.007915698923170567,-0.013845425099134445,-4.1499407961964607E-4,-0.0033800587989389896,-0.006182907614856958,-0.0018289611907675862,-0.014893130399286747,-0.026460787281394005,0.006762850563973188,8.378793718293309E-4,0.002298101084306836,0.012238427065312862,-0.008076085709035397,0.010224616155028343,-0.004078010097146034,-0.007020915392786264,-0.019533755257725716,-0.029108542948961258,0.011310231871902943,-0.0039037910755723715,0.00589656550437212,-0.021806281059980392,0.031864143908023834,0.014188447967171669,-8.269711397588253E-4,-0.02175857126712799,-0.008298013359308243,0.023119069635868073,3.2619069679640234E-4,-0.009495814330875874,0.02406548522412777,0.002140754833817482,-0.005259216297417879,-0.00661805085837841,7.006538799032569E-4,0.01477980799973011,-0.002869483083486557,-0.013275232166051865,0.001017178874462843,-0.014309395104646683,6.877395207993686E-5,-0.026685606688261032,0.0032268101349473,0.0030622498597949743,-0.013505741022527218,-0.014398216269910336,0.012681594118475914,0.008786718361079693,-0.003921301104128361,5.594462854787707E-4,0.019314710050821304,-0.005283539183437824,-0.008902554400265217,-6.678476347588003E-5,-0.007165735587477684,-0.012554097920656204,0.01384795643389225,0.016064153984189034,-0.0048089358024299145,-4.819503228645772E-4,-0.020052233710885048,0.013400274328887463,0.00701545225456357,0.027192648500204086,-0.00557459332048893,-0.0011633771937340498,0.010581879876554012,-0.006267154589295387,-0.01132423896342516,0.0012563266791403294]] |\n",
            "|[[-0.04365136846899986,0.02279176376760006,0.01479332149028778,0.008015013299882412,-0.0619480200111866,0.018926842138171196,-0.09350120276212692,0.019639261066913605,-0.017516151070594788,-0.09807797521352768,-0.0952233299612999,0.08731742948293686,0.02287731133401394,0.018120544031262398,-0.021861610934138298,-0.041500117629766464,-0.02174588479101658,0.04475132003426552,0.07777569442987442,0.034932367503643036,-0.004744248930364847,-0.03248890861868858,-0.025045784190297127,-0.0043718707747757435,-0.044233936816453934,-0.04805929958820343,-0.026740534231066704,-0.07971345633268356,-0.09100144356489182,0.055335234850645065,-0.02031577378511429,-0.047328054904937744,-0.01020603533834219,-0.03142816573381424,-0.08527963608503342,0.0027848510071635246,-0.04289182648062706,-0.06602591276168823,-0.021852953359484673,-0.0251294057816267,0.040104303508996964,0.059391383081674576,-3.304524871055037E-4,-0.018601320683956146,0.010503130964934826,-0.015339699573814869,-0.04307226464152336,-0.05843820050358772,0.0540061891078949,-0.020197292789816856,-0.022088484838604927,-0.048489704728126526,0.03670448064804077,0.05795903876423836,-0.01512156706303358,-0.088090680539608,-0.042032938450574875,0.025948986411094666,0.0027670192066580057,0.0550772063434124,0.06011224165558815,-0.011382448486983776,-0.05970146879553795,-0.0020631104707717896,0.05724240466952324,-0.019217422232031822,-0.02270633541047573,-0.010261614806950092,-0.024227803573012352,-0.06513351947069168,-0.045641448348760605,-0.02925485372543335,0.045519690960645676,0.03908408805727959,-0.01385211106389761,-0.011837645433843136,0.04138373211026192,3.2393759465776384E-4,0.06466221809387207,-0.006086475681513548,0.004532589111477137,-0.032000843435525894,-0.027872296050190926,0.025157727301120758,-0.03402906283736229,0.0048818644136190414,0.02413642592728138,-0.03403536230325699,0.02382984757423401,0.018131323158740997,0.0268304031342268,0.07409346103668213,0.011736016720533371,0.08527874201536179,0.017376763746142387,-0.024096980690956116,-0.017889270558953285,-0.008894682861864567,-0.0691463053226471,-0.006752459332346916]]                                              |\n",
            "|[[0.025087259709835052,0.019540786743164062,0.03865920379757881,0.013494082726538181,-0.023396629840135574,0.023600708693265915,-0.029790636152029037,0.0020487532019615173,-0.0035479941871017218,-0.036133091896772385,-0.0475432313978672,0.034643448889255524,-0.008672189898788929,-0.006362988613545895,-0.02150685526430607,-0.049794986844062805,-0.010520443320274353,0.018102847039699554,0.0689232125878334,0.011246138252317905,0.011703019961714745,0.01639612391591072,-0.013367678038775921,-0.011201073415577412,-0.005450015887618065,-0.014489333145320415,-0.04528455436229706,-0.02597828395664692,-0.01811404339969158,0.05015546828508377,-0.018819520249962807,-0.012404652312397957,0.006562575697898865,-0.020874477922916412,-0.016068467870354652,-0.003309159306809306,-0.026245739310979843,-0.041499264538288116,0.013347196392714977,-0.011130371131002903,-0.003975993487983942,0.03271770849823952,-0.025533314794301987,0.012231191620230675,-7.907519466243684E-4,-0.0049511222168803215,-0.03706665709614754,-0.042856574058532715,0.04134992137551308,0.0024263658560812473,-0.010025103576481342,-0.05184904485940933,0.042039018124341965,0.030439067631959915,0.028007863089442253,-0.0458882600069046,-0.012716648168861866,0.04740121588110924,-0.005736249033361673,-0.01571422442793846,0.0561857707798481,0.0025490340776741505,-0.02030571922659874,-0.01980743743479252,0.0024799974635243416,0.02115853875875473,-0.015621762722730637,-0.03793667256832123,-0.008945053443312645,-0.03148471936583519,0.002778389258310199,-0.04130881652235985,0.012373048812150955,-0.002306872745975852,-0.01839510165154934,-0.028405029326677322,0.04822411388158798,0.028502177447080612,-0.002453734166920185,-4.221729759592563E-4,0.020811626687645912,6.12210831604898E-4,-0.0031280231196433306,4.949753638356924E-4,-0.013063237071037292,-0.02282514050602913,0.036235831677913666,0.0389862060546875,0.006619215942919254,-0.005558934062719345,-0.005634240340441465,0.01814570464193821,0.024655790999531746,0.05642728507518768,-0.01702691800892353,0.005424967035651207,0.02793317474424839,-0.017277410253882408,-0.035858940333127975,-0.01944907009601593]]                           |\n",
            "|[[-0.01741163060069084,0.007693518418818712,0.005249429494142532,-0.010091371834278107,-0.03616007789969444,0.01252355519682169,-0.031334564089775085,0.018766537308692932,0.002407348481938243,-0.03600257635116577,-0.024790246039628983,0.01941411755979061,-0.007452679798007011,-0.007326184771955013,-0.007865618914365768,-0.018493900075554848,0.008793535642325878,0.005463034845888615,0.02081308886408806,0.0035336692817509174,0.019665958359837532,-0.0036079352721571922,0.006613868288695812,-0.017137741670012474,-0.021663011983036995,0.014788124710321426,0.016322113573551178,-0.010857438668608665,-0.013081647455692291,0.024179967120289803,0.0011845446424558759,-0.024425083771348,-0.010137764737010002,0.004178731236606836,-0.0176713690161705,0.0039488025940954685,-0.005848976317793131,-0.021149612963199615,-0.021571040153503418,-0.0020107540767639875,0.017129801213741302,0.002657444914802909,0.004967453423887491,0.008060057647526264,0.008731361478567123,0.00453269574791193,-0.008302212692797184,-0.021923493593931198,-0.016854990273714066,-0.011867411434650421,0.02361898124217987,-0.012582117691636086,0.02359185367822647,-0.0021536170970648527,-0.013172189705073833,-0.017573172226548195,0.007156606297940016,0.009015687741339207,-7.675377128180116E-5,-0.010611342266201973,-0.010746341198682785,0.0018665461102500558,-0.004651552997529507,-0.019885296002030373,0.016336720436811447,0.009306642226874828,0.01660182885825634,0.005198407452553511,0.007658738177269697,-0.02525346726179123,-0.006111910566687584,-0.007463082671165466,0.006478003226220608,-8.878108928911388E-4,-0.009243037551641464,-0.01190309040248394,-0.0065711550414562225,-0.006961528677493334,0.007725400384515524,0.0027120495215058327,0.020335091277956963,-0.016437659040093422,-0.015139145776629448,0.01383781898766756,-0.010922124609351158,-0.014883388765156269,-0.004898763727396727,-0.011007343418896198,0.0036387285217642784,-0.010300352238118649,-0.019023355096578598,0.0021394838113337755,0.021709948778152466,0.005387299694120884,0.002778159687295556,-0.007530251517891884,-0.016445718705654144,0.007956563495099545,-0.009591903537511826,0.006999334320425987]]       |\n",
            "|[[-0.012260980904102325,0.007014045026153326,0.015350468456745148,-0.03853112459182739,-0.019605372101068497,0.047999486327171326,-0.04955616220831871,0.0430697426199913,0.025388741865754128,-0.037713874131441116,0.006380405277013779,0.040376435965299606,-0.02761559933423996,0.05073981732130051,0.004033019300550222,0.026609240099787712,0.03484324738383293,-0.03199880197644234,0.014892651699483395,-0.0456894226372242,0.04630798473954201,-0.010487627238035202,0.027020525187253952,0.01731684058904648,-0.00797862559556961,0.049893952906131744,0.02900041453540325,-0.005853330250829458,-0.022658970206975937,-0.01782567799091339,0.02207738161087036,-0.047099336981773376,0.022076403722167015,0.0352659747004509,-0.006680172402411699,-0.027086040005087852,-0.008490742184221745,-0.013569670729339123,-0.004185204394161701,0.014413281343877316,0.03372880071401596,0.002448511542752385,0.014683224260807037,0.029567426070570946,-0.019901618361473083,-0.006749589927494526,0.0017505622236058116,-0.05988333001732826,-0.031403400003910065,-0.01122756116092205,0.04356829449534416,0.02191891334950924,0.016560224816203117,-0.001126043382100761,-0.040040213614702225,0.028443152084946632,-0.0070595345459878445,0.015320043079555035,0.015964755788445473,0.009291896596550941,0.02159014157950878,-0.020333493128418922,-0.01819959469139576,-0.004281578119844198,4.059683997184038E-4,0.0023415356408804655,-0.008262792602181435,0.022153763100504875,0.006885102484375238,0.002990598324686289,0.006468925159424543,-0.02867179922759533,-0.019281620159745216,0.011469348333775997,-0.006522044073790312,-0.0015789426397532225,-0.034649766981601715,-0.029903804883360863,-0.022204017266631126,0.013820708729326725,0.05286017805337906,-0.01561862975358963,-0.02514202706515789,0.035980816930532455,0.0060865911655128,-0.0051545025780797005,0.015862509608268738,0.00450777867808938,-0.02486676722764969,0.023072203621268272,-0.06854183971881866,-0.01749216392636299,-0.004854429513216019,0.01179727166891098,0.011883345432579517,-0.02300427481532097,-0.02508964017033577,0.03197759762406349,0.04865078255534172,0.003286234801635146]]                                          |\n",
            "|[[-0.013957151211798191,0.008490536361932755,0.02404138632118702,0.00828858558088541,-0.032897207885980606,0.01541904266923666,-0.04878188297152519,0.019200725480914116,-0.011335670948028564,-0.04522320628166199,-0.03738570958375931,0.03460067883133888,-0.007022716570645571,0.011160559952259064,-0.016111792996525764,-0.008808616548776627,-0.019006451591849327,0.026662545278668404,0.039467953145504,0.00554601801559329,0.00989880133420229,-0.01848190650343895,-0.004514138214290142,-0.003074065549299121,-0.014020338654518127,-0.01693444512784481,-0.007978156208992004,-0.034275420010089874,-0.029401540756225586,0.017005229368805885,-0.0189975593239069,-0.017667138949036598,-0.006116707343608141,-0.007957189343869686,-0.031244643032550812,-0.003160220803692937,-0.019096920266747475,-0.02676289714872837,-2.4565242347307503E-4,-0.01647254452109337,0.025495702400803566,0.02491804026067257,-0.013161261565983295,0.008725294843316078,-0.0029237261041998863,-0.0070716142654418945,-0.02570982277393341,-0.02734292298555374,0.02336285077035427,-8.101382409222424E-4,-1.4283519703894854E-4,-0.01926412247121334,0.02489534765481949,0.032615888863801956,0.0037615171167999506,-0.036788735538721085,-0.021079132333397865,0.0049273367039859295,-0.007731861900538206,0.021568767726421356,0.036950428038835526,-0.0037456636782735586,-0.026650646701455116,8.021891117095947E-4,0.01956581138074398,0.0033793447073549032,-0.019147289916872978,-0.022708812728524208,-0.02123570442199707,-0.021659081801772118,-0.014885206706821918,-0.026447787880897522,0.023658709600567818,0.01608753763139248,-0.005202135536819696,-0.019914060831069946,0.025415785610675812,0.015240608714520931,0.034615449607372284,-0.013332572765648365,0.013452235609292984,-0.011941791512072086,-0.0158526748418808,0.004224447533488274,-0.017739849165081978,-0.010548216290771961,-0.002399015473201871,-0.010694765485823154,5.415105842985213E-4,0.023147350177168846,0.002786630764603615,0.039261531084775925,0.008154583163559437,0.04076278582215309,-0.0028759967535734177,-0.0034581900108605623,-0.0019009477691724896,0.0034616661723703146,-0.017397867515683174,0.0023613034281879663]]           |\n",
            "|[[-0.05106782913208008,0.030931081622838974,0.02937937155365944,0.0034531541168689728,-0.06427762657403946,0.018559139221906662,-0.12316347658634186,0.012117601931095123,-0.02574945241212845,-0.12402793765068054,-0.134189635515213,0.11507869511842728,0.01899157278239727,0.04466249793767929,-0.03282740339636803,-0.03970879316329956,-0.03888143226504326,0.06819573044776917,0.11025688052177429,0.0387733057141304,-0.026107508689165115,-0.034007683396339417,-0.03798384219408035,0.01875126361846924,-0.03604009002447128,-0.07904104143381119,-0.05598893761634827,-0.10660351812839508,-0.10673190653324127,0.06785356998443604,-0.04386409372091293,-0.0460861399769783,0.005453236401081085,-0.04364709183573723,-0.11702311038970947,-0.01946376822888851,-0.05919359624385834,-0.08605101704597473,-0.013312624767422676,-0.029299113899469376,0.0493057556450367,0.08645393699407578,-0.015397319570183754,-0.010186411440372467,0.005907320883125067,-0.023513810709118843,-0.08126386255025864,-0.07092597335577011,0.09749554097652435,-0.020455386489629745,-0.05637113377451897,-0.06574929505586624,0.04313249886035919,0.10317160189151764,0.0063520148396492004,-0.11215870082378387,-0.05894443020224571,0.03393489867448807,0.017514416947960854,0.08611290156841278,0.11852076649665833,-0.023132698610424995,-0.10133258253335953,0.027339452877640724,0.06033914163708687,-0.03631586581468582,-0.06178474798798561,-0.04971090331673622,-0.042926125228405,-0.07632602751255035,-0.05830623209476471,-0.057571496814489365,0.06130508333444595,0.06586527824401855,-0.016359597444534302,-0.02377363294363022,0.07702278345823288,0.014182481914758682,0.0828126072883606,-0.00851424876600504,-0.019979367032647133,-0.04860372841358185,-0.03232748433947563,0.023445118218660355,-0.04235319048166275,0.013747746124863625,0.05238214135169983,-0.021989990025758743,0.03252263739705086,0.052358776330947876,0.052974723279476166,0.11963382363319397,0.001286100596189499,0.12675702571868896,0.031064201146364212,-0.030398791655898094,-0.004372713156044483,-0.015467251650989056,-0.07844199240207672,-0.010081523098051548]]                                                                     |\n",
            "|[[-0.010229256004095078,0.007384082768112421,0.005491168238222599,-0.005139114800840616,-0.029254266992211342,0.008394268341362476,-0.022382594645023346,0.01474362425506115,0.0018008813494816422,-0.022241827100515366,-0.018121466040611267,0.009111321531236172,-0.0069168321788311005,-0.015619821846485138,-0.008602562360465527,-0.02053724229335785,7.643122225999832E-4,0.007075057365000248,0.029189888387918472,0.007037139963358641,0.02441747672855854,-0.006718885153532028,0.006911626551300287,-0.009915170259773731,-0.016221169382333755,0.0015496554551646113,0.0149845527485013,-0.011660064570605755,-0.008123818784952164,0.02568083442747593,0.0010144340340048075,-0.0046072714030742645,-0.013310746289789677,0.0015217072796076536,-0.01432416308671236,0.005493584554642439,-0.005361682269722223,-0.015157616697251797,-0.013233744539320469,-0.008306663483381271,0.006421864498406649,0.004065818153321743,0.0018418732797726989,0.008869859389960766,7.313096430152655E-4,-0.003733475459739566,-0.005436682607978582,-0.015070009976625443,-0.008184450678527355,-0.01309968065470457,0.020113689824938774,-0.011182833462953568,0.026317810639739037,-0.002507503144443035,-0.002320950385183096,-0.022214921191334724,0.0033867578022181988,0.006092981435358524,8.860583329806104E-5,-0.010678330436348915,-0.0071433247067034245,0.004876977298408747,-0.001670084078796208,-0.013584083877503872,0.006749559193849564,0.016762426123023033,0.017119308933615685,-0.0019623569678515196,0.005982363596558571,-0.016395162791013718,-0.0055718934163451195,-0.010242014192044735,0.00830292422324419,-7.83280935138464E-4,-0.004816605243831873,-0.017910057678818703,-0.0038299765437841415,0.0014097725506871939,0.015047772787511349,-0.003404313698410988,0.016930444166064262,-0.0180777870118618,-0.012823861092329025,-0.0011300648329779506,-0.006293189246207476,-0.012197472155094147,-0.00850218627601862,-0.014865848235785961,0.003768590046092868,-0.00476802745833993,-0.01923111267387867,0.010322000831365585,0.015562821179628372,0.008765733800828457,4.50649531558156E-4,-0.002324335975572467,-0.007271911948919296,0.002481623087078333,-0.008999472483992577,0.014224052429199219]]|\n",
            "|[[-0.0011510386830195785,0.011750021949410439,0.0023320571053773165,0.002253949409350753,-0.03172028437256813,0.028442902490496635,-0.04621721804141998,0.014944421127438545,-0.01549345999956131,-0.04763074964284897,-0.015909582376480103,0.032500866800546646,-0.015443249605596066,0.025985825806856155,-0.0015827043680474162,0.0015420254785567522,-0.015318064950406551,0.03498882055282593,0.01575610041618347,0.007773259188979864,-0.001554624643176794,-0.004448144230991602,-0.01182528119534254,-0.013124284334480762,-0.011295473203063011,0.006835979409515858,0.005061656702309847,-0.023223308846354485,-0.023551182821393013,-0.006544958800077438,-0.013112331740558147,-0.02099710702896118,-0.0015375363873317838,-0.0039917826652526855,-0.016649750992655754,0.0015443748561665416,-0.0073833889327943325,-0.02957972325384617,-0.003490051254630089,0.0036837481893599033,0.02133464813232422,-0.006446288898587227,0.011344442144036293,0.00887676328420639,0.0027511538937687874,-0.009410041384398937,-0.02542366459965706,-0.014271685853600502,0.015097216702997684,-0.014389097690582275,0.022336415946483612,-0.0047475979663431644,0.01956983283162117,0.02429269626736641,0.0028733161743730307,-0.006838294677436352,-0.01582001894712448,0.004168176557868719,-0.0023874191101640463,0.015174906700849533,0.026335986331105232,-0.010128924623131752,-0.025124160572886467,7.032771245576441E-4,0.0211282130330801,0.013722915202379227,-0.01159979123622179,-0.02241595834493637,-0.046921804547309875,-0.015470100566744804,-0.0026929008308798075,-0.02073602005839348,0.014183968305587769,0.0049377623945474625,-0.021541323512792587,-0.02329735830426216,0.021407946944236755,0.0019628172740340233,0.03068525530397892,-0.01711629517376423,0.01290541049093008,-0.012604568153619766,-0.013772211968898773,0.015266201458871365,-0.026324691250920296,-0.007620928809046745,-0.01151239313185215,-0.015188595280051231,-4.176846123300493E-4,0.015242519788444042,-0.006680952850729227,0.018007101491093636,0.00549653172492981,0.03324434161186218,-0.0026667993515729904,0.005971768405288458,-0.005703540984541178,0.01348626147955656,-0.010318880900740623,4.988375585526228E-4]]         |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 15 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vector_length = embeddings.getVectorSize()\n",
        "\n",
        "print(f'Embeddings dimension is set to {vector_length}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHR7Hbf28XO_",
        "outputId": "d319799e-47d3-49c0-982c-856c9509cc8b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embeddings dimension is set to 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# explode the resulting column and transform to a vector\n",
        "result_df = df_embeddings.select(col('sarcastic').alias('label'),\n",
        "                                 explode(df_embeddings.finished_sentence_embeddings).alias('features'))\\\n",
        "                          .withColumn(\"features\", vector_to_array(\"features\"))"
      ],
      "metadata": {
        "id": "kUjg6Ke6DtAx"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtpJg38tD64I",
        "outputId": "5d322756-92c1-46ab-8758-85b679c5094f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------------+\n",
            "|label|            features|\n",
            "+-----+--------------------+\n",
            "|    0|[-0.0254239886999...|\n",
            "|    0|[0.01708064414560...|\n",
            "|    1|[-0.0420452132821...|\n",
            "|    0|[-0.0319583863019...|\n",
            "|    1|[-0.0137873692438...|\n",
            "+-----+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# split the vector \n",
        "df_expr = result_df.select(['label']+[expr('features[' + str(x) + ']') for x in range(vector_length)])"
      ],
      "metadata": {
        "id": "Hu4FQolGEyVE"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_expr.cache()\n",
        "df_expr.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3icjC9rH2Q6",
        "outputId": "2ff00be3-c05b-4dc9-9bc6-42925a4a88f1"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|label|         features[0]|         features[1]|         features[2]|         features[3]|         features[4]|         features[5]|         features[6]|         features[7]|         features[8]|         features[9]|        features[10]|        features[11]|        features[12]|        features[13]|        features[14]|        features[15]|        features[16]|        features[17]|        features[18]|        features[19]|        features[20]|        features[21]|        features[22]|        features[23]|        features[24]|        features[25]|        features[26]|        features[27]|        features[28]|        features[29]|        features[30]|        features[31]|        features[32]|        features[33]|        features[34]|        features[35]|        features[36]|        features[37]|        features[38]|        features[39]|        features[40]|        features[41]|        features[42]|        features[43]|        features[44]|        features[45]|        features[46]|        features[47]|        features[48]|        features[49]|        features[50]|        features[51]|        features[52]|        features[53]|        features[54]|        features[55]|        features[56]|        features[57]|        features[58]|        features[59]|        features[60]|        features[61]|        features[62]|        features[63]|        features[64]|        features[65]|        features[66]|        features[67]|        features[68]|        features[69]|        features[70]|        features[71]|        features[72]|        features[73]|        features[74]|        features[75]|        features[76]|        features[77]|        features[78]|        features[79]|        features[80]|        features[81]|        features[82]|        features[83]|        features[84]|        features[85]|        features[86]|        features[87]|        features[88]|        features[89]|        features[90]|        features[91]|        features[92]|        features[93]|        features[94]|        features[95]|        features[96]|        features[97]|        features[98]|        features[99]|\n",
            "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|    0|-0.02542398869991...|0.009470736607909203|0.005137912463396788|-0.00351363164372...|-0.03794898465275...|0.015587643720209599| -0.0473012700676918|0.021750489249825478|-0.00369196641258...|-0.04947682097554207|-0.03305191174149513| 0.03620591759681702|-0.00303693208843...|0.007895741611719131|-0.00791501533240...|-0.01117664948105812|-0.00355572346597...| 0.01832418330013752| 0.02849573642015457|0.007954251952469349|0.014168589375913143|-0.01703066006302...|-0.00106931186746...|-0.00932525936514...|-0.02296206541359...|-0.00216292543336...|0.011585361324250698|-0.02709889225661...| -0.0331214964389801|0.017744140699505806|-0.00532779050990...|-0.02809751592576...|-0.01081523858010...|-0.00310204527340...|-0.03306630998849869|0.003584994468837...|-0.01249725185334...| -0.0267027597874403|-0.01576865278184414|-0.00930319540202...|0.025882987305521965|0.013128508813679218|0.004462534561753273|0.003796216798946...|0.006859034299850464|-0.00218785414472...|-0.01478959433734417|-0.02647942304611206|0.002407524967566...|-0.01329812780022...| 0.01643352583050728|-0.01117309369146...|0.021443994715809822|0.013992861844599247|-0.01323818787932396|-0.02792682871222496|-0.00760651612654...|  0.0051385797560215|-0.00264975731261...|0.013838939368724823|0.011402172967791557|-0.00690417177975...|-0.02125011011958...|-0.00930613558739...|0.026774585247039795|0.003571799956262...|7.398598245345056E-4|-5.02142589539289...|-0.01230051834136...|-0.02933113463222...|-0.01766788400709629|-0.01419457141309...|0.016059979796409607|0.010428404435515404|-0.01016427855938673|-0.01310459710657...|0.003053995547816...|-0.00507941702380...|0.028709376230835915|-0.00305774156004...|0.018289070576429367|-0.01716695539653...|-0.01802903600037098|0.014862715266644955|-0.01691289246082306|-0.00718421395868063|-0.00607922486960...|-0.02445472031831...|0.005661380477249622|0.008091789670288563|-0.00791633129119873|0.021418944001197815|0.012477811425924301|  0.0251704640686512|0.005367986857891083|-0.00931058544665575|-0.01767513342201...|0.008770938962697983|-0.01761908456683159| 0.00704982690513134|\n",
            "|    0| 0.01708064414560795|0.014206066727638245|0.029749209061264992|-0.00429637636989...|-0.03052658587694168|0.018801912665367126|-0.01028735749423...|0.009226358495652676|0.008807494305074215|-0.02100674062967...|-0.02345531992614...|0.006453792098909...|-0.02629614621400833|-0.02739410474896431|-0.01613870449364...|-0.04400443658232689|0.012572766281664371|0.001768490648828...| 0.04174619913101196|-8.39832238852977...|0.028157422319054604|0.024590885266661644|0.008505136705935001|-0.02615215256810...|-0.00903763156384...|0.025803618133068085|-0.00597174558788538|0.002556930994614...| 0.01657864823937416| 0.04388829693198204|-0.00558725371956...|-0.01556641422212...|-0.00585564831271...|-0.00134197447914...|0.005112984217703...|0.003492061514407...|-0.00223160791210...|-0.02515976876020...|-0.00832104962319...|-2.53555132076144...|-0.00476870825514...|8.728490793146193E-4|-0.01688118278980255|  0.0249074287712574| 0.00470349658280611|0.010943465866148472|-0.01763851940631...|-0.02477335371077...|-0.01282706204801...|1.054805470630526...|0.024071432650089264|-0.03187162429094...|  0.0417817048728466|-0.00853381119668...|0.016295399516820908|-0.01865602098405...|0.020864326506853104|0.029468577355146408|-0.00735437870025...|-0.05158591270446777|-0.00520213367417...|0.010635482147336006| 0.00782795250415802|-0.03485901653766632|-0.00259277573786...| 0.03192541003227234| 0.02148476429283619|-0.02318263053894043|0.012930203229188919|-0.02550434507429...|0.012069505639374256|-0.02217037789523...|-0.00202868762426...|-0.02148976549506...|-0.01647311821579933|-0.03274351730942726|0.013148127123713493|0.013281027786433697|-0.02104034833610058|0.005738272797316313| 0.03206782415509224|-0.00322276004590...|-0.00744396587833...|0.001828765962272...|-0.00568082276731...|-0.03886869177222252| 0.00782687496393919| 0.03322911635041237|0.003859894350171089|-0.02535753324627...|-0.03481787815690...|-0.01825814880430...| 0.03933516889810562|0.009620471857488155|-0.01793560199439...|0.006581405177712...|0.014785386621952057|-0.00264927558600...|-0.01010849047452...|-0.00326404185034...|\n",
            "|    1|-0.04204521328210831|0.011024787090718746| 0.00845038890838623|-0.00740163633599...|-0.05592026188969612|0.011522707529366016|-0.05530001595616...| 0.03191670775413513|-0.00426089949905...|-0.05046072974801...|-0.05267751216888428|0.028784099966287613|0.001528050284832716|-0.02324824407696724|-0.01602635346353054|-0.03638245165348053|0.003057508496567607|0.013669351115822792| 0.05224304646253586| 0.01657070219516754|0.027405887842178345|-0.01995833218097...|0.010237550362944603|-0.01420065388083458|-0.04298542812466...|-0.00681020319461...|  0.0244801864027977|-0.03569038584828377|-0.03802857920527458| 0.05093635618686676|-0.00134875136427...|-0.02403648942708969|-0.02710605226457119|-0.00163143000099...|-0.04588667675852...|0.005605172831565142|-0.01597164012491703|-0.03265159204602...|-0.03378286957740784|-0.01583659462630...|0.027206923812627792|0.018942857161164284|0.005394039675593376|0.001105193980038166|0.009883887134492397|-0.00287169008515...|-0.01312636211514473|-0.03071986883878708|-0.01143553294241...|-0.02383330464363098| 0.02004014328122139|-0.02616643905639...| 0.04305296763777733|0.005915173329412937|-0.01890760287642479|-0.05705492198467...|-8.09967983514070...|0.005097059532999992|0.001507401233538...|0.003260314930230379|-0.01124897412955761| 0.00904424861073494|-0.00931834522634...|-0.02001703158020...|0.027964383363723755|0.006362750194966793| 0.02954857423901558|0.006969080306589603|0.014156747609376907|-0.03898143023252487|-0.02118277549743...|-0.01677031628787...| 0.02276831679046154|0.010749703273177147|-0.00464932015165...|-0.01867369934916...|-0.00868728198111...|-0.00610424019396...|  0.0358390174806118|-0.00124010350555...|0.022756371647119522|-0.03534648194909096|-0.02814159542322...|0.008051129058003426|-0.01648316346108...|-0.01089332904666...|-0.01325818523764...|-0.03540926054120064|0.010875366628170013|-0.00689763715490...|-0.01758354343473...|0.030078787356615067|0.021577665582299232| 0.01749844290316105| 0.00820137932896614|-0.01350611541420...|-0.02530426532030...|0.004973471164703369|-0.02856498025357...| 0.02309395931661129|\n",
            "|    0|-0.03195838630199...|0.009085196070373058|0.013885668478906155|-0.01389739941805...|-0.04162388294935...|0.012329819612205029|-0.05576954409480095|0.022440442815423012|-0.00555131630972...|-0.04578797519207001|-0.04522811993956566|0.030400089919567108|-0.00218341243453...|0.006648262497037649| -0.0115028852596879|-0.01346262264996767| -0.0034992431756109|0.015352848917245865| 0.04782600700855255|0.006523722317069769|0.013972935266792774|-0.01377031672745943|0.005291072651743889|0.009860356338322163|-0.01903349161148...|-0.01750878058373928|0.010519415140151978|-0.03512465581297...|-0.03288209065794945| 0.03151160851120949|-0.00726205669343...|-0.01980333961546421|-0.01087641716003418|-0.00349260005168...|-0.04021668061614...|-0.01105976756662...|-0.01604765653610...|-0.03223619237542...|-0.01543038804084...|-0.00405098730698...|0.022357450798153877|0.022447459399700165|0.006240889430046...|0.004214756656438112|-0.00251152366399765|-0.01471254695206...|-0.02377277612686...|-0.02857315354049...| 0.00908359419554472|-0.02100809104740...|0.004075068980455...|-0.01896905712783...|0.030987737700343132| 0.02385818026959896|-0.01250060927122...|-0.03813734278082...|-0.01241488661617...|0.007494504097849131|0.015163195319473743|0.017404597252607346|0.021392904222011566|-0.00238252803683...|-0.02757400088012...|0.004434279631823301|0.017032595351338387|-0.00470020109787...|-0.00134890340268...|-0.00590086355805397|0.002410774817690...|-0.02245799638330...|-0.02081108279526...|-0.02524320222437...|0.015108407475054264|0.019999012351036072|-0.00756400777027...|-0.01435189414769...|0.004931750241667032|-0.00583996996283...| 0.02900238148868084|-0.00170445663388...|0.007275795564055443|-0.03438493236899376|-0.02716999314725399|0.005453612189739...|-0.00990337785333395| 6.48949237074703E-4|0.007934718392789364|-0.02131487429141...| 0.00631573935970664|0.014980143867433071|-0.00590197229757905| 0.04461272433400154|0.001177006284706...|0.029503995552659035| 0.01841401867568493|-0.01444800291210413|-0.01325517147779...|0.001280368189327...|-0.01392407249659...|0.018341274932026863|\n",
            "|    1|-0.01378736924380064| 0.00713732372969389|0.006271126214414835|-0.00623265141621232|-0.02622748911380...|0.001438104780390...|-0.01937903091311...| 0.00994428712874651| 0.00264269532635808|-0.02906251512467...|-0.02160540036857128|0.014490860514342785|-0.00472475215792...|-0.00823023635894...|-0.00794135872274...|-0.01597614027559...| 9.25292435567826E-4| 0.00860561989247799|0.024137932807207108|0.004041346721351147| 0.01883048005402088|-0.00532658863812685|0.001602549687959...|-0.01260249782353...|-0.00811027735471...|0.001098723965696...|0.003883959027007222|-0.01278942544013...|-0.00854344759136...|0.023706089705228806|-0.00411377009004...|-0.01520661450922...|-0.00557610671967268|-0.00316868466325...|-0.02266389876604...|0.003315092530101...|-0.00603368738666...|-0.01382055133581...|-0.01411242969334...|-0.01021938212215...|0.011305167339742184|0.012209273874759674|-0.00239664549008...|0.005738550331443548|0.006356913596391678|0.003565865103155...|-0.00672111380845...|-0.01375662069767...|-0.00174060498829...|-0.00746055040508...| 0.00831218995153904|-0.01263973861932...|0.016371257603168488| 0.00518811447545886|-0.00350491655990...|-0.02090091630816...|0.002931516384705901|0.008529731072485447|0.001177658210508...|-0.00848555378615...|0.001974130980670452|-0.00206833099946...|-0.01054567843675...|-0.00990117713809...|0.009033777751028538|0.006012294441461563|0.006609581410884857|-0.00493280217051506|0.007728769443929195|-0.02231196686625...|-0.00946427136659...|-0.00619248766452...|0.005636558867990971|0.006729389540851116|-0.00275129755027...|-0.01523521263152361|-3.42047947924584...|-0.00180898758117...|0.011739932000637054|0.002571512013673...|0.013237659819424152|-0.01533831190317...|-0.01218863576650...| 0.00864667259156704|-9.58522781729698...|-0.01300434302538...|0.004363876301795244|-0.00792350433766...|0.006623761262744665|4.732855013571679...|-0.00811595469713211|0.012086011469364166|0.017315026372671127|0.010074399411678314|0.006288859993219376|-0.00758778024464...|-0.00798297859728...|0.002266144612804055|-0.00913247652351...|0.006439292337745428|\n",
            "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cast each column to float\n",
        "for col_name in df_expr.columns:\n",
        "  df_expr = df_expr.withColumn(col_name, col(col_name).cast(FloatType()))"
      ],
      "metadata": {
        "id": "sTgRdVmrNFcg"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_expr.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtvuCAthLnOz",
        "outputId": "9db10205-05a1-4746-982f-485af5dd8671"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- label: float (nullable = true)\n",
            " |-- features[0]: float (nullable = true)\n",
            " |-- features[1]: float (nullable = true)\n",
            " |-- features[2]: float (nullable = true)\n",
            " |-- features[3]: float (nullable = true)\n",
            " |-- features[4]: float (nullable = true)\n",
            " |-- features[5]: float (nullable = true)\n",
            " |-- features[6]: float (nullable = true)\n",
            " |-- features[7]: float (nullable = true)\n",
            " |-- features[8]: float (nullable = true)\n",
            " |-- features[9]: float (nullable = true)\n",
            " |-- features[10]: float (nullable = true)\n",
            " |-- features[11]: float (nullable = true)\n",
            " |-- features[12]: float (nullable = true)\n",
            " |-- features[13]: float (nullable = true)\n",
            " |-- features[14]: float (nullable = true)\n",
            " |-- features[15]: float (nullable = true)\n",
            " |-- features[16]: float (nullable = true)\n",
            " |-- features[17]: float (nullable = true)\n",
            " |-- features[18]: float (nullable = true)\n",
            " |-- features[19]: float (nullable = true)\n",
            " |-- features[20]: float (nullable = true)\n",
            " |-- features[21]: float (nullable = true)\n",
            " |-- features[22]: float (nullable = true)\n",
            " |-- features[23]: float (nullable = true)\n",
            " |-- features[24]: float (nullable = true)\n",
            " |-- features[25]: float (nullable = true)\n",
            " |-- features[26]: float (nullable = true)\n",
            " |-- features[27]: float (nullable = true)\n",
            " |-- features[28]: float (nullable = true)\n",
            " |-- features[29]: float (nullable = true)\n",
            " |-- features[30]: float (nullable = true)\n",
            " |-- features[31]: float (nullable = true)\n",
            " |-- features[32]: float (nullable = true)\n",
            " |-- features[33]: float (nullable = true)\n",
            " |-- features[34]: float (nullable = true)\n",
            " |-- features[35]: float (nullable = true)\n",
            " |-- features[36]: float (nullable = true)\n",
            " |-- features[37]: float (nullable = true)\n",
            " |-- features[38]: float (nullable = true)\n",
            " |-- features[39]: float (nullable = true)\n",
            " |-- features[40]: float (nullable = true)\n",
            " |-- features[41]: float (nullable = true)\n",
            " |-- features[42]: float (nullable = true)\n",
            " |-- features[43]: float (nullable = true)\n",
            " |-- features[44]: float (nullable = true)\n",
            " |-- features[45]: float (nullable = true)\n",
            " |-- features[46]: float (nullable = true)\n",
            " |-- features[47]: float (nullable = true)\n",
            " |-- features[48]: float (nullable = true)\n",
            " |-- features[49]: float (nullable = true)\n",
            " |-- features[50]: float (nullable = true)\n",
            " |-- features[51]: float (nullable = true)\n",
            " |-- features[52]: float (nullable = true)\n",
            " |-- features[53]: float (nullable = true)\n",
            " |-- features[54]: float (nullable = true)\n",
            " |-- features[55]: float (nullable = true)\n",
            " |-- features[56]: float (nullable = true)\n",
            " |-- features[57]: float (nullable = true)\n",
            " |-- features[58]: float (nullable = true)\n",
            " |-- features[59]: float (nullable = true)\n",
            " |-- features[60]: float (nullable = true)\n",
            " |-- features[61]: float (nullable = true)\n",
            " |-- features[62]: float (nullable = true)\n",
            " |-- features[63]: float (nullable = true)\n",
            " |-- features[64]: float (nullable = true)\n",
            " |-- features[65]: float (nullable = true)\n",
            " |-- features[66]: float (nullable = true)\n",
            " |-- features[67]: float (nullable = true)\n",
            " |-- features[68]: float (nullable = true)\n",
            " |-- features[69]: float (nullable = true)\n",
            " |-- features[70]: float (nullable = true)\n",
            " |-- features[71]: float (nullable = true)\n",
            " |-- features[72]: float (nullable = true)\n",
            " |-- features[73]: float (nullable = true)\n",
            " |-- features[74]: float (nullable = true)\n",
            " |-- features[75]: float (nullable = true)\n",
            " |-- features[76]: float (nullable = true)\n",
            " |-- features[77]: float (nullable = true)\n",
            " |-- features[78]: float (nullable = true)\n",
            " |-- features[79]: float (nullable = true)\n",
            " |-- features[80]: float (nullable = true)\n",
            " |-- features[81]: float (nullable = true)\n",
            " |-- features[82]: float (nullable = true)\n",
            " |-- features[83]: float (nullable = true)\n",
            " |-- features[84]: float (nullable = true)\n",
            " |-- features[85]: float (nullable = true)\n",
            " |-- features[86]: float (nullable = true)\n",
            " |-- features[87]: float (nullable = true)\n",
            " |-- features[88]: float (nullable = true)\n",
            " |-- features[89]: float (nullable = true)\n",
            " |-- features[90]: float (nullable = true)\n",
            " |-- features[91]: float (nullable = true)\n",
            " |-- features[92]: float (nullable = true)\n",
            " |-- features[93]: float (nullable = true)\n",
            " |-- features[94]: float (nullable = true)\n",
            " |-- features[95]: float (nullable = true)\n",
            " |-- features[96]: float (nullable = true)\n",
            " |-- features[97]: float (nullable = true)\n",
            " |-- features[98]: float (nullable = true)\n",
            " |-- features[99]: float (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We know that our dataset is heavily unbalanced. Our network could be tempted to predict always the majority class. To avoid this we could apply a weigth to each class the discourages the network into predicting always 'non-sarcastic'."
      ],
      "metadata": {
        "id": "lKsbhjuPlmuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training a simple NN"
      ],
      "metadata": {
        "id": "TLWnDjOLqTvE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = df_expr.randomSplit([0.7,0.3], seed=1234)"
      ],
      "metadata": {
        "id": "UuV1Qgs3qYtI"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "network = nn.Sequential(\n",
        "    nn.Linear(100, 75),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(75, 50),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(50, 25),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(25, 2),\n",
        "    nn.Softmax(dim=1)\n",
        ")\n",
        "\n",
        "print(network)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TU4GQrVp1V4G",
        "outputId": "5c011287-cd7e-42a3-a3e8-e5098642fc49"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=100, out_features=75, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=75, out_features=50, bias=True)\n",
            "  (3): ReLU()\n",
            "  (4): Linear(in_features=50, out_features=25, bias=True)\n",
            "  (5): ReLU()\n",
            "  (6): Linear(in_features=25, out_features=2, bias=True)\n",
            "  (7): Softmax(dim=1)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the pytorch object\n",
        "torch_obj = serialize_torch_obj(\n",
        "    model=network,\n",
        "    criterion=nn.CrossEntropyLoss(weight=class_weights,reduction='mean'),\n",
        "    optimizer=torch.optim.Adam,\n",
        "    lr=0.001\n",
        ")\n",
        "\n",
        "# Setup features\n",
        "vector_assembler = VectorAssembler(inputCols=train.columns[1:], outputCol='features') \\\n",
        "                          .setHandleInvalid(\"skip\")\n",
        "\n",
        "# Create a SparkTorch Model with torch distributed. Barrier execution is on by default for this mode.\n",
        "spark_model = SparkTorch(\n",
        "    inputCol='features',\n",
        "    labelCol='label',\n",
        "    predictionCol='predictions',\n",
        "    torchObj=torch_obj,\n",
        "    iters=150,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "# Can be used in a pipeline and saved.\n",
        "nn_pipeline = Pipeline(stages=[vector_assembler, spark_model]).fit(train)\n",
        "nn_pipeline.save(DRIVE_FOLDER+\"nn_model\")\n",
        "nn_predictions = nn_pipeline.transform(test).select(['label','predictions'])"
      ],
      "metadata": {
        "id": "YMHNm_XvQHky"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nn_predictions.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dN63YvcHv9Q8",
        "outputId": "666d0e10-65fe-456d-eef8-c34637c13d84"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----------+\n",
            "|label|predictions|\n",
            "+-----+-----------+\n",
            "|  0.0|        1.0|\n",
            "|  0.0|        0.0|\n",
            "|  0.0|        0.0|\n",
            "|  0.0|        0.0|\n",
            "|  0.0|        0.0|\n",
            "|  0.0|        1.0|\n",
            "|  0.0|        0.0|\n",
            "|  0.0|        0.0|\n",
            "|  0.0|        0.0|\n",
            "|  0.0|        0.0|\n",
            "+-----+-----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = nn_predictions.select('predictions').toPandas()\n",
        "y_true = test.select('label').toPandas()\n",
        "clf_nn = classification_report(y_true=y_true, y_pred=y_pred, zero_division=0)\n",
        "print(clf_nn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vUBCymj9DDh",
        "outputId": "683cdc83-881c-4ef3-c3eb-ecf79a096a7d"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.82      0.78      0.80      1321\n",
            "         1.0       0.55      0.61      0.58       580\n",
            "\n",
            "    accuracy                           0.73      1901\n",
            "   macro avg       0.69      0.70      0.69      1901\n",
            "weighted avg       0.74      0.73      0.73      1901\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training a CNN"
      ],
      "metadata": {
        "id": "O5gt7wjcG1yN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# try a different approach to our imbalanced dataset: splitting the dataset \n",
        "train = df_expr.sampleBy('label', fractions={0.0: 0.5, 1.0:0.6})\n",
        "test = df_expr.subtract(train)"
      ],
      "metadata": {
        "id": "qJhXviaSm1pk"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train balancement:\")\n",
        "train.groupBy('label').count().show()\n",
        "\n",
        "print(\"Test balancement:\")\n",
        "test.groupBy('label').count().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9y0A_fU-sTYp",
        "outputId": "7c0d270a-640a-4277-b759-e861b1ee975c"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train balancement:\n",
            "+-----+-----+\n",
            "|label|count|\n",
            "+-----+-----+\n",
            "|  1.0| 1171|\n",
            "|  0.0| 2368|\n",
            "+-----+-----+\n",
            "\n",
            "Test balancement:\n",
            "+-----+-----+\n",
            "|label|count|\n",
            "+-----+-----+\n",
            "|  1.0|  762|\n",
            "|  0.0| 2236|\n",
            "+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = nn.Sequential(\n",
        "    nn.Conv1d(1, 1, kernel_size=4, stride=2),\n",
        "    nn.MaxPool1d(4),\n",
        "    nn.Conv1d(1, 1, kernel_size=4, stride=2),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool1d(2),\n",
        "    nn.Sigmoid()\n",
        ")\n",
        "print(cnn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "or893SbCG71d",
        "outputId": "a5889209-6156-4d83-c93b-b46e05fd6a9f"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Conv1d(32, 100, kernel_size=(4,), stride=(2,))\n",
            "  (1): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
            "  (2): Conv1d(8, 100, kernel_size=(4,), stride=(2,))\n",
            "  (3): ReLU()\n",
            "  (4): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (5): Sigmoid()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch_obj = serialize_torch_obj(\n",
        "    model=cnn,\n",
        "    criterion=nn.CrossEntropyLoss(weight=class_weights,reduction='mean'),\n",
        "    optimizer=torch.optim.Adam,\n",
        "    lr=0.001\n",
        ")\n",
        "\n",
        "vector_assembler = VectorAssembler(inputCols=train.columns[1:], outputCol='features') \\\n",
        "                          .setHandleInvalid(\"skip\")\n",
        "\n",
        "spark_model = SparkTorch(\n",
        "    inputCol='features',\n",
        "    labelCol='label',\n",
        "    predictionCol='predictions',\n",
        "    torchObj=torch_obj,\n",
        "    miniBatch=1,\n",
        "    iters=100,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "cnn_pipeline = Pipeline(stages=[vector_assembler, spark_model]).fit(train)\n",
        "cnn_pipeline.save(DRIVE+'cnn_model')\n",
        "cnn_predictions = cnn_pipeline.transform(test).select(['label','predictions'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZXLlJWNkHZro",
        "outputId": "8f4a470f-4d72-4b96-b51a-4f85397151be"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "error",
          "ename": "Py4JJavaError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-71-b2a68f7e7f9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mcnn_pipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvector_assembler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspark_model\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mcnn_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDRIVE_FOLDER\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'cnn_model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mcnn_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'predictions'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/ml/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# must be an Estimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m                     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m                     \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mindexOfLastEstimator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sparktorch/torch_distributed.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mworld_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitions\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m                 \u001b[0mearly_stop_patience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stop_patience\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m             )\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sparktorch/distributed.py\u001b[0m in \u001b[0;36mtrain_distributed\u001b[0;34m(rdd, torch_obj, iters, partition_shuffles, verbose, mini_batch, validation_pct, world_size, device, early_stop_patience)\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0;31m# Run model with barrier execution mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m             state_dict = mapPartitionsWithIndex(\n\u001b[0;32m--> 254\u001b[0;31m                 rdd, lambda i, x: handle_model(\n\u001b[0m\u001b[1;32m    255\u001b[0m                     \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/rdd.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    947\u001b[0m         \"\"\"\n\u001b[1;32m    948\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 949\u001b[0;31m             \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectAndServe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    950\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1305\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
            "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Could not recover from a failed barrier ResultStage. Most recent failure reason: Stage failed because barrier task ResultTask(55, 3) finished unsuccessfully.\norg.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/lib/python3.7/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 604, in main\n    process()\n  File \"/usr/local/lib/python3.7/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 594, in process\n    out_iter = func(split_index, iterator)\n  File \"/usr/local/lib/python3.7/dist-packages/pyspark/rdd.py\", line 2916, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/usr/local/lib/python3.7/dist-packages/sparktorch/distributed.py\", line 265, in <lambda>\n    early_stop_patience=int(early_stop_patience+0)\n  File \"/usr/local/lib/python3.7/dist-packages/sparktorch/distributed.py\", line 151, in handle_model\n    y_pred = model(x_train)\n  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\", line 141, in forward\n    input = module(input)\n  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\", line 302, in forward\n    return self._conv_forward(input, self.weight, self.bias)\n  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\", line 299, in _conv_forward\n    self.padding, self.dilation, self.groups)\nRuntimeError: Given groups=1, weight of size [100, 8, 4], expected input[1, 100, 12] to have 8 channels, but got 100 channels instead\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:517)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:652)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:635)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:470)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:315)\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:313)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:307)\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:307)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:294)\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:288)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1030)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2236)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2258)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2207)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2206)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2206)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:1968)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2442)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2387)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2376)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2196)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2217)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2236)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2261)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1030)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:414)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1029)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:180)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_predictions.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMsIgaoUuO8W",
        "outputId": "84758880-c542-4f92-b1e0-5b7e8d2356af"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----------+\n",
            "|label|predictions|\n",
            "+-----+-----------+\n",
            "|  0.0|        0.0|\n",
            "|  0.0|        0.0|\n",
            "|  0.0|        1.0|\n",
            "|  0.0|        0.0|\n",
            "|  0.0|        0.0|\n",
            "|  0.0|        0.0|\n",
            "|  0.0|        0.0|\n",
            "|  0.0|        0.0|\n",
            "|  0.0|        0.0|\n",
            "|  0.0|        0.0|\n",
            "+-----+-----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = cnn_predictions.select('predictions').toPandas()\n",
        "y_true = test.select('label').toPandas()\n",
        "clf_cnn = classification_report(y_true=y_true, y_pred=y_pred, zero_division=0)\n",
        "print(clf_cnn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uK_ScWWLMPNF",
        "outputId": "5b1dd9c9-a197-4801-e518-4ffb29a13aee"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.74      0.84      0.78      2236\n",
            "         1.0       0.20      0.12      0.15       762\n",
            "\n",
            "    accuracy                           0.65      2998\n",
            "   macro avg       0.47      0.48      0.46      2998\n",
            "weighted avg       0.60      0.65      0.62      2998\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bert"
      ],
      "metadata": {
        "id": "1RrWqgF8AuXU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will try to change the embedding methodology"
      ],
      "metadata": {
        "id": "_ADqn99Ixz40"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_bert = df.select('document','clean_lemma', col('sarcastic').alias('label'))"
      ],
      "metadata": {
        "id": "bFmBlf4ePNfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = BertEmbeddings.pretrained()\\\n",
        "              .setInputCols(\"document\", \"clean_lemma\")\\\n",
        "              .setOutputCol(\"embeddings\")\\\n",
        "              .setDimension(100)\n",
        "\n",
        "finisher = EmbeddingsFinisher()\\\n",
        "            .setInputCols(\"embeddings\")\\\n",
        "            .setOutputCols(\"embeddings_result\")"
      ],
      "metadata": {
        "id": "ZrXQbBUgsUP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "em_pipeline = Pipeline(stages=[embeddings, finisher])"
      ],
      "metadata": {
        "id": "27rkGJaQ23cq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_embedded = em_pipeline.fit(df_bert).transform(df_bert)\\\n",
        "                          .select(col('label').cast(FloatType()), explode(\"embeddings_result\").alias('features'))\\\n",
        "                          .select(['label']+[expr('features[' + str(x) + ']') for x in range(100)])"
      ],
      "metadata": {
        "id": "N2t1hQaPsxgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_embedded.show()"
      ],
      "metadata": {
        "id": "x4MtQo9z21go"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sarcastic_weight = class_weights[0].item()\n",
        "non_sarcastic_weight = class_weights[1].item()"
      ],
      "metadata": {
        "id": "7TtrzH4f533G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_weigthed = df_embedded.withColumn(\"weigth\",\n",
        "                                     when(col('label') == 1.0, sarcastic_weight)\n",
        "                                     .otherwise(non_sarcastic_weight))\\\n",
        "                          .select(['label', col('weigth').cast(FloatType())]+df_embedded.columns[1:])"
      ],
      "metadata": {
        "id": "MsWwVnMZ6vAK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_weigthed.printSchema()"
      ],
      "metadata": {
        "id": "fjFFLZOp7nHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = df_weigthed.sampleBy('label', fractions={0.0: 0.5, 1.0:0.6})\n",
        "test = df_weigthed.subtract(train)"
      ],
      "metadata": {
        "id": "PzB6UKAbs7OZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.show()"
      ],
      "metadata": {
        "id": "V0jwm7aS9hjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup features\n",
        "vector_assembler = VectorAssembler(inputCols=train.columns[2:], outputCol='features') \\\n",
        "                          .setHandleInvalid(\"skip\")                 "
      ],
      "metadata": {
        "id": "IyYnfiC44eQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LogisticRegression(featuresCol='features',\n",
        "                        labelCol='label',\n",
        "                        maxIter=150, \n",
        "                        regParam=0.3, \n",
        "                        elasticNetParam=0.8)\n",
        "#lr.setWeightCol(\"weight\")"
      ],
      "metadata": {
        "id": "tdabECsB3scc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = Pipeline(stages=[vector_assembler, lr])\n",
        "bert_pipeline = pipeline.fit(train)\n",
        "bert_pipeline.save(DRIVE_FOLDER+\"bert_model\")\n",
        "bert_predictions = bert_pipeline.transform(test)"
      ],
      "metadata": {
        "id": "mtVOYLu13wdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_predictions.show(5)"
      ],
      "metadata": {
        "id": "-UrO2nY49nrI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_predictions.write.parquet(\"/content/bert\")"
      ],
      "metadata": {
        "id": "CQLapT_-SYEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = bert_predictions.select('prediction').toPandas()\n",
        "y_true = test.select('label').toPandas()\n",
        "clf_bert = classification_report(y_true=y_true, y_pred=y_pred, zero_division=0)\n",
        "print(clf_bert)"
      ],
      "metadata": {
        "id": "Wx3GQ13Pu-34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paramGrid = ParamGridBuilder()\\\n",
        "             .addGrid(lr.regParam, [0.01, 0.1, 0.5, 1.0, 2.0])\\\n",
        "             .addGrid(lr.elasticNetParam, [0.0, 0.25, 0.5, 0.75, 1.0])\\\n",
        "             .addGrid(lr.maxIter, [1, 5, 10, 20, 50])\\\n",
        "             .build()\n",
        "\n",
        "crossval = CrossValidator(estimator=bert_pipeline,\n",
        "                          estimatorParamMaps=paramGrid,\n",
        "                          evaluator=BinaryClassificationEvaluator(),\n",
        "                          numFolds=2)  # use 3+ folds in practice\n",
        "\n",
        "# Run cross-validation, and choose the best set of parameters.\n",
        "cvModel = crossval.fit(train)"
      ],
      "metadata": {
        "id": "xTa3cvqVldbO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}