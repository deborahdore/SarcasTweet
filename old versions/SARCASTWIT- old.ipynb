{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SARCASTWIT.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "DokjWUCvcIkQ",
        "5wh23uCQcxfP",
        "29_DCW9URUjb",
        "daSEOScGUKJo",
        "pDQJOzR4-Ncl"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ade30892659f44b5b3fa14158bb8822f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ef832b97083c4501a01513b576f9e74b",
              "IPY_MODEL_ff07d831e3f8414c952cfd0478dd1569"
            ],
            "layout": "IPY_MODEL_9959fc7bcf094cf49c13abac1fd3d205"
          }
        },
        "ef832b97083c4501a01513b576f9e74b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "info",
            "description": "Yes",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_f731679f895a4d19bffc7c41d50842ed",
            "style": "IPY_MODEL_52c9d59f4a404ef7bbe0d3f4750bca0d",
            "tooltip": ""
          }
        },
        "ff07d831e3f8414c952cfd0478dd1569": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "info",
            "description": "No",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_ae0c980d1df842149c1b27093980c3a1",
            "style": "IPY_MODEL_6ba53a4adc3647d8952852c4ee2019c5",
            "tooltip": ""
          }
        },
        "9959fc7bcf094cf49c13abac1fd3d205": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f731679f895a4d19bffc7c41d50842ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "50px",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "150px"
          }
        },
        "52c9d59f4a404ef7bbe0d3f4750bca0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "ae0c980d1df842149c1b27093980c3a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "50px",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "150px"
          }
        },
        "6ba53a4adc3647d8952852c4ee2019c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. **Define dependencies and constrains**"
      ],
      "metadata": {
        "id": "IfcrKr5Na8A_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to download tweet from Twitter, first one must create an account and apply for **developer priviledges**. The application will grant the developer basic access the the [Twitter API](https://developer.twitter.com/en/docs/twitter-api) which are not enough because it only allows the download of tweet of the last 7 days. Therefore, I've applied to the [Premium plan](https://developer.twitter.com/en/support/twitter-api/premium) which allows the download of 25k of tweets per month along with the use _full archive_ and the _30 days_ search API but with limited amout of request per month."
      ],
      "metadata": {
        "id": "TdELnf08cHP2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ImtN6rXUazit"
      },
      "outputs": [],
      "source": [
        "JAVA_HOME = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "COLLAB_DIR = \"/content/\"\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "\n",
        "# File with Twitter project credentials\n",
        "CREDENTIALS = '/content/credentials.yaml'\n",
        "CREDENTIALS_KEY = 'search_tweets_30_day_dev'\n",
        "\n",
        "# csv file where tweet downloaded will be saved\n",
        "DATASET = '/content/dataset.csv'\n",
        "DATASET_ANNOTATED = '/content/dataset_annotated.csv'\n",
        "SENTIPOLIC = '/content/sentipolic.csv'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0sYKlPLLjvx",
        "outputId": "da5a186d-dc1f-4592-f335-137e89d41362"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.7.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### install libraries"
      ],
      "metadata": {
        "id": "bdKPmsLJTYA6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install findspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPUDzdbEL6zM",
        "outputId": "2cacde4c-f021-45ac-b72f-8ebdff7e9d89"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting findspark\n",
            "  Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
            "Installing collected packages: findspark\n",
            "Successfully installed findspark-2.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install libenchant1c2a\n",
        "!pip install pyenchant\n",
        "!apt-get install hunspell-it"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRdt8lR_QBTm",
        "outputId": "28ada427-c9d1-489a-b7ef-9d26e927754f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  aspell aspell-en dictionaries-common emacsen-common enchant hunspell-en-us\n",
            "  libaspell15 libhunspell-1.6-0 libtext-iconv-perl\n",
            "Suggested packages:\n",
            "  aspell-doc spellutils wordlist hunspell openoffice.org-hunspell\n",
            "  | openoffice.org-core libenchant-voikko\n",
            "The following NEW packages will be installed:\n",
            "  aspell aspell-en dictionaries-common emacsen-common enchant hunspell-en-us\n",
            "  libaspell15 libenchant1c2a libhunspell-1.6-0 libtext-iconv-perl\n",
            "0 upgraded, 10 newly installed, 0 to remove and 42 not upgraded.\n",
            "Need to get 1,312 kB of archives.\n",
            "After this operation, 5,353 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libtext-iconv-perl amd64 1.7-5build6 [13.0 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libaspell15 amd64 0.60.7~20110707-4ubuntu0.2 [310 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 emacsen-common all 2.0.8 [17.6 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 dictionaries-common all 1.27.2 [186 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 aspell amd64 0.60.7~20110707-4ubuntu0.2 [87.7 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 aspell-en all 2017.08.24-0-0.1 [298 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 hunspell-en-us all 1:2017.08.24 [168 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhunspell-1.6-0 amd64 1.6.2-1 [154 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 libenchant1c2a amd64 1.6.0-11.1 [64.4 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 enchant amd64 1.6.0-11.1 [12.2 kB]\n",
            "Fetched 1,312 kB in 0s (3,208 kB/s)\n",
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package libtext-iconv-perl.\n",
            "(Reading database ... 155629 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libtext-iconv-perl_1.7-5build6_amd64.deb ...\n",
            "Unpacking libtext-iconv-perl (1.7-5build6) ...\n",
            "Selecting previously unselected package libaspell15:amd64.\n",
            "Preparing to unpack .../1-libaspell15_0.60.7~20110707-4ubuntu0.2_amd64.deb ...\n",
            "Unpacking libaspell15:amd64 (0.60.7~20110707-4ubuntu0.2) ...\n",
            "Selecting previously unselected package emacsen-common.\n",
            "Preparing to unpack .../2-emacsen-common_2.0.8_all.deb ...\n",
            "Unpacking emacsen-common (2.0.8) ...\n",
            "Selecting previously unselected package dictionaries-common.\n",
            "Preparing to unpack .../3-dictionaries-common_1.27.2_all.deb ...\n",
            "Adding 'diversion of /usr/share/dict/words to /usr/share/dict/words.pre-dictionaries-common by dictionaries-common'\n",
            "Unpacking dictionaries-common (1.27.2) ...\n",
            "Selecting previously unselected package aspell.\n",
            "Preparing to unpack .../4-aspell_0.60.7~20110707-4ubuntu0.2_amd64.deb ...\n",
            "Unpacking aspell (0.60.7~20110707-4ubuntu0.2) ...\n",
            "Selecting previously unselected package aspell-en.\n",
            "Preparing to unpack .../5-aspell-en_2017.08.24-0-0.1_all.deb ...\n",
            "Unpacking aspell-en (2017.08.24-0-0.1) ...\n",
            "Selecting previously unselected package hunspell-en-us.\n",
            "Preparing to unpack .../6-hunspell-en-us_1%3a2017.08.24_all.deb ...\n",
            "Unpacking hunspell-en-us (1:2017.08.24) ...\n",
            "Selecting previously unselected package libhunspell-1.6-0:amd64.\n",
            "Preparing to unpack .../7-libhunspell-1.6-0_1.6.2-1_amd64.deb ...\n",
            "Unpacking libhunspell-1.6-0:amd64 (1.6.2-1) ...\n",
            "Selecting previously unselected package libenchant1c2a:amd64.\n",
            "Preparing to unpack .../8-libenchant1c2a_1.6.0-11.1_amd64.deb ...\n",
            "Unpacking libenchant1c2a:amd64 (1.6.0-11.1) ...\n",
            "Selecting previously unselected package enchant.\n",
            "Preparing to unpack .../9-enchant_1.6.0-11.1_amd64.deb ...\n",
            "Unpacking enchant (1.6.0-11.1) ...\n",
            "Setting up libhunspell-1.6-0:amd64 (1.6.2-1) ...\n",
            "Setting up libaspell15:amd64 (0.60.7~20110707-4ubuntu0.2) ...\n",
            "Setting up emacsen-common (2.0.8) ...\n",
            "Setting up libtext-iconv-perl (1.7-5build6) ...\n",
            "Setting up dictionaries-common (1.27.2) ...\n",
            "Setting up aspell (0.60.7~20110707-4ubuntu0.2) ...\n",
            "Setting up hunspell-en-us (1:2017.08.24) ...\n",
            "Setting up libenchant1c2a:amd64 (1.6.0-11.1) ...\n",
            "Setting up aspell-en (2017.08.24-0-0.1) ...\n",
            "Setting up enchant (1.6.0-11.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for dictionaries-common (1.27.2) ...\n",
            "aspell-autobuildhash: processing: en [en-common].\n",
            "aspell-autobuildhash: processing: en [en-variant_0].\n",
            "aspell-autobuildhash: processing: en [en-variant_1].\n",
            "aspell-autobuildhash: processing: en [en-variant_2].\n",
            "aspell-autobuildhash: processing: en [en-w_accents-only].\n",
            "aspell-autobuildhash: processing: en [en-wo_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_AU-variant_0].\n",
            "aspell-autobuildhash: processing: en [en_AU-variant_1].\n",
            "aspell-autobuildhash: processing: en [en_AU-w_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_AU-wo_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_CA-variant_0].\n",
            "aspell-autobuildhash: processing: en [en_CA-variant_1].\n",
            "aspell-autobuildhash: processing: en [en_CA-w_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_CA-wo_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_GB-ise-w_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_GB-ise-wo_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_GB-ize-w_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_GB-ize-wo_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_GB-variant_0].\n",
            "aspell-autobuildhash: processing: en [en_GB-variant_1].\n",
            "aspell-autobuildhash: processing: en [en_US-w_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_US-wo_accents-only].\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyenchant\n",
            "  Downloading pyenchant-3.2.2-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 2.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: pyenchant\n",
            "Successfully installed pyenchant-3.2.2\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "Suggested packages:\n",
            "  hunspell libreoffice-writer\n",
            "The following NEW packages will be installed:\n",
            "  hunspell-it\n",
            "0 upgraded, 1 newly installed, 0 to remove and 42 not upgraded.\n",
            "Need to get 340 kB of archives.\n",
            "After this operation, 1,752 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 hunspell-it all 1:6.0.3-3 [340 kB]\n",
            "Fetched 340 kB in 0s (1,089 kB/s)\n",
            "Selecting previously unselected package hunspell-it.\n",
            "(Reading database ... 156043 files and directories currently installed.)\n",
            "Preparing to unpack .../hunspell-it_1%3a6.0.3-3_all.deb ...\n",
            "Unpacking hunspell-it (1:6.0.3-3) ...\n",
            "Setting up hunspell-it (1:6.0.3-3) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install openjdk-8-jdk-headless -qq\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = JAVA_HOME"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rF7hhURdQB9v",
        "outputId": "537f1ce8-609a-43d1-cc6c-e67c5d3895c8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  openjdk-8-jre-headless\n",
            "Suggested packages:\n",
            "  openjdk-8-demo openjdk-8-source libnss-mdns fonts-dejavu-extra\n",
            "  fonts-ipafont-gothic fonts-ipafont-mincho fonts-wqy-microhei\n",
            "  fonts-wqy-zenhei fonts-indic\n",
            "The following NEW packages will be installed:\n",
            "  openjdk-8-jdk-headless openjdk-8-jre-headless\n",
            "0 upgraded, 2 newly installed, 0 to remove and 42 not upgraded.\n",
            "Need to get 36.5 MB of archives.\n",
            "After this operation, 143 MB of additional disk space will be used.\n",
            "Selecting previously unselected package openjdk-8-jre-headless:amd64.\n",
            "(Reading database ... 156050 files and directories currently installed.)\n",
            "Preparing to unpack .../openjdk-8-jre-headless_8u312-b07-0ubuntu1~18.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jre-headless:amd64 (8u312-b07-0ubuntu1~18.04) ...\n",
            "Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n",
            "Preparing to unpack .../openjdk-8-jdk-headless_8u312-b07-0ubuntu1~18.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk-headless:amd64 (8u312-b07-0ubuntu1~18.04) ...\n",
            "Setting up openjdk-8-jre-headless:amd64 (8u312-b07-0ubuntu1~18.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n",
            "Setting up openjdk-8-jdk-headless:amd64 (8u312-b07-0ubuntu1~18.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!java -version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08GbgJr6MgmM",
        "outputId": "3cbc7195-d83b-4ca8-c852-863feea991fd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "openjdk version \"11.0.15\" 2022-04-19\n",
            "OpenJDK Runtime Environment (build 11.0.15+10-Ubuntu-0ubuntu0.18.04.1)\n",
            "OpenJDK 64-Bit Server VM (build 11.0.15+10-Ubuntu-0ubuntu0.18.04.1, mixed mode, sharing)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark==3.2.0\n",
        "!pip install spark-nlp==3.4.4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvmO7zGx6v_1",
        "outputId": "0ea1caba-a89a-4894-ecbc-9b8091103081"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark==3.2.0\n",
            "  Downloading pyspark-3.2.0.tar.gz (281.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.3 MB 17 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.2\n",
            "  Downloading py4j-0.10.9.2-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 37.5 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.2.0-py2.py3-none-any.whl size=281805911 sha256=78d58367275728fd2a8f4eda180d6fb3a0b0545507fea4d3caaee96af005d9aa\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/de/d2/9be5d59d7331c6c2a7c1b6d1a4f463ce107332b1ecd4e80718\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.2 pyspark-3.2.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting spark-nlp==3.4.4\n",
            "  Downloading spark_nlp-3.4.4-py2.py3-none-any.whl (145 kB)\n",
            "\u001b[K     |████████████████████████████████| 145 kB 5.5 MB/s \n",
            "\u001b[?25hInstalling collected packages: spark-nlp\n",
            "Successfully installed spark-nlp-3.4.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNZLejN9TRN2",
        "outputId": "b108413b-ae1b-4e91-9499-ea0d52f32d99"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras-tqdm\n",
            "  Downloading keras_tqdm-2.0.1-py2.py3-none-any.whl (7.1 kB)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.7/dist-packages (from keras-tqdm) (2.8.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from keras-tqdm) (4.64.0)\n",
            "Installing collected packages: keras-tqdm\n",
            "Successfully installed keras-tqdm-2.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install elephas"
      ],
      "metadata": {
        "id": "riiFxATzw3gl",
        "outputId": "433e6ff0-ca1f-4593-b8ca-65d204ce9740",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting elephas\n",
            "  Downloading elephas-3.1.0.tar.gz (26 kB)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from elephas) (0.29.30)\n",
            "Requirement already satisfied: tensorflow!=2.2.*,>=2 in /usr/local/lib/python3.7/dist-packages (from elephas) (2.8.0+zzzcolab20220506162203)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.7/dist-packages (from elephas) (1.1.4)\n",
            "Collecting h5py==3.3.0\n",
            "  Downloading h5py-3.3.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.1 MB 7.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyspark==3.2 in /usr/local/lib/python3.7/dist-packages (from elephas) (3.2.0)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from h5py==3.3.0->elephas) (1.21.6)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py==3.3.0->elephas) (1.5.2)\n",
            "Requirement already satisfied: py4j==0.10.9.2 in /usr/local/lib/python3.7/dist-packages (from pyspark==3.2->elephas) (0.10.9.2)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.2.*,>=2->elephas) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.2.*,>=2->elephas) (57.4.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.2.*,>=2->elephas) (0.26.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.2.*,>=2->elephas) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.2.*,>=2->elephas) (1.0.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.2.*,>=2->elephas) (2.8.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.2.*,>=2->elephas) (3.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.2.*,>=2->elephas) (1.14.1)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.2.*,>=2->elephas) (0.5.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.2.*,>=2->elephas) (4.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.2.*,>=2->elephas) (1.46.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.2.*,>=2->elephas) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.2.*,>=2->elephas) (1.1.2)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.2.*,>=2->elephas) (2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.2.*,>=2->elephas) (1.15.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.2.*,>=2->elephas) (14.0.1)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 19.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.2.*,>=2->elephas) (1.6.3)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.2.*,>=2->elephas) (3.17.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow!=2.2.*,>=2->elephas) (0.37.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow!=2.2.*,>=2->elephas) (3.3.7)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow!=2.2.*,>=2->elephas) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow!=2.2.*,>=2->elephas) (0.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow!=2.2.*,>=2->elephas) (2.23.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow!=2.2.*,>=2->elephas) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow!=2.2.*,>=2->elephas) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow!=2.2.*,>=2->elephas) (1.8.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow!=2.2.*,>=2->elephas) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow!=2.2.*,>=2->elephas) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow!=2.2.*,>=2->elephas) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow!=2.2.*,>=2->elephas) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow!=2.2.*,>=2->elephas) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow!=2.2.*,>=2->elephas) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow!=2.2.*,>=2->elephas) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow!=2.2.*,>=2->elephas) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow!=2.2.*,>=2->elephas) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow!=2.2.*,>=2->elephas) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow!=2.2.*,>=2->elephas) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow!=2.2.*,>=2->elephas) (3.2.0)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from flask->elephas) (7.1.2)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask->elephas) (2.11.3)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask->elephas) (1.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->flask->elephas) (2.0.1)\n",
            "Building wheels for collected packages: elephas\n",
            "  Building wheel for elephas (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for elephas: filename=elephas-3.1.0-py3-none-any.whl size=26259 sha256=d12befe98537e8df57145fb98cf6407f1341ba3e44ddf00fd47124d3799e3412\n",
            "  Stored in directory: /root/.cache/pip/wheels/33/e4/e1/56dda8be927bb0e9971cd7ddf3fc1b17ce78db56268b1f867f\n",
            "Successfully built elephas\n",
            "Installing collected packages: tf-estimator-nightly, h5py, elephas\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "Successfully installed elephas-3.1.0 h5py-3.3.0 tf-estimator-nightly-2.8.0.dev2021122109\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### import libraries"
      ],
      "metadata": {
        "id": "IEOD3tq6TdtT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pyspark packages\n",
        "from pyspark import *\n",
        "from pyspark.sql import *\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark import SparkContext, SparkConf\n",
        "from pyspark.sql import DataFrame\n",
        "from pyspark.ml.feature import VectorAssembler, SQLTransformer, Normalizer"
      ],
      "metadata": {
        "id": "V-dnnL8JS90g"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data processing useful packages\n",
        "from pyspark.sql.functions import udf, col, lower, trim, regexp_replace, transform\n",
        "import enchant\n",
        "from enchant.checker import SpellChecker"
      ],
      "metadata": {
        "id": "Oa1b_SYrUrr9"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# libraries for feature engineering\n",
        "import sparknlp\n",
        "from sparknlp.base import *\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.common import *\n",
        "from sparknlp.annotator import Tokenizer"
      ],
      "metadata": {
        "id": "qmEjIQRep142"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# useful imports\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "import requests\n",
        "import json\n",
        "import yaml\n",
        "import csv\n",
        "import pdb\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "2Q2kd-HsTAVu"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# python widgets\n",
        "from ipywidgets import Button\n",
        "import asyncio\n",
        "from IPython.display import display, clear_output\n",
        "import ipywidgets as widgets\n",
        "from ipywidgets import HBox, Layout\n",
        "import time as t\n",
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator"
      ],
      "metadata": {
        "id": "9oWwzEUWTJGE"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Kers imports\n",
        "import tensorflow as tf\n",
        "from keras_tqdm import TQDMNotebookCallback\n",
        "from keras.layers.core import Dense, Dropout, Activation\n",
        "from keras import optimizers, regularizers\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.preprocessing.sequence import *"
      ],
      "metadata": {
        "id": "8bOshskATS8l"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# keras \n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping"
      ],
      "metadata": {
        "id": "Qd8-rb9ZW3d9"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sklearn \n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "L_SpAtHtRiUi"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from elephas.ml_model import ElephasEstimator"
      ],
      "metadata": {
        "id": "eNPwOzBr4V7A"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PySpark configurations"
      ],
      "metadata": {
        "id": "VdfBlXxLTgxU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark = sparknlp.start(spark32=True)\n",
        "\n",
        "print(\"Spark NLP version\", sparknlp.version())\n",
        "print(\"Apache Spark version:\", spark.version)"
      ],
      "metadata": {
        "id": "mkCNpht6bvLp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a26f7b6-70f2-40ac-aa3e-099c558d8aca"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark NLP version 3.4.4\n",
            "Apache Spark version: 3.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sc = spark.sparkContext\n",
        "type(sc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYCtzalg-rGm",
        "outputId": "71fb3684-83ef-4e13-f56b-316a8b44703e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.context.SparkContext"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "OJzJeXfRMCPb"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cd ~/.ivy2/cache/com.johnsnowlabs.nlp/spark-nlp_2.12/jars && ls -lt"
      ],
      "metadata": {
        "id": "0yAIKiS36-3J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fc05575-f2cc-4a8a-e8ee-afa3482c456f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 0: cd: /root/.ivy2/cache/com.johnsnowlabs.nlp/spark-nlp_2.12/jars: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download Files from GitHub"
      ],
      "metadata": {
        "id": "DokjWUCvcIkQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/deborahdore/italian-sarcastic-tweet-classification/raw/main/dataset/dataset.csv\n",
        "!wget https://github.com/deborahdore/italian-sarcastic-tweet-classification/raw/main/dataset/other/sentipolic.csv\n",
        "!wget https://raw.githubusercontent.com/deborahdore/italian-sarcastic-tweet-classification/main/credentials/credentials.yaml\n",
        "!wget https://raw.githubusercontent.com/deborahdore/italian-sarcastic-tweet-classification/main/dataset/dataset_annotated.csv"
      ],
      "metadata": {
        "id": "EENgh8yncNzS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed6692ab-df92-4275-eb00-9ec563088413"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-23 21:55:53--  https://github.com/deborahdore/italian-sarcastic-tweet-classification/raw/main/dataset/dataset.csv\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/deborahdore/italian-sarcastic-tweet-classification/main/dataset/dataset.csv [following]\n",
            "--2022-05-23 21:55:54--  https://raw.githubusercontent.com/deborahdore/italian-sarcastic-tweet-classification/main/dataset/dataset.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1797205 (1.7M) [text/plain]\n",
            "Saving to: ‘dataset.csv’\n",
            "\n",
            "dataset.csv         100%[===================>]   1.71M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2022-05-23 21:55:54 (31.0 MB/s) - ‘dataset.csv’ saved [1797205/1797205]\n",
            "\n",
            "--2022-05-23 21:55:54--  https://github.com/deborahdore/italian-sarcastic-tweet-classification/raw/main/dataset/other/sentipolic.csv\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/deborahdore/italian-sarcastic-tweet-classification/main/dataset/other/sentipolic.csv [following]\n",
            "--2022-05-23 21:55:55--  https://raw.githubusercontent.com/deborahdore/italian-sarcastic-tweet-classification/main/dataset/other/sentipolic.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1356686 (1.3M) [text/plain]\n",
            "Saving to: ‘sentipolic.csv’\n",
            "\n",
            "sentipolic.csv      100%[===================>]   1.29M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2022-05-23 21:55:55 (24.5 MB/s) - ‘sentipolic.csv’ saved [1356686/1356686]\n",
            "\n",
            "--2022-05-23 21:55:55--  https://raw.githubusercontent.com/deborahdore/italian-sarcastic-tweet-classification/main/credentials/credentials.yaml\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 237 [text/plain]\n",
            "Saving to: ‘credentials.yaml’\n",
            "\n",
            "credentials.yaml    100%[===================>]     237  --.-KB/s    in 0s      \n",
            "\n",
            "2022-05-23 21:55:55 (14.2 MB/s) - ‘credentials.yaml’ saved [237/237]\n",
            "\n",
            "--2022-05-23 21:55:55--  https://raw.githubusercontent.com/deborahdore/italian-sarcastic-tweet-classification/main/dataset/dataset_annotated.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 931783 (910K) [text/plain]\n",
            "Saving to: ‘dataset_annotated.csv’\n",
            "\n",
            "dataset_annotated.c 100%[===================>] 909.94K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2022-05-23 21:55:56 (19.6 MB/s) - ‘dataset_annotated.csv’ saved [931783/931783]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# italian dictionary for lemmatization\n",
        "!wget https://raw.githubusercontent.com/michmech/lemmatization-lists/master/lemmatization-it.txt"
      ],
      "metadata": {
        "id": "5v7zGUIlnl4Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ef8d48b-9177-48a9-ff42-cf89805fc265"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-23 21:55:56--  https://raw.githubusercontent.com/michmech/lemmatization-lists/master/lemmatization-it.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7917510 (7.5M) [text/plain]\n",
            "Saving to: ‘lemmatization-it.txt’\n",
            "\n",
            "lemmatization-it.tx 100%[===================>]   7.55M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2022-05-23 21:55:56 (90.0 MB/s) - ‘lemmatization-it.txt’ saved [7917510/7917510]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. **Retrieve Tweet**\n",
        "\n",
        "\n",
        "> Following, some code cell will be annotated with *%% script false* in order to avoid their execution. Those cell concern the download of the tweets from Twitter. Even if this may not sound dangerous, I've finished the request at my disposal. Therefore, calling the Twitter API will produce an error. Also, please don't run them otherwise the output of the cell will be lost.\n",
        "\n"
      ],
      "metadata": {
        "id": "5wh23uCQcxfP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- First we must retrieve and validate the credentials that we will need to access the Twitter API. I've store the bearer token in a yaml file: *credentials.yaml*\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gt6JZtFie0Py"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def handle_credentials(credentials, key):\n",
        "  with open(credentials, \"r\") as stream:\n",
        "    try:\n",
        "        credentials = yaml.safe_load(stream)\n",
        "        return credentials[key]\n",
        "    except yaml.YAMLError as exc:\n",
        "        print(exc)"
      ],
      "metadata": {
        "id": "qOoIg7uZc2bM"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "credentials = handle_credentials(CREDENTIALS, CREDENTIALS_KEY)\n",
        "endpoint = credentials['endpoint'] # we will use this endpoint to search for the tweet\n",
        "print(endpoint)"
      ],
      "metadata": {
        "id": "i_UEONFUfOt2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3bec80f-c051-4a6a-ad61-66f8f6cf9e6c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://api.twitter.com/1.1/tweets/search/30day/dev1.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Second we must create the header for the request"
      ],
      "metadata": {
        "id": "J-RByZFOf9iQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def handle_headers(credentials:dict):\n",
        "  headers = {\n",
        "    'Content-Type': 'application/json',\n",
        "    'Authorization': f'Bearer {credentials[\"bearer_token\"]}'\n",
        "  }\n",
        "  return headers"
      ],
      "metadata": {
        "id": "5OYEqkb2fW7U"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "headers = handle_headers(credentials)\n",
        "headers"
      ],
      "metadata": {
        "id": "vfRm7V29gCJq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92bee8f4-0a6d-468d-e6bc-b73d390a559c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Authorization': 'Bearer None', 'Content-Type': 'application/json'}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Another parameter of the request is the query. The query determines which tweet will be returned in the response. In our case, we have 2 types of queries: the one that searches for sarcastic tweets and the one that returns non-sarcastic tweets"
      ],
      "metadata": {
        "id": "9yp2tFf9gOsg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the query about sarcastic tweet I've chosen some keyword that, in my opion, are used to express sarcasm and/or irony (sarcasm is a sub-type of irony):\n",
        "\n",
        "\n",
        "1. sarcasmo (with or without #)\n",
        "2. ironia (with or without #)\n",
        "3. \"*ridiamo per non piangere*\"\n",
        "4. #coincidenze (.. io non credo) is mostly used to express sarcasm\n",
        "5. \"*qualquadra non cosa*\"\n",
        "\n",
        "Many studies also suggest that sarcasm can be found in tweet related to politics. Therefore, these seems very good starting point:\n",
        "1. monti, draghi, berlusconi (known italian prime minister)\n",
        "2. governo\n",
        "3. premier\n",
        "\n",
        "\n",
        "For non-sarcastic tweet, I've excluded all the possibile word that may refer to sarcasm.\n",
        "\n",
        "The list of operator used can be found in the [Twitter API documentation](https://developer.twitter.com/en/docs/twitter-api/enterprise/rules-and-filtering/operators-by-product)."
      ],
      "metadata": {
        "id": "jL_QG_G5Ew4o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sarcasm_query = '(#sarcasmo OR sarcasmo OR #ironia OR ironia OR \"ridiamo per non piangere\" \\\n",
        "                  OR #coincidenze OR \"qualquadra non cosa\" OR draghi OR monti OR berlusconi \\\n",
        "                  OR governo OR premier) lang:it -has:media'\n",
        "\n",
        "non_sarcasm_query = '-\"ridiamo per non piangere\" -sarcasmo -ironia -\"qualquadra non cosa\" lang:it -has:media'"
      ],
      "metadata": {
        "id": "B4Qan_sigKsq"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Now we can define the function that will handle the request and the dataframe where tweet will be stored.\n",
        "\n",
        "\n",
        "> Other parameters that we need in order to process the request are:\n",
        "- *max_result_per_page* : the maximum number of tweets per call \n",
        "- *next_token* : a token that if passed to the request will return the next page of results\n",
        "- I've defined a parameter *max_num_of_request* that will stop the call once that we've reached the desidered amount of calls. This must be done because the request at our disposal are not illimited. So we must be careful to the number of the request that we do\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1AItsWZphAXa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def handle_request(endpoint, headers, query, max_result_per_page, next_token = None):\n",
        "  \n",
        "  if next_token is not None:\n",
        "    payload = json.dumps({\n",
        "      \"maxResults\": max_result_per_page,\n",
        "      \"query\": query,\n",
        "      \"next\": next_token\n",
        "    })\n",
        "  else:\n",
        "    payload = json.dumps({\n",
        "      \"maxResults\": max_result_per_page,\n",
        "      \"query\": query,\n",
        "    })\n",
        "  \n",
        "  response = requests.post(endpoint, headers=headers, data=payload)\n",
        "\n",
        "  return response.text"
      ],
      "metadata": {
        "id": "OVmgNDDch8Se"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_tweet(response, label):\n",
        "  tweets = []\n",
        "  json_response = json.loads(response)\n",
        "  \n",
        "  if 'results' in response:\n",
        "    results = json_response[\"results\"]\n",
        "\n",
        "    for tweet in results:\n",
        "      # is tweet a retweet?\n",
        "      if 'retweeted_status' in tweet:\n",
        "        if tweet['retweeted_status']['truncated']:\n",
        "          text = tweet['retweeted_status']['extended_tweet']['full_text']\n",
        "        else:\n",
        "          text = tweet['retweeted_status']['text']\n",
        "      else:\n",
        "        if tweet['truncated']:\n",
        "          text = tweet['extended_tweet']['full_text']\n",
        "        else:\n",
        "          text = tweet['text']\n",
        "        \n",
        "      text = text.replace('\"', \"'\")\n",
        "      data = Tweet(tweet[\"id\"], f\"{text}\", label)\n",
        "      \n",
        "      tweets.append(data)\n",
        "\n",
        "  else:\n",
        "    print(\"Request went wrong\")\n",
        "    print(response)\n",
        "\n",
        "  return tweets"
      ],
      "metadata": {
        "id": "1gNdo7Bnijtz"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_tweet(endpoint, \n",
        "                   headers, \n",
        "                   query, \n",
        "                   label,\n",
        "                   max_result_per_page,\n",
        "                   tweet_list,\n",
        "                   next_token = None, \n",
        "                   max_num_of_request = 20):\n",
        "\n",
        "  if max_num_of_request <= 0:\n",
        "    return tweet_list\n",
        "\n",
        "  response = handle_request(endpoint, headers, query, max_result_per_page, next_token)\n",
        "\n",
        "  tweet_list.extend(extract_tweet(response, label))\n",
        "\n",
        "  try:\n",
        "      next_token = json.loads(response)['next']\n",
        "  except:\n",
        "      next_token = None\n",
        "\n",
        "  if next_token is not None:\n",
        "      return download_tweet(endpoint, headers, query, label, max_result_per_page,\n",
        "                   tweet_list, next_token, max_num_of_request - 1)\n",
        "  else:\n",
        "      return tweet_list"
      ],
      "metadata": {
        "id": "oHbiTTbNg7x4"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define tweet\n",
        "Tweet = Row(\"id\", \"text\", \"sarcastic\")"
      ],
      "metadata": {
        "id": "yUW4eUSoyq08"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweets = []"
      ],
      "metadata": {
        "id": "nnd9wSFdmzTs"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%script false\n",
        "\n",
        "# download sarcastic tweet\n",
        "tweets = download_tweet(endpoint, \n",
        "                   headers, \n",
        "                   sarcasm_query, \n",
        "                   \"Yes\",\n",
        "                   100,\n",
        "                   [],\n",
        "                   next_token = None, \n",
        "                   max_num_of_request = 40)"
      ],
      "metadata": {
        "id": "wqphEQDcwHHr"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%script false\n",
        "\n",
        "# download non-sarcastic tweet\n",
        "tweets.extend(\n",
        "    download_tweet(endpoint, \n",
        "                   headers, \n",
        "                   non_sarcasm_query, \n",
        "                   \"No\",\n",
        "                   100,\n",
        "                   [],\n",
        "                   next_token = None, \n",
        "                   max_num_of_request = 40))"
      ],
      "metadata": {
        "id": "rLUvtri88LyI"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%script false\n",
        "# create DataFrame\n",
        "df = spark.createDataFrame(tweets)"
      ],
      "metadata": {
        "id": "RZeSJmGt5FOG"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%script false\n",
        "df.show(10, truncate=False)"
      ],
      "metadata": {
        "id": "nmS3eNL075po"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%script false\n",
        "\n",
        "# create file\n",
        "if not os.path.exists(DATASET):\n",
        "  os.mknod(DATASET)\n",
        "\n",
        "# save tweets\n",
        "df.toPandas().to_csv(DATASET, header=True, index=False) "
      ],
      "metadata": {
        "id": "PgAKUhbDmrmU"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. **Annotate Tweet**"
      ],
      "metadata": {
        "id": "29_DCW9URUjb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When we download tweet using an hashtag, we are not 100% sure of what we downloaded is correct. We must analyze - at least - the majority of the tweet to understand if what we have labelled is correct. There here's a little tool to help us with that."
      ],
      "metadata": {
        "id": "xrDr46suRbeP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Tweet = Row(\"id\", \"text\", \"sarcastic\")\n",
        "\n",
        "schema = StructType([StructField(\"id\", StringType(), True)\\\n",
        "                   ,StructField(\"text\", StringType(), True)\\\n",
        "                   ,StructField(\"sarcastic\", StringType(), True)])\n",
        "\n",
        "df = spark.createDataFrame(pd.read_csv(DATASET), schema=schema)\n",
        "df.show(10)"
      ],
      "metadata": {
        "id": "8hS8XFLNRa2q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afc55c78-226e-465a-a8a4-6a67be8250ce"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+--------------------+---------+\n",
            "|                 id|                text|sarcastic|\n",
            "+-------------------+--------------------+---------+\n",
            "|1524034279151489025|@AlienoGentile C’...|       No|\n",
            "|1524034279122034690|@NaremFox @RickyT...|       No|\n",
            "|1524034278983704581|Sempre al fine di...|       No|\n",
            "|1524034278870372354|E Comunque quest'...|       No|\n",
            "|1524034278828425218|Comunque a me Alb...|       No|\n",
            "|1524034278719475712|che bella persona...|       No|\n",
            "|1524034278589411328|oddio io quando h...|       No|\n",
            "|1524034278559993857|@carlopitocchi La...|       No|\n",
            "|1524034278140616708|Oh nooo solo 400 ...|       No|\n",
            "|1524034278031609856|@WillSorareSmith ...|       No|\n",
            "+-------------------+--------------------+---------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def count_label(df, numeric=False):\n",
        "  label_yes = 1 if numeric else \"Yes\"\n",
        "  label_no = 0 if numeric else \"No\"\n",
        "  return df.groupBy(\"sarcastic\").agg(\n",
        "      count(when(col(\"sarcastic\") == label_yes, 1)),\n",
        "      count(when(col(\"sarcastic\") == label_no, 1)))"
      ],
      "metadata": {
        "id": "g-2CxhPEb59B"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# count tweet\n",
        "print(f'Total number of tweet retrieved {df.count()}')"
      ],
      "metadata": {
        "id": "UWC7f6AHbzKA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f16c414-0496-4cae-9df2-edffd91ae656"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of tweet retrieved 11800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we want first to drop duplicates\n",
        "\n",
        "print(\"Count before drop:\")\n",
        "count_label(df).show()\n",
        "\n",
        "count_before_drop = df.count()\n",
        "df = df.dropDuplicates([\"text\"])\n",
        "print(f\"Distinct count: {str(df.count())} \\n\")\n",
        "\n",
        "print(\"Count after drop:\")\n",
        "count_label(df).show()"
      ],
      "metadata": {
        "id": "gciiYKT7R148",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3c84efa-2ffe-4396-d875-3ec69c2b3d3a"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Count before drop:\n",
            "+---------+---------------------------------------------+--------------------------------------------+\n",
            "|sarcastic|count(CASE WHEN (sarcastic = Yes) THEN 1 END)|count(CASE WHEN (sarcastic = No) THEN 1 END)|\n",
            "+---------+---------------------------------------------+--------------------------------------------+\n",
            "|       No|                                            0|                                        7800|\n",
            "|      Yes|                                         4000|                                           0|\n",
            "+---------+---------------------------------------------+--------------------------------------------+\n",
            "\n",
            "Distinct count: 9290 \n",
            "\n",
            "Count after drop:\n",
            "+---------+---------------------------------------------+--------------------------------------------+\n",
            "|sarcastic|count(CASE WHEN (sarcastic = Yes) THEN 1 END)|count(CASE WHEN (sarcastic = No) THEN 1 END)|\n",
            "+---------+---------------------------------------------+--------------------------------------------+\n",
            "|       No|                                            0|                                        7304|\n",
            "|      Yes|                                         1986|                                           0|\n",
            "+---------+---------------------------------------------+--------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'dropped {count_before_drop-df.count()} columns')\n",
        "print(f'total count: {df.count()}')"
      ],
      "metadata": {
        "id": "q3WedH78qpMX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f5f5a08-a84b-4b99-ee58-0334d68e0be8"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dropped 2510 columns\n",
            "total count: 9290\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# visually \n",
        "data = count_label(df).collect()\n",
        "\n",
        "labels = ['sarcastic', 'non sarcastic']\n",
        "colors = sns.color_palette('pastel')[0:5]\n",
        "\n",
        "plt.pie([int(data[1][1]), int(data[0][2])], labels = labels, colors = colors, autopct='%.0f%%')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "idZSd7XIVbXS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "5530864b-5f0f-48c3-c583-1707a0307344"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tweets_annotated = []"
      ],
      "metadata": {
        "id": "t4hgqk7qs9mZ"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def wait_for_change(widget1, widget2): \n",
        "    future = asyncio.Future()\n",
        "    def getvalue(change):\n",
        "        future.set_result(change.description)\n",
        "        widget1.on_click(getvalue, remove=True)\n",
        "        widget2.on_click(getvalue, remove=True) \n",
        "    widget1.on_click(getvalue)\n",
        "    widget2.on_click(getvalue)\n",
        "    return future\n",
        "\n",
        "async def f(df):\n",
        "  df_pandas = df.toPandas()\n",
        "  for index, row in df_pandas.iterrows():\n",
        "    print(f'Is this tweet sarcastic? \\n {row.text} \\n', flush=True)\n",
        "\n",
        "    x = await wait_for_change(sarcastic,non_sarcastic)\n",
        "    \n",
        "    if x == \"Yes\":\n",
        "      print(\"Tagged \", row.id, \"with sarcastic \\n\")\n",
        "      data = Tweet(row.id, row.text, \"Yes\")\n",
        "      tweets_annotated.append(data)\n",
        "    else:\n",
        "      print(\"Tagged \", row.id, \"with non-sarcastic \\n\")\n",
        "      data = Tweet(row.id, row.text, \"No\")      \n",
        "      tweets_annotated.append(data)\n",
        "\n",
        "    clear_output()\n",
        "    display(HBox([sarcastic,non_sarcastic]))"
      ],
      "metadata": {
        "id": "T3QQC7zoSvmO"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before going forward, we want to ask ourselves *How can know if a tweet is sarcastic or not?*\n",
        "\n",
        "*In Harry Potter and the Half Blood Prince, there is a scene where Harry is leaving the Weasley house and Mrs. Weasley says: “Promise me you will look after yourself…stay out of trouble….” Harry responds: “I always do Mrs. Weasley. I like a quiet life, you know me.” Anyone familiar with Harry Potter knows that his life is far from quiet, and so he must not really mean what he is saying. In fact, Harry is being sarcastic.*\n",
        "\n",
        "[source](https://kids.frontiersin.org/articles/10.3389/frym.2018.00056)\n",
        "\n",
        "Sarcasm is the use of words that say the opposite of what you really mean, often as a joke and with a tone of voice that shows this. It is often used to mock or critize someone, express disapproval or as a defence mechanism.\n",
        "\n",
        "For example:\n",
        "> *Noi invece ce la caviamo con un grado in meno ai termosifoni d'inverno e spegnendo i condizionatori d'estate. Non è fantastico? (#Draghi è un cialtrone sesquipedale, nel caso aveste ancora qualche dubbio)*\n",
        "\n",
        "Here we can imagine the sarcastic tone of the writer. He's obviously criticising the Italian prime minister, Mario Draghi, when, during an interview, he said that we must make sacrifices like lowering the grade of the radiator in order to cope with the possibility of not having the gas from Russia anymore. Obviously, this won't be enough. *Isn't this great?*\n",
        "\n",
        "Sometimes it's difficult also for a human person to understand sarcasm therefore I don't expect the following dataset to be 100% free from bias."
      ],
      "metadata": {
        "id": "8Kyh9cjvkoZN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tool used for annotation: it displays each tweet and the user has to click \"Yes\" \n",
        "# if the tweet was sarcastic, \"No\" otherwise\n",
        "\n",
        "sarcastic=Button(description=\"Yes\", button_style='info', layout=Layout(width='150px', height='50px'))\n",
        "non_sarcastic=Button(description=\"No\", button_style='info', layout=Layout(width='150px', height='50px'))\n",
        "\n",
        "asyncio.create_task(f(df))\n",
        "t.sleep(2)\n",
        "display(HBox([sarcastic,non_sarcastic]))"
      ],
      "metadata": {
        "id": "NJM-MObHrwWp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0,
          "referenced_widgets": [
            "ade30892659f44b5b3fa14158bb8822f",
            "ef832b97083c4501a01513b576f9e74b",
            "ff07d831e3f8414c952cfd0478dd1569",
            "9959fc7bcf094cf49c13abac1fd3d205",
            "f731679f895a4d19bffc7c41d50842ed",
            "52c9d59f4a404ef7bbe0d3f4750bca0d",
            "ae0c980d1df842149c1b27093980c3a1",
            "6ba53a4adc3647d8952852c4ee2019c5"
          ]
        },
        "outputId": "d15d58ec-db16-4d34-e5f0-da385a036a2c"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HBox(children=(Button(button_style='info', description='Yes', layout=Layout(height='50px', width='150px'), sty…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ade30892659f44b5b3fa14158bb8822f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%script false\n",
        "print(tweets_annotated)"
      ],
      "metadata": {
        "id": "XvlYa09uXPRs"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%script false\n",
        "df_annotated = spark.createDataFrame(tweets_annotated)\n",
        "df_annotated.tail(5)"
      ],
      "metadata": {
        "id": "5oOAAGZFsYKo"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%script false\n",
        "if not os.path.exists(DATASET_ANNOTATED):\n",
        "  os.mknod(DATASET_ANNOTATED)\n",
        "\n",
        "# save tweets\n",
        "df_annotated.toPandas().to_csv(DATASET_ANNOTATED, header=True, index=False) "
      ],
      "metadata": {
        "id": "ClMe-OHFXrDf"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. **Extend Dataset**"
      ],
      "metadata": {
        "id": "daSEOScGUKJo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "schema = StructType([StructField(\"id\", StringType(), True)\\\n",
        "                   ,StructField(\"text\", StringType(), True)\\\n",
        "                   ,StructField(\"sarcastic\", StringType(), True)])\n",
        "\n",
        "df_annotated = spark.createDataFrame(pd.read_csv(DATASET_ANNOTATED), schema=schema)"
      ],
      "metadata": {
        "id": "W4g8iOQTxneE"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Annotated tweets: {df_annotated.count()}\")"
      ],
      "metadata": {
        "id": "K421QQz1sfyt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f5a3037-0f3b-45dc-f2db-24b0ba3f90f3"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Annotated tweets: 5480\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see from the code below, we lost multiple *tweet*.\n",
        "First of all, multiple tweets classified as sarcastic were not sarcastic. Also, I've dropped every tweet that contained only one word, that wasn't actually in italian or \n",
        "that had no sense."
      ],
      "metadata": {
        "id": "M_awlh0kq3nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count_label(df_annotated).show()"
      ],
      "metadata": {
        "id": "k6k_llNRpKCE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e69930d-adfe-4c70-ee49-d00ede7ca47a"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------------------------------------------+--------------------------------------------+\n",
            "|sarcastic|count(CASE WHEN (sarcastic = Yes) THEN 1 END)|count(CASE WHEN (sarcastic = No) THEN 1 END)|\n",
            "+---------+---------------------------------------------+--------------------------------------------+\n",
            "|       No|                                            0|                                        4629|\n",
            "|      Yes|                                          830|                                           0|\n",
            "|      NaN|                                            0|                                           0|\n",
            "+---------+---------------------------------------------+--------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "However, we can integrate we some external Dataset such as: [SENTIPOLIC](http://www.di.unito.it/~tutreeb/sentipolc-evalita16/index.html) from the challenge EVALITA2016 which contains several italian tweet already classified."
      ],
      "metadata": {
        "id": "UeH_4XijrNc3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_sentipolic = spark.createDataFrame(pd.read_csv(SENTIPOLIC))"
      ],
      "metadata": {
        "id": "B2eVp6uIw9kO"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_sentipolic.show(10)"
      ],
      "metadata": {
        "id": "qld5kvU0yDBS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac363b42-e63c-4a17-c86a-2c66680ff31b"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+----+----+----+---+----+----+---+--------------------+\n",
            "|         idtwitter|subj|opos|oneg|iro|lpos|lneg|top|                text|\n",
            "+------------------+----+----+----+---+----+----+---+--------------------+\n",
            "|122449983151669248|   1|   0|   1|  0|   0|   1|  1|Intanto la partit...|\n",
            "|125485104863780865|   1|   0|   1|  0|   0|   1|  1|False illusioni, ...|\n",
            "|125513454315507712|   1|   0|   1|  0|   0|   1|  1|False illusioni, ...|\n",
            "|125524238290522113|   1|   0|   1|  0|   0|   1|  1|Mario Monti: Berl...|\n",
            "|125527933224886272|   1|   0|   1|  0|   0|   1|  1|Mario Monti: Berl...|\n",
            "|125530285164072961|   1|   1|   1|  0|   1|   1|  1|False illusioni, ...|\n",
            "|125533343482789889|   1|   0|   1|  0|   0|   1|  1|L'attacco di Mari...|\n",
            "|125633929217708032|   1|   1|   0|  0|   1|   0|  1|Mario Monti sul C...|\n",
            "|125642756147265536|   1|   0|   1|  0|   0|   1|  1|Le 5 sgradevoli r...|\n",
            "|125692702145785856|   1|   0|   1|  0|   0|   1|  1|False illusioni, ...|\n",
            "+------------------+----+----+----+---+----+----+---+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we will extract only the tweets which are ironic since we have plenty non-ironic\n",
        "df_sentipolic = df_sentipolic.filter(col(\"iro\")==1)"
      ],
      "metadata": {
        "id": "0LMvvrxNyFlS"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Ironic tweet retrieved: {df_sentipolic.count()}\")"
      ],
      "metadata": {
        "id": "lN-MoSRiyQ37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8983096-b3d2-4343-8715-d2a327fabffd"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ironic tweet retrieved: 1103\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# drop columns that we don't need\n",
        "df_sentipolic = df_sentipolic.drop(*('subj', 'opos', 'oneg', 'lpos', 'lneg', 'top'))\n",
        "\n",
        "# rename columns\n",
        "df_sentipolic = df_sentipolic.withColumnRenamed(\"idTwitter\", \"id\")\\\n",
        "                              .withColumnRenamed(\"iro\", \"sarcastic\")\n",
        "\n",
        "# change order\n",
        "df_sentipolic = df_sentipolic.select(\"id\", \"text\", \"sarcastic\")"
      ],
      "metadata": {
        "id": "CmzhGiatyZxd"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_sentipolic.show(10)"
      ],
      "metadata": {
        "id": "PrDm7Oz_zbDx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50eff330-1bf1-4300-e363-be35a0d7d50c"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+--------------------+---------+\n",
            "|                id|                text|sarcastic|\n",
            "+------------------+--------------------+---------+\n",
            "|125695266887184384|Mario Monti: c'è ...|        1|\n",
            "|125838624670490624|Ma a quanta gente...|        1|\n",
            "|127137847491821568|#la7 ma perche' M...|        1|\n",
            "|129143970163990528|Mario Monti è con...|        1|\n",
            "|131426878245437440|Ma quanto ce vuol...|        1|\n",
            "|133822129773879297|Mario Monti a cap...|        1|\n",
            "|133831591234502656| Mario Monti for ...|        1|\n",
            "|133849038243110912|[News] Mario Mont...|        1|\n",
            "|133954931982991360|cmq Mario Monti è...|        1|\n",
            "|134335814531416064| Napolitano: \"Bis...|        1|\n",
            "+------------------+--------------------+---------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now we want to join the two dataset. However we must use the same label for both.\n",
        "# Therefore if the tweet is sarcastic, the label will be 1, 0 otherwise.\n",
        "\n",
        "\n",
        "df_annotated = df_annotated.withColumn(\"sarcastic\", \n",
        "                                         when(df_annotated.sarcastic == \"Yes\", 1)\n",
        "                                         .when(df_annotated.sarcastic == \"No\", 0)                                    \n",
        "                                         .otherwise(df_annotated.sarcastic))"
      ],
      "metadata": {
        "id": "9J2Ekp4317OU"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_annotated.show()"
      ],
      "metadata": {
        "id": "MEk2bAHu2XwA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8be1c8cf-2247-4ff3-9c77-d63b2545ded6"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+--------------------+---------+\n",
            "|                 id|                text|sarcastic|\n",
            "+-------------------+--------------------+---------+\n",
            "|1524033834416754689|#'Tu sei un gioca...|        0|\n",
            "|1524034020417294337|#10maggio In occa...|        0|\n",
            "|1524034242963034112|#9maggio Zelensky...|        0|\n",
            "|1524034526908981250|#A SCUOLA DI GIUS...|        1|\n",
            "|1524034207923814401|#A1 - Ginevra -&g...|        0|\n",
            "|1524034530579030018|#A1 - Zurigo -&gt...|        0|\n",
            "|1524034404850581504|#APRILIA: TENTATO...|        0|\n",
            "|1524034635012968448|#Agricoltura, Ocm...|        0|\n",
            "|1524034097424777216|#Algeria: colloqu...|        0|\n",
            "|1524034794635603972|#Alpini pensate c...|        1|\n",
            "|1524034897383505921|#Amici21\\nIl mond...|        0|\n",
            "|1524034689366953984|#Amici21\\nRiassun...|        0|\n",
            "|1524034761940946952|#Amici21 che tene...|        0|\n",
            "|1523988570867961856|#Armi #Ucraina Fr...|        1|\n",
            "|1524001659290017794|#Armi, #gas e nuo...|        1|\n",
            "|1524033774102720512|#Aron è una creat...|        0|\n",
            "|1524033888124874752|#Bergamo L'Ammini...|        0|\n",
            "|1524033892935733248|#Bergamo Tutto su...|        0|\n",
            "|1524034781201190915|#Bergamo potrebbe...|        0|\n",
            "|1523993624861626368|#Biden e #Draghi ...|        1|\n",
            "+-------------------+--------------------+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# concatenate DataFrames\n",
        "\n",
        "df_complete = df_annotated.union(df_sentipolic)\n",
        "df_complete.show(5)"
      ],
      "metadata": {
        "id": "vRXyeqRH2nUU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce6146d4-235e-4528-a932-bd1f5973642e"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+--------------------+---------+\n",
            "|                 id|                text|sarcastic|\n",
            "+-------------------+--------------------+---------+\n",
            "|1524033834416754689|#'Tu sei un gioca...|        0|\n",
            "|1524034020417294337|#10maggio In occa...|        0|\n",
            "|1524034242963034112|#9maggio Zelensky...|        0|\n",
            "|1524034526908981250|#A SCUOLA DI GIUS...|        1|\n",
            "|1524034207923814401|#A1 - Ginevra -&g...|        0|\n",
            "+-------------------+--------------------+---------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Now we have a total of {df_complete.count()} tweets')"
      ],
      "metadata": {
        "id": "DGDmh6_d3Csy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eefeb983-7f3f-4fb0-fe31-287710eedb32"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Now we have a total of 6583 tweets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count_label(df_complete, numeric=True).show()"
      ],
      "metadata": {
        "id": "e89JUhcA3IkL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c9c82d0-0423-41f7-fcce-dee075d01cfc"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-------------------------------------------+-------------------------------------------+\n",
            "|sarcastic|count(CASE WHEN (sarcastic = 1) THEN 1 END)|count(CASE WHEN (sarcastic = 0) THEN 1 END)|\n",
            "+---------+-------------------------------------------+-------------------------------------------+\n",
            "|        0|                                          0|                                       4629|\n",
            "|      NaN|                                          0|                                          0|\n",
            "|        1|                                       1933|                                          0|\n",
            "+---------+-------------------------------------------+-------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset is still unbalanced, but better than before."
      ],
      "metadata": {
        "id": "Ap6Pm9b13WEL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. **Data Processing**"
      ],
      "metadata": {
        "id": "pDQJOzR4-Ncl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we want to clean tweet: remove hashtag, links, emoji, whitespaces, mentions."
      ],
      "metadata": {
        "id": "lGGkaFhE360S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convert to lowercase"
      ],
      "metadata": {
        "id": "orAHqnwtcBH5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_lowercase = df_complete.withColumn('text', lower(col('text')))\n",
        "df_lowercase.show(5)"
      ],
      "metadata": {
        "id": "Guj-V0Sa-VZw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa774c89-cb9d-4fa9-8a4a-b58d2a4fb653"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+--------------------+---------+\n",
            "|                 id|                text|sarcastic|\n",
            "+-------------------+--------------------+---------+\n",
            "|1524033834416754689|#'tu sei un gioca...|        0|\n",
            "|1524034020417294337|#10maggio in occa...|        0|\n",
            "|1524034242963034112|#9maggio zelensky...|        0|\n",
            "|1524034526908981250|#a scuola di gius...|        1|\n",
            "|1524034207923814401|#a1 - ginevra -&g...|        0|\n",
            "+-------------------+--------------------+---------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Remove Links"
      ],
      "metadata": {
        "id": "gvABbixLcEEW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_links = df_lowercase.withColumn('text', regexp_replace('text', r'http\\S+', ''))\n",
        "df_links.show(5)"
      ],
      "metadata": {
        "id": "uVXPLbDXNq2H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cff1b97-bcb7-4488-96f2-0c2952734aec"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+--------------------+---------+\n",
            "|                 id|                text|sarcastic|\n",
            "+-------------------+--------------------+---------+\n",
            "|1524033834416754689|#'tu sei un gioca...|        0|\n",
            "|1524034020417294337|#10maggio in occa...|        0|\n",
            "|1524034242963034112|#9maggio zelensky...|        0|\n",
            "|1524034526908981250|#a scuola di gius...|        1|\n",
            "|1524034207923814401|#a1 - ginevra -&g...|        0|\n",
            "+-------------------+--------------------+---------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Remove mentions"
      ],
      "metadata": {
        "id": "kp2tHehscHav"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_mentions = df_links.withColumn('text', regexp_replace('text', '@\\w+', ''))\n",
        "df_mentions.show(5)"
      ],
      "metadata": {
        "id": "kNotR0WCNvZ6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6b78a89-5205-4322-e950-b2039255dbe8"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+--------------------+---------+\n",
            "|                 id|                text|sarcastic|\n",
            "+-------------------+--------------------+---------+\n",
            "|1524033834416754689|#'tu sei un gioca...|        0|\n",
            "|1524034020417294337|#10maggio in occa...|        0|\n",
            "|1524034242963034112|#9maggio zelensky...|        0|\n",
            "|1524034526908981250|#a scuola di gius...|        1|\n",
            "|1524034207923814401|#a1 - ginevra -&g...|        0|\n",
            "+-------------------+--------------------+---------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Remove hashtag, keeping the word"
      ],
      "metadata": {
        "id": "ZdyQbi7tcKvi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_hashtag = df_mentions.withColumn('text', regexp_replace('text', '#', ''))\n",
        "df_hashtag.show(5)"
      ],
      "metadata": {
        "id": "U2m-waqGNzf4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3546f480-9097-4ba5-b834-8505af32140b"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+--------------------+---------+\n",
            "|                 id|                text|sarcastic|\n",
            "+-------------------+--------------------+---------+\n",
            "|1524033834416754689|'tu sei un giocat...|        0|\n",
            "|1524034020417294337|10maggio in occas...|        0|\n",
            "|1524034242963034112|9maggio zelensky?...|        0|\n",
            "|1524034526908981250|a scuola di giuse...|        1|\n",
            "|1524034207923814401|a1 - ginevra -&gt...|        0|\n",
            "+-------------------+--------------------+---------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Remove RT symbol"
      ],
      "metadata": {
        "id": "tinvjmSacNMd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_RT = df_hashtag.withColumn('text', regexp_replace('text', 'RT', ''))\n",
        "df_RT.show(5)"
      ],
      "metadata": {
        "id": "qsQzeAiqN2-E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8c1a6e6-68e4-4d8e-d1ca-f958bdf9ebea"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+--------------------+---------+\n",
            "|                 id|                text|sarcastic|\n",
            "+-------------------+--------------------+---------+\n",
            "|1524033834416754689|'tu sei un giocat...|        0|\n",
            "|1524034020417294337|10maggio in occas...|        0|\n",
            "|1524034242963034112|9maggio zelensky?...|        0|\n",
            "|1524034526908981250|a scuola di giuse...|        1|\n",
            "|1524034207923814401|a1 - ginevra -&gt...|        0|\n",
            "+-------------------+--------------------+---------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Remove punctuation"
      ],
      "metadata": {
        "id": "YTeyb52FcO-4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_punctuation = df_RT.withColumn('text', regexp_replace('text', '[^a-zA-Z\\\\s]', ''))\n",
        "df_punctuation.show(5)"
      ],
      "metadata": {
        "id": "VR6VCqdaN5kF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d9a8d13-5418-44ea-87eb-dc4bd8eaea08"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+--------------------+---------+\n",
            "|                 id|                text|sarcastic|\n",
            "+-------------------+--------------------+---------+\n",
            "|1524033834416754689|tu sei un giocato...|        0|\n",
            "|1524034020417294337|maggio in occasio...|        0|\n",
            "|1524034242963034112|maggio zelensky n...|        0|\n",
            "|1524034526908981250|a scuola di giuse...|        1|\n",
            "|1524034207923814401|a  ginevra gt los...|        0|\n",
            "+-------------------+--------------------+---------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Remove new line symbol"
      ],
      "metadata": {
        "id": "bVxdMpKicR3a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_new_line = df_punctuation.withColumn('text', regexp_replace('text', '\\n', ''))\n",
        "df_new_line.show(5)"
      ],
      "metadata": {
        "id": "CfBt3wKyOXRk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b11d91bc-b6a7-4f2f-e0d8-82fb9ac0a2ec"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+--------------------+---------+\n",
            "|                 id|                text|sarcastic|\n",
            "+-------------------+--------------------+---------+\n",
            "|1524033834416754689|tu sei un giocato...|        0|\n",
            "|1524034020417294337|maggio in occasio...|        0|\n",
            "|1524034242963034112|maggio zelensky n...|        0|\n",
            "|1524034526908981250|a scuola di giuse...|        1|\n",
            "|1524034207923814401|a  ginevra gt los...|        0|\n",
            "+-------------------+--------------------+---------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Remove emoij"
      ],
      "metadata": {
        "id": "PFb46xXycTst"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_emoij = df_new_line.withColumn('text', regexp_replace('text', \"[^\\x00-\\x7F]+\" , ''))\n",
        "df_emoij.show(5)"
      ],
      "metadata": {
        "id": "PSNeYYDlOa7z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c3c7fb5-9bb0-4cf5-881c-453efef1ea3b"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+--------------------+---------+\n",
            "|                 id|                text|sarcastic|\n",
            "+-------------------+--------------------+---------+\n",
            "|1524033834416754689|tu sei un giocato...|        0|\n",
            "|1524034020417294337|maggio in occasio...|        0|\n",
            "|1524034242963034112|maggio zelensky n...|        0|\n",
            "|1524034526908981250|a scuola di giuse...|        1|\n",
            "|1524034207923814401|a  ginevra gt los...|        0|\n",
            "+-------------------+--------------------+---------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Remove Digits"
      ],
      "metadata": {
        "id": "7VF5lLh3scuy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_digit = df_emoij.withColumn('text', regexp_replace('text', r'[0-9]{5,}', ''))\n",
        "df_digit.show(5)"
      ],
      "metadata": {
        "id": "t6bZWfWkseEU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec35112c-2ba0-4319-e4a3-b7a667865c55"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+--------------------+---------+\n",
            "|                 id|                text|sarcastic|\n",
            "+-------------------+--------------------+---------+\n",
            "|1524033834416754689|tu sei un giocato...|        0|\n",
            "|1524034020417294337|maggio in occasio...|        0|\n",
            "|1524034242963034112|maggio zelensky n...|        0|\n",
            "|1524034526908981250|a scuola di giuse...|        1|\n",
            "|1524034207923814401|a  ginevra gt los...|        0|\n",
            "+-------------------+--------------------+---------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Spell Checker"
      ],
      "metadata": {
        "id": "NtdPyrJnmnlj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When annotating the tweets, I've noticed that many of them contained spelling errors. It is recommended to adjust those tweets before the model training."
      ],
      "metadata": {
        "id": "J8fxGMrPZekd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "broker = enchant.Broker()\n",
        "broker.describe()\n",
        "broker.list_languages()"
      ],
      "metadata": {
        "id": "mmwTu7-xsNr0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b30b4366-7517-4735-86c4-7d82eb222e4c"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['it_IT', 'en_US', 'it_CH', 'en', 'en_AU', 'en_CA', 'en_GB']"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def spell_checker(text):\n",
        "  checker = SpellChecker(\"it_IT\", text)\n",
        "  for err in checker:\n",
        "    if len(err.suggest())>0:\n",
        "      sug = err.suggest()[0]\n",
        "      err.replace(sug)\n",
        "  return checker.get_text()"
      ],
      "metadata": {
        "id": "dDwr9bgG5e4o"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## TODO\n",
        "udf_spell_checker = udf(lambda x: (x), StringType())\n",
        "df_spell = df_digit.withColumn('text', udf_spell_checker(col('text')))\n",
        "\n",
        "df_spell.cache()\n",
        "\n",
        "df_spell.show(5)"
      ],
      "metadata": {
        "id": "zxp3RisBN48j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abf12d34-8b1d-468b-ac32-ddb2bd0bfa84"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+--------------------+---------+\n",
            "|                 id|                text|sarcastic|\n",
            "+-------------------+--------------------+---------+\n",
            "|1524033834416754689|tu sei un giocato...|        0|\n",
            "|1524034020417294337|maggio in occasio...|        0|\n",
            "|1524034242963034112|maggio zelensky n...|        0|\n",
            "|1524034526908981250|a scuola di giuse...|        1|\n",
            "|1524034207923814401|a  ginevra gt los...|        0|\n",
            "+-------------------+--------------------+---------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Removing exceeding whitespace"
      ],
      "metadata": {
        "id": "mMABXUG0cWl_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"a. Trimming\")\n",
        "df_trimming = df_spell.withColumn('text', trim(col('text')))\n",
        "df_trimming.show(5, truncate=False)\n",
        "\n",
        "print(\"b. Filter out extra whitespaces\")\n",
        "df_cleaned = df_trimming.withColumn('text', regexp_replace(col(\"text\"), \" +\", \" \"))\n",
        "\n",
        "df_cleaned.show(5, truncate=False)"
      ],
      "metadata": {
        "id": "BR_rP0QqOeYb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b67eb87-3a94-40a9-c25a-c3034784edef"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a. Trimming\n",
            "+-------------------+------------------------------------------------------------------------------------------------------------------------------------+---------+\n",
            "|id                 |text                                                                                                                                |sarcastic|\n",
            "+-------------------+------------------------------------------------------------------------------------------------------------------------------------+---------+\n",
            "|1524033834416754689|tu sei un giocatore incredibile abbracciami lemozionante discorso di un bambino al compagno dibattito attualitesociet la politica   |0        |\n",
            "|1524034020417294337|maggio in occasione della ix giornata dellamicizia tra copti e cattolici messaggio inviato oggi da papafrancesco a tawadros ii leggi|0        |\n",
            "|1524034242963034112|maggio zelensky nato crimea pace ha dettonoha rispostonograzie a  per il servizio reso alla chiarezza dei fatti                     |0        |\n",
            "|1524034526908981250|a scuola di giuseppe conte devi venire                                                                                              |1        |\n",
            "|1524034207923814401|a  ginevra gt losanna  tra raccordo di ecublens e losannacrissier problemi di traffico veicolo in avaria                            |0        |\n",
            "+-------------------+------------------------------------------------------------------------------------------------------------------------------------+---------+\n",
            "only showing top 5 rows\n",
            "\n",
            "b. Filter out extra whitespaces\n",
            "+-------------------+------------------------------------------------------------------------------------------------------------------------------------+---------+\n",
            "|id                 |text                                                                                                                                |sarcastic|\n",
            "+-------------------+------------------------------------------------------------------------------------------------------------------------------------+---------+\n",
            "|1524033834416754689|tu sei un giocatore incredibile abbracciami lemozionante discorso di un bambino al compagno dibattito attualitesociet la politica   |0        |\n",
            "|1524034020417294337|maggio in occasione della ix giornata dellamicizia tra copti e cattolici messaggio inviato oggi da papafrancesco a tawadros ii leggi|0        |\n",
            "|1524034242963034112|maggio zelensky nato crimea pace ha dettonoha rispostonograzie a per il servizio reso alla chiarezza dei fatti                      |0        |\n",
            "|1524034526908981250|a scuola di giuseppe conte devi venire                                                                                              |1        |\n",
            "|1524034207923814401|a ginevra gt losanna tra raccordo di ecublens e losannacrissier problemi di traffico veicolo in avaria                              |0        |\n",
            "+-------------------+------------------------------------------------------------------------------------------------------------------------------------+---------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Result"
      ],
      "metadata": {
        "id": "aJX-UZe_aBHx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df_cleaned.select([col('text'), col('sarcastic')])\n",
        "\n",
        "df.cache()\n",
        "df.show(5, truncate=False)\n",
        "\n",
        "df_spell.unpersist()"
      ],
      "metadata": {
        "id": "W2E3VSNhjtE8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4cc9c5e-a8f5-4309-8659-0c73507fb8f9"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------------------------------------------------------------------------------------------------------------+---------+\n",
            "|text                                                                                                                                |sarcastic|\n",
            "+------------------------------------------------------------------------------------------------------------------------------------+---------+\n",
            "|tu sei un giocatore incredibile abbracciami lemozionante discorso di un bambino al compagno dibattito attualitesociet la politica   |0        |\n",
            "|maggio in occasione della ix giornata dellamicizia tra copti e cattolici messaggio inviato oggi da papafrancesco a tawadros ii leggi|0        |\n",
            "|maggio zelensky nato crimea pace ha dettonoha rispostonograzie a per il servizio reso alla chiarezza dei fatti                      |0        |\n",
            "|a scuola di giuseppe conte devi venire                                                                                              |1        |\n",
            "|a ginevra gt losanna tra raccordo di ecublens e losannacrissier problemi di traffico veicolo in avaria                              |0        |\n",
            "+------------------------------------------------------------------------------------------------------------------------------------+---------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[id: string, text: string, sarcastic: string]"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. **Feature Engineering**"
      ],
      "metadata": {
        "id": "p-cnH0NX7Xup"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Starting feature engineering, constructing pipeline..\")"
      ],
      "metadata": {
        "id": "OjDEMuzht4po",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78c332e4-a39f-4920-ab90-10658265bc81"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting feature engineering, constructing pipeline..\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Document assembler\n",
        "Each annotator in Spark NLP takes specific sorts of columns and produces new columns of a different type. We have the following types in Spark NLP: document, token, chunk, pos, word embeddings, date, entity, sentiment, named entity, dependency, labeled dependency.\n",
        "\n",
        "To implement the solution in Spark NLP, we must first transform raw data into Document type. DocumentAssembler() is a special transformer that builds the initial annotation of type Document that annotators can utilize later on."
      ],
      "metadata": {
        "id": "rAS_atsEaqLN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "document_assembler = DocumentAssembler()\\\n",
        "                        .setInputCol('text')\\\n",
        "                        .setOutputCol('document')\\\n",
        "                        .setCleanupMode(\"shrink\")"
      ],
      "metadata": {
        "id": "WGJ6c4YZjhi4"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sentence Detector\n",
        "Finds sentence bounds in raw text."
      ],
      "metadata": {
        "id": "z-SPkWFVn953"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_detector = SentenceDetector()\\\n",
        "                      .setInputCols('document')\\\n",
        "                      .setOutputCol('sentence')"
      ],
      "metadata": {
        "id": "x1akLd6gbWHE"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenizer\n",
        "Tokenization is the process of breaking raw text into smaller pieces. Tokenization divides the raw text into words known as tokens. These tokens help to better understand the context or constructing the NLP model. Tokenization aids in determining the meaning of the text by evaluating the word sequence."
      ],
      "metadata": {
        "id": "tqvryDZkbHWu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = sparknlp.annotator.Tokenizer().setInputCols([\"sentence\"]).setOutputCol(\"token\")"
      ],
      "metadata": {
        "id": "CG1Hu0uBPpAE"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lemmatizer\n",
        "Lemmatization is a technique for reducing words to their normalized form. The transformation of lemmatization employs a dictionary to map distinct versions of a word back to its base format. So, using this method, we may reduce non-trivial inflections like \"is,\" \"was,\" and \"were\" down to the root \"be.\""
      ],
      "metadata": {
        "id": "cJ_NmjWhb11e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lemma = Lemmatizer()\\\n",
        "     .setInputCols(['token'])\\\n",
        "     .setOutputCol('lemma')\\\n",
        "     .setDictionary(\"lemmatization-it.txt\", \"->\", \"\\t\")"
      ],
      "metadata": {
        "id": "FkKFHCWrP6pd"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stopwords cleaner\n",
        "Removes stopwords, that are not useful to our goal, from the text."
      ],
      "metadata": {
        "id": "wltZjHU7cb9q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords_cleaner = StopWordsCleaner.pretrained(\"stopwords_it\", \"it\")\\\n",
        "     .setInputCols(['lemma'])\\\n",
        "     .setOutputCol('clean_lemma')"
      ],
      "metadata": {
        "id": "LZhcIFXqP2ej",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "537b9456-2e4f-4ba4-d03e-92a3ad764e61"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "stopwords_it download started this may take some time.\n",
            "Approximate size to download 2.4 KB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word Embedding using BERT pretrained for italian language\n",
        "Word Embedding is a method that involves representing a word with a vector. The BERT model was used to construct these embeddings in the code below since it provides embeddings that allow us to have numerous vector representations for the same word dependent on the context in which the word is used. BERT embeddings are thus context-dependent."
      ],
      "metadata": {
        "id": "V5Ztn9KYcjdF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = BertEmbeddings.pretrained(\"bert_base_italian_cased\", \"it\") \\\n",
        "      .setInputCols([\"sentence\", \"clean_lemma\"]) \\\n",
        "      .setOutputCol(\"embeddings\")"
      ],
      "metadata": {
        "id": "_SMA5vO8P9Xz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9815dcb-abea-4810-adfc-d1183fdbf3c0"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert_base_italian_cased download started this may take some time.\n",
            "Approximate size to download 393.1 MB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_embeddings = SentenceEmbeddings()\\\n",
        "                        .setInputCols([\"sentence\", \"embeddings\"])\\\n",
        "                        .setOutputCol(\"sentence_embeddings\")"
      ],
      "metadata": {
        "id": "Vw4DouOoisXu"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_finisher = EmbeddingsFinisher() \\\n",
        "                      .setInputCols(\"sentence_embeddings\") \\\n",
        "                      .setOutputCols(\"features\") \\\n",
        "                      .setOutputAsVector(False) \\\n",
        "                      .setCleanAnnotations(False)"
      ],
      "metadata": {
        "id": "w7f-XHIFGZu5"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fitting pipeline"
      ],
      "metadata": {
        "id": "apVjUtRcgUi4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = Pipeline(stages=[\n",
        "                    document_assembler,\n",
        "                    sentence_detector,\n",
        "                    tokenizer,\n",
        "                    lemma,\n",
        "                    stopwords_cleaner,\n",
        "                    embeddings,\n",
        "                    sentence_embeddings,\n",
        "                    embeddings_finisher]\n",
        ")"
      ],
      "metadata": {
        "id": "nc557jkAZc0W"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "features = pipeline.fit(df).transform(df)"
      ],
      "metadata": {
        "id": "i284tX2NRJGP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a61fea9-9a65-493e-a759-aae96b6c5c4d"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 168 ms, sys: 23.9 ms, total: 191 ms\n",
            "Wall time: 3.07 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_fitted = features.withColumn(\"features\", explode(\"features\"))"
      ],
      "metadata": {
        "id": "k4RtvVDtbHag"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "df_fitted.cache()\n",
        "\n",
        "df_fitted = df_fitted.select([col(\"features\"), col(\"sarcastic\").alias(\"target\")])\n",
        "\n",
        "df_fitted.show()"
      ],
      "metadata": {
        "id": "9KXs6UYY8zLY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "93ac4168-5b53-4d73-b64b-ae8f3cf905a2"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-95-22021d18b745>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'df_fitted.cache()\\n\\ndf_fitted = df_fitted.select([col(\"features\"), col(\"sarcastic\").alias(\"target\")])\\n\\ndf_fitted.show()'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-53>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mcache\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    803\u001b[0m         \"\"\"\n\u001b[1;32m    804\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_cached\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 805\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    806\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1306\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1308\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1309\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1310\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1038\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1039\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/py4j/clientserver.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m                 \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m                 \u001b[0;31m# Happens when a the other end is dead. There might be an empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the model"
      ],
      "metadata": {
        "id": "AKicmZse8UWx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rows = []\n",
        "for row in df_fitted.collect():\n",
        "  if len(row['features']) > 0:\n",
        "    rows.append(row)\n",
        "\n",
        "df_fitted = spark.createDataFrame(rows)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mCFp89KopjX6",
        "outputId": "b30ef444-2fe6-4619-8250-24967a5f42a6"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pyspark/sql/dataframe.py\", line 693, in collect\n",
            "    sock_info = self._jdf.collectToPython()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/py4j/java_gateway.py\", line 1308, in __call__\n",
            "    answer = self.gateway_client.send_command(command)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
            "    response = connection.send_command(command)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/py4j/clientserver.py\", line 475, in send_command\n",
            "    answer = smart_decode(self.stream.readline()[:-1])\n",
            "  File \"/usr/lib/python3.7/socket.py\", line 589, in readinto\n",
            "    return self._sock.recv_into(b)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-93-a7fb224f5c6e>\", line 2, in <module>\n",
            "    for row in df_fitted.collect():\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pyspark/sql/dataframe.py\", line 693, in collect\n",
            "    sock_info = self._jdf.collectToPython()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pyspark/traceback_utils.py\", line 78, in __exit__\n",
            "    self._context._jsc.setCallSite(None)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/py4j/java_gateway.py\", line 1308, in __call__\n",
            "    answer = self.gateway_client.send_command(command)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
            "    response = connection.send_command(command)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/py4j/clientserver.py\", line 475, in send_command\n",
            "    answer = smart_decode(self.stream.readline()[:-1])\n",
            "  File \"/usr/lib/python3.7/socket.py\", line 589, in readinto\n",
            "    return self._sock.recv_into(b)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
            "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 742, in getmodule\n",
            "    os.path.realpath(f)] = module.__name__\n",
            "  File \"/usr/lib/python3.7/posixpath.py\", line 395, in realpath\n",
            "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
            "  File \"/usr/lib/python3.7/posixpath.py\", line 429, in _joinrealpath\n",
            "    if not islink(newpath):\n",
            "  File \"/usr/lib/python3.7/posixpath.py\", line 171, in islink\n",
            "    st = os.lstat(path)\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    692\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectToPython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchedSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPickleSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1308\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1309\u001b[0m         return_value = get_return_value(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1037\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1038\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1039\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/py4j/clientserver.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    474\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m                 \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_code\u001b[0;34m(self, code_obj, result)\u001b[0m\n\u001b[1;32m   2881\u001b[0m                 \u001b[0;31m#rprint('Running code', repr(code_obj)) # dbg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2882\u001b[0;31m                 \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_global_ns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2883\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-93-a7fb224f5c6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf_fitted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'features'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    692\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectToPython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchedSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPickleSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/traceback_utils.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, tb)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spark_stack_depth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetCallSite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1308\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1309\u001b[0m         return_value = get_return_value(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1037\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1038\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1039\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/py4j/clientserver.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    474\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m                 \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only)\u001b[0m\n\u001b[1;32m   1822\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_code\u001b[0;34m(self, code_obj, result)\u001b[0m\n\u001b[1;32m   2897\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2898\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_in_exec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2899\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2900\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m             \u001b[0moutflag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only)\u001b[0m\n\u001b[1;32m   1824\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 1826\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   1827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1828\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1409\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1410\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1411\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1317\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1319\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1320\u001b[0m             )\n\u001b[1;32m   1321\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1180\u001b[0m             \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_parts_of_chained_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m                 \u001b[0mformatted_exceptions\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_chained_exception_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__cause__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m                 \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"list\") to str"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_fitted = df_fitted.filter(~col('target').contains('NaN'))"
      ],
      "metadata": {
        "id": "H0zgErP5DNtp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "outputId": "d5339f02-f140-4959-ee53-b7fe8ee57f74"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-94-02145d878f0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_fitted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_fitted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'NaN'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/sql/functions.py\u001b[0m in \u001b[0;36mcol\u001b[0;34m(col)\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0mColumn\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \"\"\"\n\u001b[0;32m--> 114\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_invoke_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"col\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/sql/functions.py\u001b[0m in \u001b[0;36m_invoke_function\u001b[0;34m(name, *args)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mand\u001b[0m \u001b[0mwraps\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mColumn\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \"\"\"\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mjf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_get_jvm_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/sql/functions.py\u001b[0m in \u001b[0;36m_get_get_jvm_function\u001b[0;34m(name, sc)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mJava\u001b[0m \u001b[0mgateway\u001b[0m \u001b[0massociated\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \"\"\"\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1698\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREFLECTION_COMMAND_NAME\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1699\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREFL_GET_UNKNOWN_SUB_COMMAND_NAME\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1700\u001b[0;31m             \"\\n\" + proto.END_COMMAND_PART)\n\u001b[0m\u001b[1;32m   1701\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSUCCESS_PACKAGE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1702\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mJavaPackage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway_client\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjvm_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1038\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1039\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/py4j/clientserver.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m                 \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m                 \u001b[0;31m# Happens when a the other end is dead. There might be an empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import lpad\n",
        "df_fitted.select('id',lpad(df_fitted['features'],250,'0')).show()"
      ],
      "metadata": {
        "id": "dgwIojzq4MRd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = df_fitted.randomSplit([0.7, 0.3], seed=42)"
      ],
      "metadata": {
        "id": "Lsw7-cZKw_N5"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = train.select('features').first()[0].shape\n",
        "input_dim"
      ],
      "metadata": {
        "id": "HGItOhtyxsuD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f15b4118-5095-4bd9-d676-566ab0f9f383"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(768,)"
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(300, output_dim=50))\n",
        "model.add(LSTM(units=50))\n",
        "model.add(Dense(1))"
      ],
      "metadata": {
        "id": "Yr5Ox7AdyHzO"
      },
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam')"
      ],
      "metadata": {
        "id": "fYevVAd_1weA"
      },
      "execution_count": 201,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from elephas.spark_model import SparkModel\n",
        "\n",
        "spark_model = SparkModel(model, frequency='epoch', mode='asynchronous')\n",
        "spark_model.fit(train.rdd, epochs=20, batch_size=64, verbose=1, validation_split=0.1)"
      ],
      "metadata": {
        "id": "I1Qm0sYo4yXr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fbde2179-8170-474e-b0a4-c630f008ac3d"
      },
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "error",
          "ename": "Py4JJavaError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-202-dbec253ccaea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mspark_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrequency\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'asynchronous'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mspark_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/elephas/spark_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, rdd, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'asynchronous'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'synchronous'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'hogwild'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/elephas/spark_model.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, rdd, **kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m                 yaml, parameters, self.client, train_config, freq, optimizer, loss, metrics, custom)\n\u001b[1;32m    178\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'>>> Distribute load'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'>>> Async training complete.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mnew_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/rdd.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    948\u001b[0m         \"\"\"\n\u001b[1;32m    949\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m             \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectAndServe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1308\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1310\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1312\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
            "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 111.0 failed 1 times, most recent failure: Lost task 0.0 in stage 111.0 (TID 285) (b4d8410a71e7 executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/lib/python3.7/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 619, in main\n    process()\n  File \"/usr/local/lib/python3.7/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 611, in process\n    serializer.dump_stream(out_iter, outfile)\n  File \"/usr/local/lib/python3.7/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 259, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/usr/local/lib/python3.7/dist-packages/elephas/worker.py\", line 105, in train\n    self.model.set_weights(weights_before_training)\n  File \"/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\", line 1849, in set_weights\n    (self.name, len(weights), expected_num_weights, str(weights)[:50]))\nValueError: You called `set_weights(weights)` on layer \"sequential_25\" with a weight list of length 8, but the layer was expecting 6 weights. Provided weights: [array([[ 0.06677961, -0.10664315, -0.09308646, -0...\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:545)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:703)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:685)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:498)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1030)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2254)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2403)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2352)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2351)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2351)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1109)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1109)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1109)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2591)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2533)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2522)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:898)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2214)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2235)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2254)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2279)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1030)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:414)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1029)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:180)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat sun.reflect.GeneratedMethodAccessor127.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/lib/python3.7/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 619, in main\n    process()\n  File \"/usr/local/lib/python3.7/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 611, in process\n    serializer.dump_stream(out_iter, outfile)\n  File \"/usr/local/lib/python3.7/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 259, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/usr/local/lib/python3.7/dist-packages/elephas/worker.py\", line 105, in train\n    self.model.set_weights(weights_before_training)\n  File \"/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\", line 1849, in set_weights\n    (self.name, len(weights), expected_num_weights, str(weights)[:50]))\nValueError: You called `set_weights(weights)` on layer \"sequential_25\" with a weight list of length 8, but the layer was expecting 6 weights. Provided weights: [array([[ 0.06677961, -0.10664315, -0.09308646, -0...\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:545)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:703)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:685)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:498)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1030)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2254)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n"
          ]
        }
      ]
    }
  ]
}